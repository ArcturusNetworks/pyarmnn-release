<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.4" />
<title>pyarmnn API documentation</title>
<meta name="description" content="About PyArmNN …" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pyarmnn</code></h1>
</header>
<section id="section-intro">
<h1 id="about-pyarmnn">About PyArmNN</h1>
<p>PyArmNN is a python extension for <a href="https://developer.arm.com/ip-products/processors/machine-learning/arm-nn">Arm NN SDK</a>.
PyArmNN provides interface similar to Arm NN C++ Api.
Before you proceed with the project setup, you will need to checkout and build a corresponding Arm NN version.</p>
<p>PyArmNN is built around public headers from the armnn/include folder of Arm NN. PyArmNN does not implement any computation kernels itself, all operations are
delegated to the Arm NN library. </p>
<p>The following diagram shows the conceptual architecture of this library:
<img alt="PyArmNN" src="../images/pyarmnn.png"></p>
<h1 id="pyarmnn-installation">PyArmNN installation</h1>
<p>PyArmNN is currently distributed only as a whl package (or also called binary package).</p>
<p>Binary package is platform dependent and the name of the package will indicate the platform it was built for. It also depends on the version of Python, e.g.:</p>
<ul>
<li>Arm NN 19.08 package for Python3.7/Linux Aarch 64 bit machine: pyarmnn-19.8.0-cp37-cp37m-linux_aarch64.whl</li>
</ul>
<p>The binary package requires the Arm NN library to be present on the target/build machine.</p>
<p>PyArmNN also depends on Numpy python library. It will be automatically downloaded and installed alongside PyArmNN. If your machine does not have access to Python pip repository you might need to install Numpy in advance by following public instructions: <a href="https://scipy.org/install.html">https://scipy.org/install.html</a></p>
<h2 id="installing-from-wheel">Installing from wheel</h2>
<p>Make sure that Arm NN binaries and Arm NN dependencies are installed and can be found in one of the system default library locations. You can check default locations by executing the following command:</p>
<pre><code class="bash">$ gcc --print-search-dirs
</code></pre>
<p>Install PyArmNN from binary by pointing to the wheel file:</p>
<pre><code class="bash">$ pip3 install /path/to/pyarmnn-19.8.0-cp37-cp37m-linux_aarch64.whl
</code></pre>
<h1 id="pyarmnn-api-overview">PyArmNN API overview</h1>
<h4 id="getting-started">Getting started</h4>
<p>The easiest way to begin using PyArmNN is by using the Parsers. We will demonstrate how to use them below:</p>
<p>Create a parser object and load your model file.</p>
<pre><code class="python">import pyarmnn as ann
import imageio

# ONNX, Caffe and TF parsers also exist.
parser = ann.ITfLiteParser()  
network = parser.CreateNetworkFromBinaryFile('./model.tflite')
</code></pre>
<p>Get the input binding information by using the name of the input layer.</p>
<pre><code class="python">input_binding_info = parser.GetNetworkInputBindingInfo(0, 'model/input')

# Create a runtime object that will perform inference.
options = ann.CreationOptions()
runtime = ann.IRuntime(options)
</code></pre>
<p>Choose preferred backends for execution and optimize the network.</p>
<pre><code class="python"># Backend choices earlier in the list have higher preference.
preferredBackends = [ann.BackendId('CpuAcc'), ann.BackendId('CpuRef')]
opt_network, messages = ann.Optimize(network, preferredBackends, runtime.GetDeviceSpec(), ann.OptimizerOptions())

# Load the optimized network into the runtime.
net_id, _ = runtime.LoadNetwork(opt_network)
</code></pre>
<p>Make workload tensors using input and output binding information.</p>
<pre><code class="python"># Load an image and create an inputTensor for inference.
img = imageio.imread('./image.png')
input_tensors = ann.make_input_tensors([input_binding_info], [img])

# Get output binding information for an output layer by using the layer name.
output_binding_info = parser.GetNetworkOutputBindingInfo(0, 'model/output')
output_tensors = ann.make_output_tensors([outputs_binding_info])
</code></pre>
<p>Perform inference and get the results back into a numpy array.</p>
<pre><code class="python">runtime.EnqueueWorkload(0, input_tensors, output_tensors)

results = ann.workload_tensors_to_ndarray(output_tensors)
print(results)
</code></pre>
<h4 id="running-examples">Running examples</h4>
<p>For a more complete Arm NN experience, there is a couple of examples located in the examples folder, which require requests, PIL and maybe some other python modules. You may install those using pip.</p>
<p>To run these examples you may simply execute them using the python interpreter. There are no arguments and the resources are downloaded by the scripts:</p>
<pre><code class="bash">$ python3 /path/to/examples/tflite_mobilenetv1_quantized.py
</code></pre>
<p><em>example_utils.py</em> is a file containg common functions for the rest of the scripts and ot does not execute anything on its own. The rest of the scripts are the examples.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright © 2019 Arm Ltd. All rights reserved.
# Copyright 2020 NXP
# SPDX-License-Identifier: MIT
import inspect
import sys
import logging

from ._generated.pyarmnn_version import GetVersion, GetMajorVersion, GetMinorVersion

# Parsers
try:
    from ._generated.pyarmnn_caffeparser import ICaffeParser
except ImportError as err:
    logger = logging.getLogger(__name__)
    message = &#34;Your ArmNN library instance does not support Caffe models parser functionality. &#34;
    logger.warning(message + &#34;Skipped ICaffeParser import.&#34;)
    logger.debug(str(err))


    def ICaffeParser():
        raise RuntimeError(message)

try:
    from ._generated.pyarmnn_onnxparser import IOnnxParser
except ImportError as err:
    logger = logging.getLogger(__name__)
    message = &#34;Your ArmNN library instance does not support Onnx models parser functionality. &#34;
    logger.warning(message + &#34;Skipped IOnnxParser import.&#34;)
    logger.debug(str(err))


    def IOnnxParser():
        raise RuntimeError(message)

try:
    from ._generated.pyarmnn_tfparser import ITfParser
except ImportError as err:
    logger = logging.getLogger(__name__)
    message = &#34;Your ArmNN library instance does not support TF models parser functionality. &#34;
    logger.warning(message + &#34;Skipped ITfParser import.&#34;)
    logger.debug(str(err))


    def ITfParser():
        raise RuntimeError(message)

try:
    from ._generated.pyarmnn_tfliteparser import ITfLiteParser
except ImportError as err:
    logger = logging.getLogger(__name__)
    message = &#34;Your ArmNN library instance does not support TF lite models parser functionality. &#34;
    logger.warning(message + &#34;Skipped ITfLiteParser import.&#34;)
    logger.debug(str(err))


    def ITfLiteParser():
        raise RuntimeError(message)

# Network
from ._generated.pyarmnn import Optimize, OptimizerOptions, IOptimizedNetwork, IInputSlot, \
    IOutputSlot, IConnectableLayer, INetwork

# Backend
from ._generated.pyarmnn import BackendId
from ._generated.pyarmnn import IDeviceSpec

# Tensors
from ._generated.pyarmnn import TensorInfo, TensorShape

# Runtime
from ._generated.pyarmnn import IRuntime, CreationOptions

# Profiler
from ._generated.pyarmnn import IProfiler

# Types
from ._generated.pyarmnn import DataType_Float16, DataType_Float32, DataType_QuantisedAsymm8, DataType_Signed32, \
    DataType_Boolean, DataType_QuantisedSymm16
from ._generated.pyarmnn import DataLayout_NCHW, DataLayout_NHWC
from ._generated.pyarmnn import ActivationFunction_Abs, ActivationFunction_BoundedReLu, ActivationFunction_LeakyReLu, \
    ActivationFunction_Linear, ActivationFunction_ReLu, ActivationFunction_Sigmoid, ActivationFunction_SoftReLu, \
    ActivationFunction_Sqrt, ActivationFunction_Square, ActivationFunction_TanH, ActivationDescriptor
from ._generated.pyarmnn import BatchNormalizationDescriptor, BatchToSpaceNdDescriptor
from ._generated.pyarmnn import Convolution2dDescriptor, DepthwiseConvolution2dDescriptor, \
    DetectionPostProcessDescriptor, FakeQuantizationDescriptor, FullyConnectedDescriptor, \
    LstmDescriptor, L2NormalizationDescriptor, MeanDescriptor
from ._generated.pyarmnn import NormalizationAlgorithmChannel_Across, NormalizationAlgorithmChannel_Within, \
    NormalizationAlgorithmMethod_LocalBrightness, NormalizationAlgorithmMethod_LocalContrast, NormalizationDescriptor
from ._generated.pyarmnn import PadDescriptor
from ._generated.pyarmnn import PermutationVector, PermuteDescriptor
from ._generated.pyarmnn import OutputShapeRounding_Ceiling, OutputShapeRounding_Floor, \
    PaddingMethod_Exclude, PaddingMethod_IgnoreValue, PoolingAlgorithm_Average, PoolingAlgorithm_L2, \
    PoolingAlgorithm_Max, Pooling2dDescriptor
from ._generated.pyarmnn import ResizeMethod_Bilinear, ResizeMethod_NearestNeighbor, ResizeDescriptor, \
    ReshapeDescriptor, SpaceToBatchNdDescriptor, SpaceToDepthDescriptor, \
    StackDescriptor, StridedSliceDescriptor, SoftmaxDescriptor, TransposeConvolution2dDescriptor, \
    SplitterDescriptor
from ._generated.pyarmnn import ConcatDescriptor, CreateDescriptorForConcatenation

from ._generated.pyarmnn import LstmInputParams

# Public API
# Quantization
from ._quantization.quantize_and_dequantize import quantize, dequantize

# Tensor
from ._tensor.tensor import Tensor
from ._tensor.const_tensor import ConstTensor
from ._tensor.workload_tensors import make_input_tensors, make_output_tensors, workload_tensors_to_ndarray

# Utilities
from ._utilities.profiling_helper import ProfilerData, get_profiling_data

from ._version import __version__, __arm_ml_version__

ARMNN_VERSION = GetVersion()


def __check_version():
    from ._version import check_armnn_version
    check_armnn_version(ARMNN_VERSION)


__check_version()

__all__ = []

__private_api_names = [&#39;__check_version&#39;]

for name, obj in inspect.getmembers(sys.modules[__name__]):
    if inspect.isclass(obj) or inspect.isfunction(obj):
        if name not in __private_api_names:
            __all__.append(name)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pyarmnn.CreateDescriptorForConcatenation"><code class="name flex">
<span>def <span class="ident">CreateDescriptorForConcatenation</span></span>(<span>shapes, concatenationDimension)</span>
</code></dt>
<dd>
<section class="desc"><p>Create a descriptor for Concatenation layer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>shapes</code></strong> :&ensp;<code>list</code> of <a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape"><code>TensorShape</code></a></dt>
<dd>Input shapes.</dd>
<dt><strong><code>concatenationDimension</code></strong> :&ensp;<code>unsigned</code> <code>int</code></dt>
<dd>Concatenation axis.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.ConcatDescriptor" href="#pyarmnn.ConcatDescriptor"><code>ConcatDescriptor</code></a></strong></dt>
<dd>A descriptor object for a concatenation layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CreateDescriptorForConcatenation(shapes, concatenationDimension):
    r&#34;&#34;&#34;

    Create a descriptor for Concatenation layer.
    Args:
        shapes (list of TensorShape): Input shapes.
        concatenationDimension (unsigned int): Concatenation axis.

    Returns:
        ConcatDescriptor: A descriptor object for a concatenation layer.

    &#34;&#34;&#34;
    return _pyarmnn.CreateDescriptorForConcatenation(shapes, concatenationDimension)</code></pre>
</details>
</dd>
<dt id="pyarmnn.GetMajorVersion"><code class="name flex">
<span>def <span class="ident">GetMajorVersion</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns Arm NN library major version. The year of the release.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>Major version of Arm NN installed.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetMajorVersion():
    r&#34;&#34;&#34;

    Returns Arm NN library major version. The year of the release.

    Returns:
        str: Major version of Arm NN installed.


    &#34;&#34;&#34;
    return _pyarmnn_version.GetMajorVersion()</code></pre>
</details>
</dd>
<dt id="pyarmnn.GetMinorVersion"><code class="name flex">
<span>def <span class="ident">GetMinorVersion</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns Arm NN library minor version. Month of the year of the release.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>Minor version of Arm NN installed.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetMinorVersion():
    r&#34;&#34;&#34;

    Returns Arm NN library minor version. Month of the year of the release.

    Returns:
        str: Minor version of Arm NN installed.


    &#34;&#34;&#34;
    return _pyarmnn_version.GetMinorVersion()</code></pre>
</details>
</dd>
<dt id="pyarmnn.GetVersion"><code class="name flex">
<span>def <span class="ident">GetVersion</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns Arm NN library full version: MAJOR + MINOR + INCREMENTAL.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>Full version of Arm NN installed.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetVersion():
    r&#34;&#34;&#34;

    Returns Arm NN library full version: MAJOR + MINOR + INCREMENTAL.

    Returns:
        str: Full version of Arm NN installed.


    &#34;&#34;&#34;
    return _pyarmnn_version.GetVersion()</code></pre>
</details>
</dd>
<dt id="pyarmnn.Optimize"><code class="name flex">
<span>def <span class="ident">Optimize</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>Create an optimized version of the given network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<a title="pyarmnn.INetwork" href="#pyarmnn.INetwork"><code>INetwork</code></a></dt>
<dd>INetwork description of the network to be optimized.</dd>
<dt><strong><code>backendPreferences</code></strong> :&ensp;<code>list</code></dt>
<dd>The choice of the backend ordered by user preferences. See <a title="pyarmnn.BackendId" href="#pyarmnn.BackendId"><code>BackendId</code></a>.</dd>
<dt><strong><code>deviceSpec</code></strong> :&ensp;<a title="pyarmnn.IDeviceSpec" href="#pyarmnn.IDeviceSpec"><code>IDeviceSpec</code></a></dt>
<dd>DeviceSpec object as queried from the runtime. See <a title="pyarmnn.IRuntime.GetDeviceSpec" href="#pyarmnn.IRuntime.GetDeviceSpec"><code>IRuntime.GetDeviceSpec()</code></a>.</dd>
<dt><strong><code>options</code></strong> :&ensp;<a title="pyarmnn.OptimizerOptions" href="#pyarmnn.OptimizerOptions"><code>OptimizerOptions</code></a></dt>
<dd>Object with optimizer configuration options.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork"><code>IOptimizedNetwork</code></a>, a tuple of failures or warnings).</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If process fails.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Optimize(*args):
    r&#34;&#34;&#34;

    Create an optimized version of the given network.
    Args:
        network (INetwork): INetwork description of the network to be optimized.
        backendPreferences (list): The choice of the backend ordered by user preferences. See `BackendId`.
        deviceSpec (IDeviceSpec): DeviceSpec object as queried from the runtime. See `IRuntime.GetDeviceSpec`.
        options (OptimizerOptions): Object with optimizer configuration options.

    Returns:
        tuple: (`IOptimizedNetwork`, a tuple of failures or warnings).

    Raises:
        RuntimeError: If process fails.

    &#34;&#34;&#34;
    return _pyarmnn.Optimize(*args)</code></pre>
</details>
</dd>
<dt id="pyarmnn.dequantize"><code class="name flex">
<span>def <span class="ident">dequantize</span></span>(<span>value, scale, offset, from_dtype)</span>
</code></dt>
<dd>
<section class="desc"><p>Dequantize given value from the given datatype using Armnn.</p>
<p>This function can be used to convert an 8-bit unsigned integer value or 16/32-bit
integer value into a 32-bit floating point value. Typically used when decoding an
output value from an output tensor on a quantized model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code></dt>
<dd>The value to be dequantized. Value could be numpy numeric data type.</dd>
<dt><strong><code>scale</code></strong> :&ensp;<code>float</code></dt>
<dd>A numeric constant that the value is multiplied by.</dd>
<dt><strong><code>offset</code></strong> :&ensp;<code>float</code></dt>
<dd>A 'zero-point' used to 'shift' the integer range.</dd>
<dt><strong><code>from_dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>The data type 'value' represents. Supported values: 'unit8', 'int16', 'int32'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>float</code></strong></dt>
<dd>A dequantized 32-bit floating-point value.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dequantize(value: int, scale: float, offset: float, from_dtype: str) -&gt; float:
    &#34;&#34;&#34;Dequantize given value from the given datatype using Armnn.

    This function can be used to convert an 8-bit unsigned integer value or 16/32-bit
    integer value into a 32-bit floating point value. Typically used when decoding an
    output value from an output tensor on a quantized model.

    Args:
        value (int): The value to be dequantized. Value could be numpy numeric data type.
        scale (float): A numeric constant that the value is multiplied by.
        offset (float): A &#39;zero-point&#39; used to &#39;shift&#39; the integer range.
        from_dtype (str): The data type &#39;value&#39; represents. Supported values: &#39;unit8&#39;, &#39;int16&#39;, &#39;int32&#39;.

    Returns:
        float: A dequantized 32-bit floating-point value.
    &#34;&#34;&#34;

    # specifies which function to use with given datatype and the value range for that data type.
    if from_dtype not in __dtype_to_dequantize_function:
        raise ValueError(&#34;&#34;&#34;Unexpected value datatype {} given. 
                         Armnn currently supports dequantization from {} values.&#34;&#34;&#34;.format(from_dtype, list(__dtype_to_dequantize_function.keys())))

    input_range = __dtype_to_dequantize_function[from_dtype][0]

    if not input_range[0] &lt;= value &lt;= input_range[1]:
        raise ValueError(&#39;Value is not within range of the given datatype {}&#39;.format(from_dtype))

    return __dtype_to_dequantize_function[from_dtype][1](int(value), scale, offset)</code></pre>
</details>
</dd>
<dt id="pyarmnn.get_profiling_data"><code class="name flex">
<span>def <span class="ident">get_profiling_data</span></span>(<span>profiler)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads IProfiler object passed in, extracts the relevant data
and returns it in a ProfilerData container.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>profile_log</code></strong> :&ensp;<a title="pyarmnn.IProfiler" href="#pyarmnn.IProfiler"><code>IProfiler</code></a></dt>
<dd>The IProfiler object to be parsed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.ProfilerData" href="#pyarmnn.ProfilerData"><code>ProfilerData</code></a></strong></dt>
<dd>A container containing the relevant data extracted from the Profiler output.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_profiling_data(profiler: &#39;IProfiler&#39;) -&gt; ProfilerData:
    &#34;&#34;&#34;Reads IProfiler object passed in, extracts the relevant data
        and returns it in a ProfilerData container.

        Args:
            profile_log (IProfiler): The IProfiler object to be parsed.

        Returns:
            ProfilerData: A container containing the relevant data extracted from the Profiler output.
    &#34;&#34;&#34;

    top_level_dict = json.loads(profiler.as_json())
    armnn_data = top_level_dict[&#34;ArmNN&#34;]
    inference_measurements = armnn_data[&#34;inference_measurements_#1&#34;]
    execution_data = inference_measurements[&#34;Execute_#2&#34;]

    workload_data = {}
    inference_data = {}
    for exec_key, exec_value in execution_data.items():
        # Check all items with a type.
        if &#34;type&#34; in exec_value and exec_value[&#34;type&#34;] == &#34;Event&#34;:
            for event_key, event_value in exec_value.items():
                if event_key.startswith(&#34;Wall clock time_#&#34;) and event_value[&#34;type&#34;] == &#34;Measurement&#34;:
                    time_data = __get_wall_clock_times__(event_value)
                    time_data[&#34;backend&#34;] = __get_backend(exec_key)
                    workload_data[exec_key] = time_data
        # This is the total inference time map
        if exec_key.startswith(&#34;Wall clock time_#&#34;) and exec_value[&#34;type&#34;] == &#34;Measurement&#34;:
            time_data = __get_wall_clock_times__(exec_value)
            inference_data.update(time_data)
    return ProfilerData(inference_data=inference_data, per_workload_execution_data=workload_data)</code></pre>
</details>
</dd>
<dt id="pyarmnn.make_input_tensors"><code class="name flex">
<span>def <span class="ident">make_input_tensors</span></span>(<span>inputs_binding_info, input_data)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns <code>inputTensors</code> to be used with <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.</p>
<p>This is the primary function to call when you want to produce <code>inputTensors</code> for <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.
The output is a list of tuples containing ConstTensors with a corresponding input tensor id.
The output should be used directly with <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.
This function works for single or multiple input data and binding information.</p>
<h2 id="examples">Examples</h2>
<p>Creating inputTensors.</p>
<pre><code>&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt;
&gt;&gt;&gt; parser = ann.ITfLiteParser()
&gt;&gt;&gt; ...
&gt;&gt;&gt; example_image = np.array(...)
&gt;&gt;&gt; input_binding_info = parser.GetNetworkInputBindingInfo(...)
&gt;&gt;&gt;
&gt;&gt;&gt; input_tensors = ann.make_input_tensors([input_binding_info], [example_image])
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>inputs_binding_info</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>(int, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>) Binding information for input tensors obtained from <code>GetNetworkInputBindingInfo</code>.</dd>
<dt><strong><code>input_data</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>Tensor data to be used for inference.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd><code>inputTensors</code> - A list of tuples (<code>int</code> , <a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a>).</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>ValueError</code></strong></dt>
<dd>If length of <code>inputs_binding_info</code> and <code>input_data</code> are not the same.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_input_tensors(inputs_binding_info: List[Tuple],
                       input_data: List[np.ndarray]) -&gt; List[Tuple[int, ConstTensor]]:
    &#34;&#34;&#34;Returns `inputTensors` to be used with `IRuntime.EnqueueWorkload`.

    This is the primary function to call when you want to produce `inputTensors` for `IRuntime.EnqueueWorkload`.
    The output is a list of tuples containing ConstTensors with a corresponding input tensor id.
    The output should be used directly with `IRuntime.EnqueueWorkload`.
    This function works for single or multiple input data and binding information.

    Examples:
        Creating inputTensors.
        &gt;&gt;&gt; import pyarmnn as ann
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt;
        &gt;&gt;&gt; parser = ann.ITfLiteParser()
        &gt;&gt;&gt; ...
        &gt;&gt;&gt; example_image = np.array(...)
        &gt;&gt;&gt; input_binding_info = parser.GetNetworkInputBindingInfo(...)
        &gt;&gt;&gt;
        &gt;&gt;&gt; input_tensors = ann.make_input_tensors([input_binding_info], [example_image])

    Args:
        inputs_binding_info (list of tuples): (int, `TensorInfo`) Binding information for input tensors obtained from `GetNetworkInputBindingInfo`.
        input_data (ndarray): Tensor data to be used for inference.

    Returns:
        list: `inputTensors` - A list of tuples (`int` , `ConstTensor`).


    Raises:
        ValueError: If length of `inputs_binding_info` and `input_data` are not the same.
    &#34;&#34;&#34;
    if len(inputs_binding_info) != len(input_data):
        raise ValueError(&#34;Length of &#39;inputs_binding_info&#39; does not match length of &#39;input_data&#39;&#34;)

    input_tensors = []

    for in_bind_info, in_data in zip(inputs_binding_info, input_data):
        in_tensor_id = in_bind_info[0]
        in_tensor_info = in_bind_info[1]
        input_tensors.append((in_tensor_id, ConstTensor(in_tensor_info, in_data)))

    return input_tensors</code></pre>
</details>
</dd>
<dt id="pyarmnn.make_output_tensors"><code class="name flex">
<span>def <span class="ident">make_output_tensors</span></span>(<span>outputs_binding_info)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns <code>outputTensors</code> to be used with <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.</p>
<p>This is the primary function to call when you want to produce <code>outputTensors</code> for <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.
The output is a list of tuples containing Tensors with a corresponding output tensor id.
The output should be used directly with <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.</p>
<h2 id="examples">Examples</h2>
<p>Creating outputTensors.</p>
<pre><code>&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt;
&gt;&gt;&gt; parser = ann.ITfLiteParser()
&gt;&gt;&gt; ...
&gt;&gt;&gt; output_binding_info = parser.GetNetworkOutputBindingInfo(...)
&gt;&gt;&gt;
&gt;&gt;&gt; output_tensors = ann.make_output_tensors([output_binding_info])
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>outputs_binding_info</code></strong> :&ensp;<code>list</code> of <code>tuples</code></dt>
<dd>(int, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>) Binding information for output tensors obtained from <code>GetNetworkOutputBindingInfo</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd><code>outputTensors</code> - A list of tuples (<code>int</code>, <a title="pyarmnn.Tensor" href="#pyarmnn.Tensor"><code>Tensor</code></a>).</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_output_tensors(outputs_binding_info: List[Tuple]) -&gt; List[Tuple[int, Tensor]]:
    &#34;&#34;&#34;Returns `outputTensors` to be used with `IRuntime.EnqueueWorkload`.

    This is the primary function to call when you want to produce `outputTensors` for `IRuntime.EnqueueWorkload`.
    The output is a list of tuples containing Tensors with a corresponding output tensor id.
    The output should be used directly with `IRuntime.EnqueueWorkload`.

    Examples:
        Creating outputTensors.
        &gt;&gt;&gt; import pyarmnn as ann
        &gt;&gt;&gt;
        &gt;&gt;&gt; parser = ann.ITfLiteParser()
        &gt;&gt;&gt; ...
        &gt;&gt;&gt; output_binding_info = parser.GetNetworkOutputBindingInfo(...)
        &gt;&gt;&gt;
        &gt;&gt;&gt; output_tensors = ann.make_output_tensors([output_binding_info])

    Args:
        outputs_binding_info (list of tuples): (int, `TensorInfo`) Binding information for output tensors obtained from `GetNetworkOutputBindingInfo`.

    Returns:
        list: `outputTensors` - A list of tuples (`int`, `Tensor`).
    &#34;&#34;&#34;
    output_tensors = []

    for out_bind_info in outputs_binding_info:
        out_tensor_id = out_bind_info[0]
        out_tensor_info = out_bind_info[1]
        output_tensors.append((out_tensor_id, Tensor(out_tensor_info)))

    return output_tensors</code></pre>
</details>
</dd>
<dt id="pyarmnn.quantize"><code class="name flex">
<span>def <span class="ident">quantize</span></span>(<span>value, scale, offset, target_dtype)</span>
</code></dt>
<dd>
<section class="desc"><p>Quantize given value to the given target datatype using Arm NN.</p>
<p>This function can be used to convert a 32-bit floating point value into 16/32-bit
integer or 8-bit unsigned integer values.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>value</code></strong> :&ensp;<code>float</code></dt>
<dd>The value to be quantized.</dd>
<dt><strong><code>scale</code></strong> :&ensp;<code>float</code></dt>
<dd>A numeric constant that the value is multiplied by.</dd>
<dt><strong><code>offset</code></strong> :&ensp;<code>int</code></dt>
<dd>A 'zero-point' used to 'shift' the integer range.</dd>
<dt><strong><code>target_dtype</code></strong> :&ensp;<code>str</code></dt>
<dd>The target data type. Supported values: 'unit8', 'int16', 'int32'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>A quantized 8-bit unsigned integer value or 16/32-bit integer value.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quantize(value: float, scale: float, offset: int, target_dtype: str) -&gt; int:
    &#34;&#34;&#34;Quantize given value to the given target datatype using Arm NN.

    This function can be used to convert a 32-bit floating point value into 16/32-bit
    integer or 8-bit unsigned integer values.

    Args:
        value (float): The value to be quantized.
        scale (float): A numeric constant that the value is multiplied by.
        offset (int): A &#39;zero-point&#39; used to &#39;shift&#39; the integer range.
        target_dtype (str): The target data type. Supported values: &#39;unit8&#39;, &#39;int16&#39;, &#39;int32&#39;.

    Returns:
        int: A quantized 8-bit unsigned integer value or 16/32-bit integer value.
    &#34;&#34;&#34;

    if target_dtype not in __dtype_to_quantize_function:
        raise ValueError(&#34;&#34;&#34;Unexpected target datatype {} given.
                         Armnn currently supports quantization to {} values.&#34;&#34;&#34;.format(target_dtype, list(__dtype_to_quantize_function.keys())))

    return __dtype_to_quantize_function[target_dtype](float(value), scale, offset)</code></pre>
</details>
</dd>
<dt id="pyarmnn.workload_tensors_to_ndarray"><code class="name flex">
<span>def <span class="ident">workload_tensors_to_ndarray</span></span>(<span>workload_tensors)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns a list of the underlying tensor data as ndarrays from <code>inputTensors</code> or <code>outputTensors</code>.</p>
<p>We refer to <code>inputTensors</code> and <code>outputTensors</code> as workload tensors because
they are used with <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.
Although this function can be used on either <code>inputTensors</code> or <code>outputTensors</code> the main use of this function
is to collect results from <code>outputTensors</code> after <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a> has been called.</p>
<h2 id="examples">Examples</h2>
<p>Getting results after inference.</p>
<pre><code>&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt;
&gt;&gt;&gt; ...
&gt;&gt;&gt; runtime = ann.IRuntime(...)
&gt;&gt;&gt; ...
&gt;&gt;&gt; runtime.EnqueueWorkload(net_id, input_tensors, output_tensors)
&gt;&gt;&gt;
&gt;&gt;&gt; inference_results = tensors_to_ndarray(output_tensors)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>workload_tensors</code></strong> :&ensp;<code>inputTensors</code> or <code>outputTensors</code></dt>
<dd><code>inputTensors</code> or <code>outputTensors</code> to get data from.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>List of <code>ndarrays</code> for the underlying tensor data from given <code>inputTensors</code> or <code>outputTensors</code>.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def workload_tensors_to_ndarray(workload_tensors: List[Tuple[int, Union[Tensor, ConstTensor]]]) -&gt; List[np.ndarray]:
    &#34;&#34;&#34;Returns a list of the underlying tensor data as ndarrays from `inputTensors` or `outputTensors`.

    We refer to `inputTensors` and `outputTensors` as workload tensors because
    they are used with `IRuntime.EnqueueWorkload`.
    Although this function can be used on either `inputTensors` or `outputTensors` the main use of this function
    is to collect results from `outputTensors` after `IRuntime.EnqueueWorkload` has been called.

    Examples:
        Getting results after inference.
        &gt;&gt;&gt; import pyarmnn as ann
        &gt;&gt;&gt;
        &gt;&gt;&gt; ...
        &gt;&gt;&gt; runtime = ann.IRuntime(...)
        &gt;&gt;&gt; ...
        &gt;&gt;&gt; runtime.EnqueueWorkload(net_id, input_tensors, output_tensors)
        &gt;&gt;&gt;
        &gt;&gt;&gt; inference_results = tensors_to_ndarray(output_tensors)

    Args:
        workload_tensors (inputTensors or outputTensors): `inputTensors` or `outputTensors` to get data from.

    Returns:
        list: List of `ndarrays` for the underlying tensor data from given `inputTensors` or `outputTensors`.
    &#34;&#34;&#34;
    arrays = []
    for index, (_, tensor) in enumerate(workload_tensors):
        arrays.append(tensor.get_memory_area())
        print(&#34;Workload tensor {} shape: {}&#34;.format(index, tensor.GetShape()))

    return arrays</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pyarmnn.ActivationDescriptor"><code class="flex name class">
<span>class <span class="ident">ActivationDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A configuration for the Activation layer. See <a title="pyarmnn.INetwork.AddActivationLayer" href="#pyarmnn.INetwork.AddActivationLayer"><code>INetwork.AddActivationLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Function</code></strong> :&ensp;<code>ActivationFunction</code></dt>
<dd>The activation function to use
(Sigmoid, TanH, Linear, ReLu, BoundedReLu, SoftReLu, LeakyReLu, Abs, Sqrt, Square).
Default: ActivationFunction_Sigmoid.</dd>
<dt><strong><code>m_A</code></strong> :&ensp;<code>float</code></dt>
<dd>Alpha upper bound value used by the activation functions. (BoundedReLu, Linear, TanH). Default: 0.</dd>
<dt><strong><code>m_B</code></strong> :&ensp;<code>float</code></dt>
<dd>Beta lower bound value used by the activation functions. (BoundedReLu, Linear, TanH). Default: 0.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ActivationDescriptor(object):
    r&#34;&#34;&#34;

    A configuration for the Activation layer. See `INetwork.AddActivationLayer()`.

    Contains:
        m_Function (ActivationFunction): The activation function to use
                                         (Sigmoid, TanH, Linear, ReLu, BoundedReLu, SoftReLu, LeakyReLu, Abs, Sqrt, Square).
                                         Default: ActivationFunction_Sigmoid.
        m_A (float): Alpha upper bound value used by the activation functions. (BoundedReLu, Linear, TanH). Default: 0.
        m_B (float): Beta lower bound value used by the activation functions. (BoundedReLu, Linear, TanH). Default: 0.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.ActivationDescriptor_swiginit(self, _pyarmnn.new_ActivationDescriptor())
    m_Function = property(_pyarmnn.ActivationDescriptor_m_Function_get, _pyarmnn.ActivationDescriptor_m_Function_set)
    m_A = property(_pyarmnn.ActivationDescriptor_m_A_get, _pyarmnn.ActivationDescriptor_m_A_set)
    m_B = property(_pyarmnn.ActivationDescriptor_m_B_get, _pyarmnn.ActivationDescriptor_m_B_set)
    __swig_destroy__ = _pyarmnn.delete_ActivationDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ActivationDescriptor.m_A"><code class="name">var <span class="ident">m_A</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ActivationDescriptor.m_B"><code class="name">var <span class="ident">m_B</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ActivationDescriptor.m_Function"><code class="name">var <span class="ident">m_Function</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ActivationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.BackendId"><code class="flex name class">
<span>class <span class="ident">BackendId</span></span>
<span>(</span><span>id)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates backend id instance.
Supported backend ids: 'CpuRef', 'CpuAcc', 'GpuAcc', 'NpuAcc'.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong> :&ensp;<code>str</code></dt>
<dd>Computation backend identification.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BackendId(object):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, id):
        r&#34;&#34;&#34;

        Creates backend id instance.
        Supported backend ids: &#39;CpuRef&#39;, &#39;CpuAcc&#39;, &#39;GpuAcc&#39;, &#39;NpuAcc&#39;.

        Args:
            id (str): Computation backend identification.

        &#34;&#34;&#34;
        _pyarmnn.BackendId_swiginit(self, _pyarmnn.new_BackendId(id))

    def IsCpuRef(self):
        r&#34;&#34;&#34;

        Checks if backend is cpu reference implementation.
        Returns:
            bool: True if backend supports cpu reference implementation, False otherwise.


        &#34;&#34;&#34;
        return _pyarmnn.BackendId_IsCpuRef(self)

    def Get(self):
        r&#34;&#34;&#34;

        Returns backend identification.

        &gt;&gt;&gt; backendId = BackendId(&#39;CpuRef&#39;)
        &gt;&gt;&gt; assert &#39;CpuRef&#39; == str(backendId)
        &gt;&gt;&gt; assert &#39;CpuRef&#39; == backendId.Get()

        Returns:
            str: Backend identification.


        &#34;&#34;&#34;
        return _pyarmnn.BackendId_Get(self)

    def __str__(self):
        return _pyarmnn.BackendId___str__(self)
    __swig_destroy__ = _pyarmnn.delete_BackendId</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.BackendId.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.BackendId.Get"><code class="name flex">
<span>def <span class="ident">Get</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns backend identification.</p>
<pre><code>&gt;&gt;&gt; backendId = BackendId('CpuRef')
&gt;&gt;&gt; assert 'CpuRef' == str(backendId)
&gt;&gt;&gt; assert 'CpuRef' == backendId.Get()
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>Backend identification.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Get(self):
    r&#34;&#34;&#34;

    Returns backend identification.

    &gt;&gt;&gt; backendId = BackendId(&#39;CpuRef&#39;)
    &gt;&gt;&gt; assert &#39;CpuRef&#39; == str(backendId)
    &gt;&gt;&gt; assert &#39;CpuRef&#39; == backendId.Get()

    Returns:
        str: Backend identification.


    &#34;&#34;&#34;
    return _pyarmnn.BackendId_Get(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.BackendId.IsCpuRef"><code class="name flex">
<span>def <span class="ident">IsCpuRef</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Checks if backend is cpu reference implementation.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>bool</code></strong></dt>
<dd>True if backend supports cpu reference implementation, False otherwise.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def IsCpuRef(self):
    r&#34;&#34;&#34;

    Checks if backend is cpu reference implementation.
    Returns:
        bool: True if backend supports cpu reference implementation, False otherwise.


    &#34;&#34;&#34;
    return _pyarmnn.BackendId_IsCpuRef(self)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.BatchNormalizationDescriptor"><code class="flex name class">
<span>class <span class="ident">BatchNormalizationDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the BatchNormalization layer.
See <a title="pyarmnn.INetwork.AddBatchNormalizationLayer" href="#pyarmnn.INetwork.AddBatchNormalizationLayer"><code>INetwork.AddBatchNormalizationLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Eps</code></strong> :&ensp;<code>float</code></dt>
<dd>Value to add to the variance. Used to avoid dividing by zero. Default: 0.0001f.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BatchNormalizationDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the BatchNormalization layer.  See `INetwork.AddBatchNormalizationLayer()`.

    Contains:
        m_Eps (float): Value to add to the variance. Used to avoid dividing by zero. Default: 0.0001f.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.BatchNormalizationDescriptor_swiginit(self, _pyarmnn.new_BatchNormalizationDescriptor())
    m_Eps = property(_pyarmnn.BatchNormalizationDescriptor_m_Eps_get, _pyarmnn.BatchNormalizationDescriptor_m_Eps_set)
    m_DataLayout = property(_pyarmnn.BatchNormalizationDescriptor_m_DataLayout_get, _pyarmnn.BatchNormalizationDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_BatchNormalizationDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.BatchNormalizationDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.BatchNormalizationDescriptor.m_Eps"><code class="name">var <span class="ident">m_Eps</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.BatchNormalizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor"><code class="flex name class">
<span>class <span class="ident">BatchToSpaceNdDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the BatchToSpaceNd layer.
See <a title="pyarmnn.INetwork.AddBatchToSpaceNdLayer" href="#pyarmnn.INetwork.AddBatchToSpaceNdLayer"><code>INetwork.AddBatchToSpaceNdLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_BlockShape</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>Block shape values. Default: (1, 1). Underlying C++ type is unsigned int.</dd>
<dt><strong><code>m_Crops</code></strong> :&ensp;<code>list</code> of <code>tuple</code></dt>
<dd>The values to crop from the input dimension. Default: [(0, 0), (0, 0)].</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BatchToSpaceNdDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the BatchToSpaceNd layer.  See `INetwork.AddBatchToSpaceNdLayer()`.

    Contains:
        m_BlockShape (list of int): Block shape values. Default: (1, 1). Underlying C++ type is unsigned int.

        m_Crops (list of tuple): The values to crop from the input dimension. Default: [(0, 0), (0, 0)].

        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.BatchToSpaceNdDescriptor_swiginit(self, _pyarmnn.new_BatchToSpaceNdDescriptor(*args))
    m_BlockShape = property(_pyarmnn.BatchToSpaceNdDescriptor_m_BlockShape_get, _pyarmnn.BatchToSpaceNdDescriptor_m_BlockShape_set)
    m_Crops = property(_pyarmnn.BatchToSpaceNdDescriptor_m_Crops_get, _pyarmnn.BatchToSpaceNdDescriptor_m_Crops_set)
    m_DataLayout = property(_pyarmnn.BatchToSpaceNdDescriptor_m_DataLayout_get, _pyarmnn.BatchToSpaceNdDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_BatchToSpaceNdDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.m_BlockShape"><code class="name">var <span class="ident">m_BlockShape</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.m_Crops"><code class="name">var <span class="ident">m_Crops</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.BatchToSpaceNdDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ConcatDescriptor"><code class="flex name class">
<span>class <span class="ident">ConcatDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates a configuration/descriptor for a Concatenation layer. See <a title="pyarmnn.INetwork.AddConcatLayer" href="#pyarmnn.INetwork.AddConcatLayer"><code>INetwork.AddConcatLayer()</code></a>.
Number of Views must be equal to the number of inputs, and their order must match e.g. first view corresponds to the first input, second view to the second input, etc.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>numViews</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of views, the value
must be equal to the number of outputs of a layer.</dd>
<dt><strong><code>numDimensions</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of dimensions. Default value is 4.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConcatDescriptor(object):
    r&#34;&#34;&#34;

    Creates a configuration/descriptor for a Concatenation layer. See `INetwork.AddConcatLayer()`.
    Number of Views must be equal to the number of inputs, and their order must match e.g. first view corresponds to the first input, second view to the second input, etc.

    Contains:
        numViews (int): Number of views, the value  must be equal to the number of outputs of a layer.
        numDimensions (int): Number of dimensions. Default value is 4.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.ConcatDescriptor_swiginit(self, _pyarmnn.new_ConcatDescriptor(*args))

    def GetNumViews(self):
        r&#34;&#34;&#34;

        Get the number of views.
        Returns:
            int: Number of views.

        &#34;&#34;&#34;
        return _pyarmnn.ConcatDescriptor_GetNumViews(self)

    def GetNumDimensions(self):
        r&#34;&#34;&#34;

        Get the number of dimensions.
        Returns:
            int: Number of dimensions.

        &#34;&#34;&#34;
        return _pyarmnn.ConcatDescriptor_GetNumDimensions(self)

    def GetViewOrigin(self, idx):
        r&#34;&#34;&#34;

        Get the view origin input by index.

        Each view match the inputs order, e.g. first view corresponds to the first input, second view to the second input, etc.

        Args:
            idx (int): Index to get view from.

        Returns:
            list: View origin (shape) specified by the int value `idx` as a list of ints.

        &#34;&#34;&#34;
        return _pyarmnn.ConcatDescriptor_GetViewOrigin(self, idx)

    def SetConcatAxis(self, concatAxis):
        r&#34;&#34;&#34;

        Set the concatenation dimension.
        Args:
            concatAxis (int): Concatenation axis index.

        &#34;&#34;&#34;
        return _pyarmnn.ConcatDescriptor_SetConcatAxis(self, concatAxis)

    def GetConcatAxis(self):
        r&#34;&#34;&#34;

        Get the concatenation dimension.
        Returns:
            int: Concatenation axis index.

        &#34;&#34;&#34;
        return _pyarmnn.ConcatDescriptor_GetConcatAxis(self)

    def SetViewOriginCoord(self, view, coord, value):
        r&#34;&#34;&#34;

        Set the coordinates of a specific origin view input.

        Args:
            view (int): Origin view index.
            coord (int): Coordinate of the origin view to set.
            value (int): Value to set.
        Raises:
            RuntimeError: If the `view` is greater than or equal to GetNumViews().
            RuntimeError: If the `coord` is greater than or equal to GetNumDimensions().

        &#34;&#34;&#34;
        return _pyarmnn.ConcatDescriptor_SetViewOriginCoord(self, view, coord, value)
    __swig_destroy__ = _pyarmnn.delete_ConcatDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ConcatDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ConcatDescriptor.GetConcatAxis"><code class="name flex">
<span>def <span class="ident">GetConcatAxis</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the concatenation dimension.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Concatenation axis index.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetConcatAxis(self):
    r&#34;&#34;&#34;

    Get the concatenation dimension.
    Returns:
        int: Concatenation axis index.

    &#34;&#34;&#34;
    return _pyarmnn.ConcatDescriptor_GetConcatAxis(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ConcatDescriptor.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the number of dimensions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Number of dimensions.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumDimensions(self):
    r&#34;&#34;&#34;

    Get the number of dimensions.
    Returns:
        int: Number of dimensions.

    &#34;&#34;&#34;
    return _pyarmnn.ConcatDescriptor_GetNumDimensions(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ConcatDescriptor.GetNumViews"><code class="name flex">
<span>def <span class="ident">GetNumViews</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the number of views.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Number of views.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumViews(self):
    r&#34;&#34;&#34;

    Get the number of views.
    Returns:
        int: Number of views.

    &#34;&#34;&#34;
    return _pyarmnn.ConcatDescriptor_GetNumViews(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ConcatDescriptor.GetViewOrigin"><code class="name flex">
<span>def <span class="ident">GetViewOrigin</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the view origin input by index.</p>
<p>Each view match the inputs order, e.g. first view corresponds to the first input, second view to the second input, etc.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index to get view from.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>View origin (shape) specified by the int value <code>idx</code> as a list of ints.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetViewOrigin(self, idx):
    r&#34;&#34;&#34;

    Get the view origin input by index.

    Each view match the inputs order, e.g. first view corresponds to the first input, second view to the second input, etc.

    Args:
        idx (int): Index to get view from.

    Returns:
        list: View origin (shape) specified by the int value `idx` as a list of ints.

    &#34;&#34;&#34;
    return _pyarmnn.ConcatDescriptor_GetViewOrigin(self, idx)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ConcatDescriptor.SetConcatAxis"><code class="name flex">
<span>def <span class="ident">SetConcatAxis</span></span>(<span>self, concatAxis)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the concatenation dimension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>concatAxis</code></strong> :&ensp;<code>int</code></dt>
<dd>Concatenation axis index.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetConcatAxis(self, concatAxis):
    r&#34;&#34;&#34;

    Set the concatenation dimension.
    Args:
        concatAxis (int): Concatenation axis index.

    &#34;&#34;&#34;
    return _pyarmnn.ConcatDescriptor_SetConcatAxis(self, concatAxis)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ConcatDescriptor.SetViewOriginCoord"><code class="name flex">
<span>def <span class="ident">SetViewOriginCoord</span></span>(<span>self, view, coord, value)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the coordinates of a specific origin view input.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>view</code></strong> :&ensp;<code>int</code></dt>
<dd>Origin view index.</dd>
<dt><strong><code>coord</code></strong> :&ensp;<code>int</code></dt>
<dd>Coordinate of the origin view to set.</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code></dt>
<dd>Value to set.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If the <code>view</code> is greater than or equal to GetNumViews().</dd>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If the <code>coord</code> is greater than or equal to GetNumDimensions().</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetViewOriginCoord(self, view, coord, value):
    r&#34;&#34;&#34;

    Set the coordinates of a specific origin view input.

    Args:
        view (int): Origin view index.
        coord (int): Coordinate of the origin view to set.
        value (int): Value to set.
    Raises:
        RuntimeError: If the `view` is greater than or equal to GetNumViews().
        RuntimeError: If the `coord` is greater than or equal to GetNumDimensions().

    &#34;&#34;&#34;
    return _pyarmnn.ConcatDescriptor_SetViewOriginCoord(self, view, coord, value)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ConstTensor"><code class="flex name class">
<span>class <span class="ident">ConstTensor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates a PyArmNN ConstTensor object.</p>
<p>A ConstTensor is a Tensor with an immutable data store. Typically, a ConstTensor
is used to input data into a network when running inference.</p>
<p>This class overrides the swig generated Tensor class. The aim of
this is to have an easy to use public API for the ConstTensor objects.</p>
<p>Supported tensor data types:
DataType_QuantisedAsymm8,
DataType_QuantisedSymm16,
DataType_Signed32,
DataType_Float32,
DataType_Float16</p>
<h2 id="examples">Examples</h2>
<p>Create empty ConstTensor</p>
<pre><code>&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt; ann.ConstTensor()
</code></pre>
<p>Create ConstTensor given tensor info and input data</p>
<pre><code>&gt;&gt;&gt; input_data = ... #  numpy array
&gt;&gt;&gt; ann.ConstTensor(ann.TensorInfo(...), input_data)
</code></pre>
<p>Create ConstTensor from another ConstTensor i.e. copy ConstTensor</p>
<pre><code>&gt;&gt;&gt; ann.ConstTensor(ann.ConstTensor())
</code></pre>
<p>Create ConstTensor from tensor</p>
<pre><code>&gt;&gt;&gt; ann.ConstTensor(ann.Tensor())
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<a title="pyarmnn.Tensor" href="#pyarmnn.Tensor"><code>Tensor</code></a>, optional</dt>
<dd>Create a ConstTensor from a Tensor.</dd>
<dt><strong><code>const_tensor</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a>, optional</dt>
<dd>Create a ConstTensor from a ConstTensor i.e. copy.</dd>
<dt><strong><code>tensor_info</code></strong> :&ensp;<a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>, optional</dt>
<dd>Tensor information.</dd>
<dt><strong><code>input_data</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>Numpy array. The numpy array will be transformed to a
buffer according to type returned by <a title="pyarmnn.TensorInfo.GetDataType" href="#pyarmnn.TensorInfo.GetDataType"><code>TensorInfo.GetDataType()</code></a>.
Input data values type must correspond to data type returned by
<a title="pyarmnn.TensorInfo.GetDataType" href="#pyarmnn.TensorInfo.GetDataType"><code>TensorInfo.GetDataType()</code></a>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>TypeError</code></strong></dt>
<dd>Unsupported input data type.</dd>
<dt><strong><code>ValueError</code></strong></dt>
<dd>Unsupported tensor data type and incorrect input data size.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConstTensor(AnnConstTensor):
    &#34;&#34;&#34;Creates a PyArmNN ConstTensor object.

    A ConstTensor is a Tensor with an immutable data store. Typically, a ConstTensor
    is used to input data into a network when running inference.

    This class overrides the swig generated Tensor class. The aim of
    this is to have an easy to use public API for the ConstTensor objects.

    &#34;&#34;&#34;

    def __init__(self, *args):
        &#34;&#34;&#34;
        Supported tensor data types:
            DataType_QuantisedAsymm8,
            DataType_QuantisedSymm16,
            DataType_Signed32,
            DataType_Float32,
            DataType_Float16

        Examples:
            Create empty ConstTensor
            &gt;&gt;&gt; import pyarmnn as ann
            &gt;&gt;&gt; ann.ConstTensor()

            Create ConstTensor given tensor info and input data
            &gt;&gt;&gt; input_data = ... #  numpy array
            &gt;&gt;&gt; ann.ConstTensor(ann.TensorInfo(...), input_data)

            Create ConstTensor from another ConstTensor i.e. copy ConstTensor
            &gt;&gt;&gt; ann.ConstTensor(ann.ConstTensor())

            Create ConstTensor from tensor
            &gt;&gt;&gt; ann.ConstTensor(ann.Tensor())

        Args:
            tensor (Tensor, optional): Create a ConstTensor from a Tensor.
            const_tensor (ConstTensor, optional): Create a ConstTensor from a ConstTensor i.e. copy.
            tensor_info (TensorInfo, optional): Tensor information.
            input_data (ndarray):   Numpy array. The numpy array will be transformed to a
                                    buffer according to type returned by `TensorInfo.GetDataType`.
                                    Input data values type must correspond to data type returned by
                                    `TensorInfo.GetDataType`.

        Raises:
            TypeError: Unsupported input data type.
            ValueError: Unsupported tensor data type and incorrect input data size.
        &#34;&#34;&#34;
        self.__memory_area = None

        # TensorInfo as first argument and numpy array as second
        if len(args) &gt; 1 and isinstance(args[0], TensorInfo):
            if isinstance(args[1], np.ndarray):
                self.__create_memory_area(args[0].GetDataType(), args[0].GetNumBytes(), args[0].GetNumElements(),
                                          args[1])
                super().__init__(args[0], self.__memory_area.data)
            else:
                raise TypeError(&#39;Data must be provided as a numpy array.&#39;)

        # copy constructor - reference to memory area is passed from copied const
        # tensor and armnn&#39;s copy constructor is called
        elif len(args) &gt; 0 and isinstance(args[0], (ConstTensor, Tensor)):
            self.__memory_area = args[0].get_memory_area()
            super().__init__(args[0])

        # empty tensor
        elif len(args) == 0:
            super().__init__()

        else:
            raise ValueError(&#39;Incorrect number of arguments or type of arguments provided to create Const Tensor.&#39;)

    def __copy__(self) -&gt; &#39;ConstTensor&#39;:
        &#34;&#34;&#34; Make copy of a const tensor.

        Make const tensor copyable using the python copy operation.

        Note:
            The tensor memory area is NOT copied. Instead, the new tensor maintains a
            reference to the same memory area as the old tensor.

        Example:
            Copy empty tensor
            &gt;&gt;&gt; from copy import copy
            &gt;&gt;&gt; import pyarmnn as ann
            &gt;&gt;&gt; tensor = ann.ConstTensor()
            &gt;&gt;&gt; copied_tensor = copy(tensor)

        Returns:
            Tensor: a copy of the tensor object provided.

        &#34;&#34;&#34;
        return ConstTensor(self)

    @staticmethod
    def __check_size(data: np.ndarray, num_bytes: int, num_elements: int):
        &#34;&#34;&#34; Check the size of the input data against the number of bytes provided by tensor info.

        Args:
            data (ndarray): Input data.
            num_bytes (int): Number of bytes required by tensor info.
            num_elements: Number of elements required by tensor info.

        Raises:
            ValueError: number of bytes in input data does not match tensor info.

        &#34;&#34;&#34;
        size_in_bytes = data.nbytes
        elements = data.size

        if size_in_bytes != num_bytes:
            raise ValueError(
                &#34;ConstTensor requires {} bytes, {} provided. &#34;
                &#34;Is your input array data type ({}) aligned with TensorInfo?&#34;.format(num_bytes, size_in_bytes,
                                                                                     data.dtype))
        elif elements != num_elements:
            raise ValueError(&#34;ConstTensor requires {} elements, {} provided.&#34;.format(num_elements, elements))

    def __create_memory_area(self, data_type: int, num_bytes: int, num_elements: int, data: np.ndarray):
        &#34;&#34;&#34; Create the memory area used by the tensor to output its results.

        Args:
            data_type (int): The type of data that will be stored in the memory area.
                             See DataType_*.
            num_bytes (int): Determines the size of the memory area that will be created.
            num_elements (int): Determines number of elements in memory area.
            data (ndarray): Input data as numpy array.

        &#34;&#34;&#34;
        np_data_type_mapping = {DataType_QuantisedAsymm8: np.uint8,
                                DataType_Float32: np.float32,
                                DataType_QuantisedSymm16: np.int16,
                                DataType_Signed32: np.int32,
                                DataType_Float16: np.float16}

        if data_type not in np_data_type_mapping:
            raise ValueError(&#34;The data type provided for this Tensor is not supported: {}&#34;.format(data_type))

        self.__check_size(data, num_bytes, num_elements)
        self.__memory_area = data
        self.__memory_area.flags.writeable = False

    def get_memory_area(self) -&gt; np.ndarray:
        &#34;&#34;&#34; Get values that are stored by the tensor.

        Returns:
             ndarray: Tensor data (as numpy array).

        &#34;&#34;&#34;
        return self.__memory_area</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pyarmnn._generated.pyarmnn.ConstTensor</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ConstTensor.get_memory_area"><code class="name flex">
<span>def <span class="ident">get_memory_area</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get values that are stored by the tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ndarray</code></strong></dt>
<dd>Tensor data (as numpy array).</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_memory_area(self) -&gt; np.ndarray:
    &#34;&#34;&#34; Get values that are stored by the tensor.

    Returns:
         ndarray: Tensor data (as numpy array).

    &#34;&#34;&#34;
    return self.__memory_area</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor"><code class="flex name class">
<span>class <span class="ident">Convolution2dDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Convolution2d layer.
See <a title="pyarmnn.INetwork.AddConvolution2dLayer" href="#pyarmnn.INetwork.AddConvolution2dLayer"><code>INetwork.AddConvolution2dLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_PadLeft</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadRight</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadTop</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_PadBottom</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_StrideX</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.</dd>
<dt><strong><code>m_StrideY</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.</dd>
<dt><strong><code>m_DilationX</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Dilation along x axis. Default: 1.</dd>
<dt><strong><code>m_DilationY</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Dilation along y axis. Default: 1.</dd>
<dt><strong><code>m_BiasEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable bias. Default: false.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Convolution2dDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Convolution2d layer.  See `INetwork.AddConvolution2dLayer()`.

    Contains:
        m_PadLeft (int): Underlying C++ data type is `uint32_t`. Padding left value in the width dimension. Default: 0.
        m_PadRight (int): Underlying C++ data type is `uint32_t`. Padding right value in the width dimension. Default: 0.
        m_PadTop (int): Underlying C++ data type is `uint32_t`. Padding top value in the height dimension. Default: 0.
        m_PadBottom (int): Underlying C++ data type is `uint32_t`. Padding bottom value in the height dimension. Default: 0.
        m_StrideX (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the width dimension. Default: 0.
        m_StrideY (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the height dimension. Default: 0.
        m_DilationX (int): Underlying C++ data type is `uint32_t`. Dilation along x axis. Default: 1.
        m_DilationY (int): Underlying C++ data type is `uint32_t`. Dilation along y axis. Default: 1.
        m_BiasEnabled (bool): Enable/disable bias. Default: false.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.Convolution2dDescriptor_swiginit(self, _pyarmnn.new_Convolution2dDescriptor())
    m_PadLeft = property(_pyarmnn.Convolution2dDescriptor_m_PadLeft_get, _pyarmnn.Convolution2dDescriptor_m_PadLeft_set)
    m_PadRight = property(_pyarmnn.Convolution2dDescriptor_m_PadRight_get, _pyarmnn.Convolution2dDescriptor_m_PadRight_set)
    m_PadTop = property(_pyarmnn.Convolution2dDescriptor_m_PadTop_get, _pyarmnn.Convolution2dDescriptor_m_PadTop_set)
    m_PadBottom = property(_pyarmnn.Convolution2dDescriptor_m_PadBottom_get, _pyarmnn.Convolution2dDescriptor_m_PadBottom_set)
    m_StrideX = property(_pyarmnn.Convolution2dDescriptor_m_StrideX_get, _pyarmnn.Convolution2dDescriptor_m_StrideX_set)
    m_StrideY = property(_pyarmnn.Convolution2dDescriptor_m_StrideY_get, _pyarmnn.Convolution2dDescriptor_m_StrideY_set)
    m_DilationX = property(_pyarmnn.Convolution2dDescriptor_m_DilationX_get, _pyarmnn.Convolution2dDescriptor_m_DilationX_set)
    m_DilationY = property(_pyarmnn.Convolution2dDescriptor_m_DilationY_get, _pyarmnn.Convolution2dDescriptor_m_DilationY_set)
    m_BiasEnabled = property(_pyarmnn.Convolution2dDescriptor_m_BiasEnabled_get, _pyarmnn.Convolution2dDescriptor_m_BiasEnabled_set)
    m_DataLayout = property(_pyarmnn.Convolution2dDescriptor_m_DataLayout_get, _pyarmnn.Convolution2dDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_Convolution2dDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.Convolution2dDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_DilationX"><code class="name">var <span class="ident">m_DilationX</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_DilationY"><code class="name">var <span class="ident">m_DilationY</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Convolution2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.CreationOptions"><code class="flex name class">
<span>class <span class="ident">CreationOptions</span></span>
</code></dt>
<dd>
<section class="desc"><p>Structure for holding creation options. For majority of cases it is fine to leave values at default.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_GpuAccTunedParameters</code></strong> :&ensp;<code>IGpuAccTunedParameters</code></dt>
<dd>If set, uses the GpuAcc tuned parameters from the given object
when executing GPU workloads. It will also be updated with new
tuned parameters if it is configured to do so.</dd>
<dt><strong><code>m_EnableGpuProfiling</code></strong> :&ensp;<code>bool</code></dt>
<dd>Setting this flag will allow the user to obtain GPU profiling information from
the runtime.</dd>
<dt><strong><code>m_DynamicBackendsPath</code></strong> :&ensp;<code>string</code></dt>
<dd>Setting this value will override the paths set by the DYNAMIC_BACKEND_PATHS
compiler directive. Only a single path is allowed for the override.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CreationOptions(object):
    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        r&#34;&#34;&#34;

        Structure for holding creation options. For majority of cases it is fine to leave values at default.

        Contains:
            m_GpuAccTunedParameters (IGpuAccTunedParameters): If set, uses the GpuAcc tuned parameters from the given object
                                                              when executing GPU workloads. It will also be updated with new
                                                              tuned parameters if it is configured to do so.

            m_EnableGpuProfiling (bool): Setting this flag will allow the user to obtain GPU profiling information from
                                         the runtime.

            m_DynamicBackendsPath (string): Setting this value will override the paths set by the DYNAMIC_BACKEND_PATHS
                                            compiler directive. Only a single path is allowed for the override.


        &#34;&#34;&#34;
        _pyarmnn.CreationOptions_swiginit(self, _pyarmnn.new_CreationOptions())
    m_GpuAccTunedParameters = property(_pyarmnn.CreationOptions_m_GpuAccTunedParameters_get, _pyarmnn.CreationOptions_m_GpuAccTunedParameters_set)
    m_EnableGpuProfiling = property(_pyarmnn.CreationOptions_m_EnableGpuProfiling_get, _pyarmnn.CreationOptions_m_EnableGpuProfiling_set)
    m_DynamicBackendsPath = property(_pyarmnn.CreationOptions_m_DynamicBackendsPath_get, _pyarmnn.CreationOptions_m_DynamicBackendsPath_set)
    __swig_destroy__ = _pyarmnn.delete_CreationOptions</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.CreationOptions.m_DynamicBackendsPath"><code class="name">var <span class="ident">m_DynamicBackendsPath</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.CreationOptions.m_EnableGpuProfiling"><code class="name">var <span class="ident">m_EnableGpuProfiling</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.CreationOptions.m_GpuAccTunedParameters"><code class="name">var <span class="ident">m_GpuAccTunedParameters</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.CreationOptions.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor"><code class="flex name class">
<span>class <span class="ident">DepthwiseConvolution2dDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the DepthwiseConvolution2d layer. See <a title="pyarmnn.INetwork.AddDepthwiseConvolution2dLayer" href="#pyarmnn.INetwork.AddDepthwiseConvolution2dLayer"><code>INetwork.AddDepthwiseConvolution2dLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_PadLeft</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadRight</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadTop</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_PadBottom</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_StrideX</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.</dd>
<dt><strong><code>m_StrideY</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.</dd>
<dt><strong><code>m_DilationX</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Dilation along x axis. Default: 1.</dd>
<dt><strong><code>m_DilationY</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Dilation along y axis. Default: 1.</dd>
<dt><strong><code>m_BiasEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable bias. Default: false.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DepthwiseConvolution2dDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the DepthwiseConvolution2d layer. See `INetwork.AddDepthwiseConvolution2dLayer()`.

    Contains:
        m_PadLeft (int): Underlying C++ data type is `uint32_t`. Padding left value in the width dimension. Default: 0.
        m_PadRight (int): Underlying C++ data type is `uint32_t`. Padding right value in the width dimension. Default: 0.
        m_PadTop (int): Underlying C++ data type is `uint32_t`. Padding top value in the height dimension. Default: 0.
        m_PadBottom (int): Underlying C++ data type is `uint32_t`. Padding bottom value in the height dimension. Default: 0.
        m_StrideX (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the width dimension. Default: 0.
        m_StrideY (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the height dimension. Default: 0.
        m_DilationX (int): Underlying C++ data type is `uint32_t`. Dilation along x axis. Default: 1.
        m_DilationY (int): Underlying C++ data type is `uint32_t`. Dilation along y axis. Default: 1.
        m_BiasEnabled (bool): Enable/disable bias. Default: false.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.DepthwiseConvolution2dDescriptor_swiginit(self, _pyarmnn.new_DepthwiseConvolution2dDescriptor())
    m_PadLeft = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_PadLeft_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_PadLeft_set)
    m_PadRight = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_PadRight_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_PadRight_set)
    m_PadTop = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_PadTop_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_PadTop_set)
    m_PadBottom = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_PadBottom_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_PadBottom_set)
    m_StrideX = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_StrideX_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_StrideX_set)
    m_StrideY = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_StrideY_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_StrideY_set)
    m_DilationX = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_DilationX_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_DilationX_set)
    m_DilationY = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_DilationY_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_DilationY_set)
    m_BiasEnabled = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_BiasEnabled_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_BiasEnabled_set)
    m_DataLayout = property(_pyarmnn.DepthwiseConvolution2dDescriptor_m_DataLayout_get, _pyarmnn.DepthwiseConvolution2dDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_DepthwiseConvolution2dDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationX"><code class="name">var <span class="ident">m_DilationX</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationY"><code class="name">var <span class="ident">m_DilationY</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DepthwiseConvolution2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor"><code class="flex name class">
<span>class <span class="ident">DetectionPostProcessDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the DetectionPostProcess layer. See <a title="pyarmnn.INetwork.AddDetectionPostProcessLayer" href="#pyarmnn.INetwork.AddDetectionPostProcessLayer"><code>INetwork.AddDetectionPostProcessLayer()</code></a>.</p>
<p>This layer is a custom layer used to process the output from SSD MobilenetV1.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_MaxDetections</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Maximum numbers of detections. Default: 0.</dd>
<dt><strong><code>m_MaxClassesPerDetection</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Maximum numbers of classes per detection, used in Fast NMS. Default: 1.</dd>
<dt><strong><code>m_DetectionsPerClass</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Detections per classes, used in Regular NMS. Default: 1.</dd>
<dt><strong><code>m_NmsScoreThreshold</code></strong> :&ensp;<code>float</code></dt>
<dd>Non maximum suppression score threshold. Default: 0.</dd>
<dt><strong><code>m_NmsIouThreshold</code></strong> :&ensp;<code>float</code></dt>
<dd>Intersection over union threshold. Default: 0.</dd>
<dt><strong><code>m_NumClasses</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Number of classes. Default: 0.</dd>
<dt><strong><code>m_UseRegularNms</code></strong> :&ensp;<code>bool</code></dt>
<dd>Use Regular Non maximum suppression. Default: false.</dd>
<dt><strong><code>m_ScaleX</code></strong> :&ensp;<code>float</code></dt>
<dd>Center size encoding scale x. Default: 0.</dd>
<dt><strong><code>m_ScaleY</code></strong> :&ensp;<code>float</code></dt>
<dd>Center size encoding scale y. Default: 0.</dd>
<dt><strong><code>m_ScaleW</code></strong> :&ensp;<code>float</code></dt>
<dd>Center size encoding scale weight. Default: 0.</dd>
<dt><strong><code>m_ScaleH</code></strong> :&ensp;<code>float</code></dt>
<dd>Center size encoding scale height. Default: 0.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DetectionPostProcessDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the DetectionPostProcess layer. See `INetwork.AddDetectionPostProcessLayer()`.

    This layer is a custom layer used to process the output from SSD MobilenetV1.

    Contains:
        m_MaxDetections (int): Underlying C++ data type is `uint32_t`. Maximum numbers of detections. Default: 0.
        m_MaxClassesPerDetection (int): Underlying C++ data type is `uint32_t`. Maximum numbers of classes per detection, used in Fast NMS. Default: 1.
        m_DetectionsPerClass (int): Underlying C++ data type is `uint32_t`. Detections per classes, used in Regular NMS. Default: 1.
        m_NmsScoreThreshold (float): Non maximum suppression score threshold. Default: 0.
        m_NmsIouThreshold (float): Intersection over union threshold. Default: 0.
        m_NumClasses (int): Underlying C++ data type is `uint32_t`. Number of classes. Default: 0.
        m_UseRegularNms (bool): Use Regular Non maximum suppression. Default: false.
        m_ScaleX (float): Center size encoding scale x. Default: 0.
        m_ScaleY (float): Center size encoding scale y. Default: 0.
        m_ScaleW (float): Center size encoding scale weight. Default: 0.
        m_ScaleH (float): Center size encoding scale height. Default: 0.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.DetectionPostProcessDescriptor_swiginit(self, _pyarmnn.new_DetectionPostProcessDescriptor())
    m_MaxDetections = property(_pyarmnn.DetectionPostProcessDescriptor_m_MaxDetections_get, _pyarmnn.DetectionPostProcessDescriptor_m_MaxDetections_set)
    m_MaxClassesPerDetection = property(_pyarmnn.DetectionPostProcessDescriptor_m_MaxClassesPerDetection_get, _pyarmnn.DetectionPostProcessDescriptor_m_MaxClassesPerDetection_set)
    m_DetectionsPerClass = property(_pyarmnn.DetectionPostProcessDescriptor_m_DetectionsPerClass_get, _pyarmnn.DetectionPostProcessDescriptor_m_DetectionsPerClass_set)
    m_NmsScoreThreshold = property(_pyarmnn.DetectionPostProcessDescriptor_m_NmsScoreThreshold_get, _pyarmnn.DetectionPostProcessDescriptor_m_NmsScoreThreshold_set)
    m_NmsIouThreshold = property(_pyarmnn.DetectionPostProcessDescriptor_m_NmsIouThreshold_get, _pyarmnn.DetectionPostProcessDescriptor_m_NmsIouThreshold_set)
    m_NumClasses = property(_pyarmnn.DetectionPostProcessDescriptor_m_NumClasses_get, _pyarmnn.DetectionPostProcessDescriptor_m_NumClasses_set)
    m_UseRegularNms = property(_pyarmnn.DetectionPostProcessDescriptor_m_UseRegularNms_get, _pyarmnn.DetectionPostProcessDescriptor_m_UseRegularNms_set)
    m_ScaleX = property(_pyarmnn.DetectionPostProcessDescriptor_m_ScaleX_get, _pyarmnn.DetectionPostProcessDescriptor_m_ScaleX_set)
    m_ScaleY = property(_pyarmnn.DetectionPostProcessDescriptor_m_ScaleY_get, _pyarmnn.DetectionPostProcessDescriptor_m_ScaleY_set)
    m_ScaleW = property(_pyarmnn.DetectionPostProcessDescriptor_m_ScaleW_get, _pyarmnn.DetectionPostProcessDescriptor_m_ScaleW_set)
    m_ScaleH = property(_pyarmnn.DetectionPostProcessDescriptor_m_ScaleH_get, _pyarmnn.DetectionPostProcessDescriptor_m_ScaleH_set)
    __swig_destroy__ = _pyarmnn.delete_DetectionPostProcessDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_DetectionsPerClass"><code class="name">var <span class="ident">m_DetectionsPerClass</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_MaxClassesPerDetection"><code class="name">var <span class="ident">m_MaxClassesPerDetection</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_MaxDetections"><code class="name">var <span class="ident">m_MaxDetections</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_NmsIouThreshold"><code class="name">var <span class="ident">m_NmsIouThreshold</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_NmsScoreThreshold"><code class="name">var <span class="ident">m_NmsScoreThreshold</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_NumClasses"><code class="name">var <span class="ident">m_NumClasses</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleH"><code class="name">var <span class="ident">m_ScaleH</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleW"><code class="name">var <span class="ident">m_ScaleW</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleX"><code class="name">var <span class="ident">m_ScaleX</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_ScaleY"><code class="name">var <span class="ident">m_ScaleY</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.m_UseRegularNms"><code class="name">var <span class="ident">m_UseRegularNms</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.DetectionPostProcessDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.FakeQuantizationDescriptor"><code class="flex name class">
<span>class <span class="ident">FakeQuantizationDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the FakeQuantization layer. See ``.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Min</code></strong> :&ensp;<code>float</code></dt>
<dd>Minimum value for quantization range. Default: -6.0.</dd>
<dt><strong><code>m_Max</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum value for quantization range. Default: 6.0.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FakeQuantizationDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the FakeQuantization layer. See ``.

    Contains:
        m_Min (float): Minimum value for quantization range. Default: -6.0.
        m_Max (float): Maximum value for quantization range. Default: 6.0.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.FakeQuantizationDescriptor_swiginit(self, _pyarmnn.new_FakeQuantizationDescriptor())
    m_Min = property(_pyarmnn.FakeQuantizationDescriptor_m_Min_get, _pyarmnn.FakeQuantizationDescriptor_m_Min_set)
    m_Max = property(_pyarmnn.FakeQuantizationDescriptor_m_Max_get, _pyarmnn.FakeQuantizationDescriptor_m_Max_set)
    __swig_destroy__ = _pyarmnn.delete_FakeQuantizationDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.FakeQuantizationDescriptor.m_Max"><code class="name">var <span class="ident">m_Max</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.FakeQuantizationDescriptor.m_Min"><code class="name">var <span class="ident">m_Min</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.FakeQuantizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.FullyConnectedDescriptor"><code class="flex name class">
<span>class <span class="ident">FullyConnectedDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the FullyConnected layer. See <a title="pyarmnn.INetwork.AddFullyConnectedLayer" href="#pyarmnn.INetwork.AddFullyConnectedLayer"><code>INetwork.AddFullyConnectedLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_BiasEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable bias. Default: false.</dd>
<dt><strong><code>m_TransposeWeightMatrix</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable transpose weight matrix. Default: false.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FullyConnectedDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the FullyConnected layer. See `INetwork.AddFullyConnectedLayer()`.

    Contains:
        m_BiasEnabled (bool): Enable/disable bias. Default: false.
        m_TransposeWeightMatrix (bool): Enable/disable transpose weight matrix. Default: false.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.FullyConnectedDescriptor_swiginit(self, _pyarmnn.new_FullyConnectedDescriptor())
    m_BiasEnabled = property(_pyarmnn.FullyConnectedDescriptor_m_BiasEnabled_get, _pyarmnn.FullyConnectedDescriptor_m_BiasEnabled_set)
    m_TransposeWeightMatrix = property(_pyarmnn.FullyConnectedDescriptor_m_TransposeWeightMatrix_get, _pyarmnn.FullyConnectedDescriptor_m_TransposeWeightMatrix_set)
    __swig_destroy__ = _pyarmnn.delete_FullyConnectedDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.FullyConnectedDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.FullyConnectedDescriptor.m_TransposeWeightMatrix"><code class="name">var <span class="ident">m_TransposeWeightMatrix</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.FullyConnectedDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ICaffeParser"><code class="flex name class">
<span>class <span class="ident">ICaffeParser</span></span>
</code></dt>
<dd>
<section class="desc"><p>Interface for creating a parser object using Caffe (<a href="http://caffe.berkeleyvision.org/">http://caffe.berkeleyvision.org/</a>) caffemodel files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ICaffeParser(object):
    r&#34;&#34;&#34;

    Interface for creating a parser object using Caffe (http://caffe.berkeleyvision.org/) caffemodel files.

    Parsers are used to automatically construct Arm NN graphs from model files.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def GetNetworkInputBindingInfo(self, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.

        Args:
            name (str): Name of the input.

        Returns:
            tuple: (`int`, `TensorInfo`)

        &#34;&#34;&#34;
        return _pyarmnn_caffeparser.ICaffeParser_GetNetworkInputBindingInfo(self, name)

    def GetNetworkOutputBindingInfo(self, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.

        Args:
            name (str): Name of the output.

        Returns:
            tuple: (`int`, `TensorInfo`)

        &#34;&#34;&#34;
        return _pyarmnn_caffeparser.ICaffeParser_GetNetworkOutputBindingInfo(self, name)

    def __init__(self):
        _pyarmnn_caffeparser.ICaffeParser_swiginit(self, _pyarmnn_caffeparser.new_ICaffeParser())
    __swig_destroy__ = _pyarmnn_caffeparser.delete_ICaffeParser

    def CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs):
        r&#34;&#34;&#34;

        Create the network from a Caffe caffemodel binary file on disk.

        Args:
            graphFile: Path to the caffe model to be parsed.
            inputShapes (tuple): (`string`, `TensorShape`) A tuple containing the input name and TensorShape information for the network.
            requestedOutputs (list): A list of the output tensor names.

        Returns:
            INetwork: INetwork object for the parsed Caffe model.

        &#34;&#34;&#34;
        return _pyarmnn_caffeparser.ICaffeParser_CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ICaffeParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ICaffeParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile, inputShapes, requestedOutputs)</span>
</code></dt>
<dd>
<section class="desc"><p>Create the network from a Caffe caffemodel binary file on disk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong></dt>
<dd>Path to the caffe model to be parsed.</dd>
<dt><strong><code>inputShapes</code></strong> :&ensp;<code>tuple</code></dt>
<dd>(<code>string</code>, <a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape"><code>TensorShape</code></a>) A tuple containing the input name and TensorShape information for the network.</dd>
<dt><strong><code>requestedOutputs</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of the output tensor names.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork"><code>INetwork</code></a></strong></dt>
<dd>INetwork object for the parsed Caffe model.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs):
    r&#34;&#34;&#34;

    Create the network from a Caffe caffemodel binary file on disk.

    Args:
        graphFile: Path to the caffe model to be parsed.
        inputShapes (tuple): (`string`, `TensorShape`) A tuple containing the input name and TensorShape information for the network.
        requestedOutputs (list): A list of the output tensor names.

    Returns:
        INetwork: INetwork object for the parsed Caffe model.

    &#34;&#34;&#34;
    return _pyarmnn_caffeparser.ICaffeParser_CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ICaffeParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the input.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkInputBindingInfo(self, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.

    Args:
        name (str): Name of the input.

    Returns:
        tuple: (`int`, `TensorInfo`)

    &#34;&#34;&#34;
    return _pyarmnn_caffeparser.ICaffeParser_GetNetworkInputBindingInfo(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ICaffeParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the output.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkOutputBindingInfo(self, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.

    Args:
        name (str): Name of the output.

    Returns:
        tuple: (`int`, `TensorInfo`)

    &#34;&#34;&#34;
    return _pyarmnn_caffeparser.ICaffeParser_GetNetworkOutputBindingInfo(self, name)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IConnectableLayer"><code class="flex name class">
<span>class <span class="ident">IConnectableLayer</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Interface for a layer that is connectable to other layers via <a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot"><code>IInputSlot</code></a> and <a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot"><code>IOutputSlot</code></a>.
The object implementing this interface is returned by <a title="pyarmnn.INetwork" href="#pyarmnn.INetwork"><code>INetwork</code></a> when calling <code>add*Layer</code> methods.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IConnectableLayer(object):
    r&#34;&#34;&#34;

    Interface for a layer that is connectable to other layers via `IInputSlot` and `IOutputSlot`.
    The object implementing this interface is returned by `INetwork` when calling `add*Layer` methods.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)

    def __init__(self, *args, **kwargs):
        raise AttributeError(&#34;No constructor defined&#34;)
    __repr__ = _swig_repr

    def GetName(self):
        r&#34;&#34;&#34;

        Returns the name of the layer. Name attribute is optional for a layer, thus
        `None` value could be returned.

        Returns:
            str: Layer name or `None`.


        &#34;&#34;&#34;
        return _pyarmnn.IConnectableLayer_GetName(self)

    def GetNumInputSlots(self):
        r&#34;&#34;&#34;

        Gets the number of input slots for the layer.

        Returns:
            int: Number of input slots.


        &#34;&#34;&#34;
        return _pyarmnn.IConnectableLayer_GetNumInputSlots(self)

    def GetNumOutputSlots(self):
        r&#34;&#34;&#34;

        Gets the number of output slots for the layer.

        Returns:
            int: Number of output slots.


        &#34;&#34;&#34;
        return _pyarmnn.IConnectableLayer_GetNumOutputSlots(self)

    def GetInputSlot(self, index):
        r&#34;&#34;&#34;

        Gets the input slot by index.

        Args:
            index (int): Slot index.

        Returns:
            IInputSlot: Borrowed reference to input slot.


        &#34;&#34;&#34;
        return _pyarmnn.IConnectableLayer_GetInputSlot(self, index)

    def GetOutputSlot(self, index):
        r&#34;&#34;&#34;

        Gets the output slot by index.

        Args:
            index (int): Slot index.

        Returns:
            IOutputSlot: Borrowed reference to output slot.


        &#34;&#34;&#34;
        return _pyarmnn.IConnectableLayer_GetOutputSlot(self, index)

    def GetGuid(self):
        r&#34;&#34;&#34;

        Gets the unique layer id (within one process).
        Guid is generated and assigned automatically when the layer is created.

        Returns:
            int: The unique layer id.


        &#34;&#34;&#34;
        return _pyarmnn.IConnectableLayer_GetGuid(self)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IConnectableLayer.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IConnectableLayer.GetGuid"><code class="name flex">
<span>def <span class="ident">GetGuid</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the unique layer id (within one process).
Guid is generated and assigned automatically when the layer is created.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>The unique layer id.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetGuid(self):
    r&#34;&#34;&#34;

    Gets the unique layer id (within one process).
    Guid is generated and assigned automatically when the layer is created.

    Returns:
        int: The unique layer id.


    &#34;&#34;&#34;
    return _pyarmnn.IConnectableLayer_GetGuid(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetInputSlot"><code class="name flex">
<span>def <span class="ident">GetInputSlot</span></span>(<span>self, index)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the input slot by index.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>Slot index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot"><code>IInputSlot</code></a></strong></dt>
<dd>Borrowed reference to input slot.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetInputSlot(self, index):
    r&#34;&#34;&#34;

    Gets the input slot by index.

    Args:
        index (int): Slot index.

    Returns:
        IInputSlot: Borrowed reference to input slot.


    &#34;&#34;&#34;
    return _pyarmnn.IConnectableLayer_GetInputSlot(self, index)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetName"><code class="name flex">
<span>def <span class="ident">GetName</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the name of the layer. Name attribute is optional for a layer, thus
<code>None</code> value could be returned.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>Layer name or <code>None</code>.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetName(self):
    r&#34;&#34;&#34;

    Returns the name of the layer. Name attribute is optional for a layer, thus
    `None` value could be returned.

    Returns:
        str: Layer name or `None`.


    &#34;&#34;&#34;
    return _pyarmnn.IConnectableLayer_GetName(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetNumInputSlots"><code class="name flex">
<span>def <span class="ident">GetNumInputSlots</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the number of input slots for the layer.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Number of input slots.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumInputSlots(self):
    r&#34;&#34;&#34;

    Gets the number of input slots for the layer.

    Returns:
        int: Number of input slots.


    &#34;&#34;&#34;
    return _pyarmnn.IConnectableLayer_GetNumInputSlots(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetNumOutputSlots"><code class="name flex">
<span>def <span class="ident">GetNumOutputSlots</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the number of output slots for the layer.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Number of output slots.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumOutputSlots(self):
    r&#34;&#34;&#34;

    Gets the number of output slots for the layer.

    Returns:
        int: Number of output slots.


    &#34;&#34;&#34;
    return _pyarmnn.IConnectableLayer_GetNumOutputSlots(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IConnectableLayer.GetOutputSlot"><code class="name flex">
<span>def <span class="ident">GetOutputSlot</span></span>(<span>self, index)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the output slot by index.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>Slot index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot"><code>IOutputSlot</code></a></strong></dt>
<dd>Borrowed reference to output slot.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetOutputSlot(self, index):
    r&#34;&#34;&#34;

    Gets the output slot by index.

    Args:
        index (int): Slot index.

    Returns:
        IOutputSlot: Borrowed reference to output slot.


    &#34;&#34;&#34;
    return _pyarmnn.IConnectableLayer_GetOutputSlot(self, index)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IDeviceSpec"><code class="flex name class">
<span>class <span class="ident">IDeviceSpec</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Interface for device specifications. Main use is to get information relating to what compute capability the device being used has.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IDeviceSpec(object):
    r&#34;&#34;&#34;

    Interface for device specifications. Main use is to get information relating to what compute capability the device being used has.

    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)

    def __init__(self, *args, **kwargs):
        raise AttributeError(&#34;No constructor defined - class is abstract&#34;)
    __repr__ = _swig_repr

    def GetSupportedBackends(self):
        r&#34;&#34;&#34;

        Returns the backends supported by this compute device.

        Returns:
            set: This devices supported backends.


        &#34;&#34;&#34;
        return _pyarmnn.IDeviceSpec_GetSupportedBackends(self)

    def __str__(self):
        return _pyarmnn.IDeviceSpec___str__(self)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IDeviceSpec.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IDeviceSpec.GetSupportedBackends"><code class="name flex">
<span>def <span class="ident">GetSupportedBackends</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the backends supported by this compute device.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>set</code></strong></dt>
<dd>This devices supported backends.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetSupportedBackends(self):
    r&#34;&#34;&#34;

    Returns the backends supported by this compute device.

    Returns:
        set: This devices supported backends.


    &#34;&#34;&#34;
    return _pyarmnn.IDeviceSpec_GetSupportedBackends(self)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IInputSlot"><code class="flex name class">
<span>class <span class="ident">IInputSlot</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>An input connection slot for a layer. Slot lifecycle is managed by the layer.</p>
<p>The input slot can be connected to an output slot of the preceding layer in the graph.
Only one connection to the input slot is allowed.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IInputSlot(object):
    r&#34;&#34;&#34;

    An input connection slot for a layer. Slot lifecycle is managed by the layer.

    The input slot can be connected to an output slot of the preceding layer in the graph.
    Only one connection to the input slot is allowed.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)

    def __init__(self, *args, **kwargs):
        raise AttributeError(&#34;No constructor defined&#34;)
    __repr__ = _swig_repr

    def GetConnection(self):
        r&#34;&#34;&#34;

        Returns output slot of a preceding layer that is connected to the given input slot.

        Returns:
            IOutputSlot: Borrowed reference to an output connection slot for a preceding layer.


        &#34;&#34;&#34;
        return _pyarmnn.IInputSlot_GetConnection(self)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IInputSlot.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IInputSlot.GetConnection"><code class="name flex">
<span>def <span class="ident">GetConnection</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns output slot of a preceding layer that is connected to the given input slot.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot"><code>IOutputSlot</code></a></strong></dt>
<dd>Borrowed reference to an output connection slot for a preceding layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetConnection(self):
    r&#34;&#34;&#34;

    Returns output slot of a preceding layer that is connected to the given input slot.

    Returns:
        IOutputSlot: Borrowed reference to an output connection slot for a preceding layer.


    &#34;&#34;&#34;
    return _pyarmnn.IInputSlot_GetConnection(self)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.INetwork"><code class="flex name class">
<span>class <span class="ident">INetwork</span></span>
</code></dt>
<dd>
<section class="desc"><p>Interface for a network object. Network objects contain the whole computation graph, made up of different layers connected together.</p>
<p>INetwork objects can be constructed manually or obtained by using parsers. INetwork objects are used to create optimized networks, see <a title="pyarmnn.Optimize" href="#pyarmnn.Optimize"><code>Optimize()</code></a>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class INetwork(object):
    r&#34;&#34;&#34;

    Interface for a network object. Network objects contain the whole computation graph, made up of different layers connected together.

    INetwork objects can be constructed manually or obtained by using parsers. INetwork objects are used to create optimized networks, see `Optimize`.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def AddInputLayer(self, id, name=None):
        r&#34;&#34;&#34;

        Adds an input layer to the network. Input layers are placed at the start of a network and used for feeding input data during inference.

        Args:
            id (int): User generated id to uniquely identify a particular input. The same id needs to be specified
                      when passing the inputs to the IRuntime::EnqueueWorkload() function.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddInputLayer(self, id, name)

    def AddAdditionLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds an addition layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddAdditionLayer(self, name)

    def AddOutputLayer(self, id, name=None):
        r&#34;&#34;&#34;

            Adds an output layer to the network. Output layer is the final layer in your network.

        Args:
            id (int): User generated id to uniquely identify a particular input. The same id needs to be specified
                      when passing the inputs to `IRuntime.EnqueueWorkload()`.
            name (str): Optional name for the layer.

            Returns:
                IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddOutputLayer(self, id, name)

    def AddActivationLayer(self, activationDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds an Activation layer to the network. Type of activation is decided by activationDescriptor.

        Args:
            activationDescriptor (ActivationDescriptor): ActivationDescriptor to configure the activation.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddActivationLayer(self, activationDescriptor, name)

    def AddBatchNormalizationLayer(self, desc, mean, variance, beta, gamma, name=None):
        r&#34;&#34;&#34;

        Adds a Batch Normalization layer to the network.

        Args:
            mean (ConstTensor): Pre-calculated mean for each channel.
            variance (ConstTensor): Pre-calculated variance for each channel.
            beta (ConstTensor): Per-channel additive factor.
            gamma (ConstTensor): Per-channel multiplicative factor.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddBatchNormalizationLayer(self, desc, mean, variance, beta, gamma, name)

    def AddBatchToSpaceNdLayer(self, batchToSpaceNdDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Batch To Space ND layer to the network.

        Args:
            batchToSpaceNdDescriptor (BatchToSpaceNdDescriptor): Configuration parameters for the layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddBatchToSpaceNdLayer(self, batchToSpaceNdDescriptor, name)

    def AddConcatLayer(self, concatDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Concatenation layer to the network.

        Args:
            concatDescriptor (ConcatDescriptor): Parameters to configure the Concatenation layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddConcatLayer(self, concatDescriptor, name)

    def AddConstantLayer(self, input, name=None):
        r&#34;&#34;&#34;

        Adds a layer with no inputs and a single output, which always corresponds to the passed in constant tensor.

        Args:
            input (ConstTensor): Tensor to be provided as the only output of the layer. The layer will maintain
                    its own copy of the tensor data, meaning the memory referenced by input can
                    be freed or reused after this function is called.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddConstantLayer(self, input, name)

    def AddDequantizeLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Dequantize layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddDequantizeLayer(self, name)

    def AddDetectionPostProcessLayer(self, descriptor, anchors, name=None):
        r&#34;&#34;&#34;

        Adds a Detection PostProcess layer to the network. Detection PostProcess is a custom layer for SSD MobilenetV1.

        Args:
            descriptor (DetectionPostProcessDescriptor): Description of the Detection PostProcess layer.
            anchors (ConstTensor): Tensor for anchors.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddDetectionPostProcessLayer(self, descriptor, anchors, name)

    def AddDivisionLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Division layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddDivisionLayer(self, name)

    def AddFloorLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Floor layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddFloorLayer(self, name)

    def AddGatherLayer(self, name=None):
        r&#34;&#34;&#34;

        Add Gather layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddGatherLayer(self, name)

    def AddL2NormalizationLayer(self, desc, name=None):
        r&#34;&#34;&#34;

        Adds an L2 Normalization layer to the network.
        Normalization is performed along dimension 1, but requires a 4d input.

        Args:
            desc (L2NormalizationDescriptor): Parameters for the L2 normalization operation.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddL2NormalizationLayer(self, desc, name)

    def AddLstmLayer(self, descriptor, params, name=None):
        r&#34;&#34;&#34;

        Add a Long Short-Term Memory layer to the network.

        Args:
            descriptor (LstmDescriptor): Parameters for the Lstm operation.
            params (LstmInputParams): Weights and biases for the LSTM cell.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddLstmLayer(self, descriptor, params, name)

    def AddMaximumLayer(self, name=None):
        r&#34;&#34;&#34;

        Add a Maximum layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddMaximumLayer(self, name)

    def AddMeanLayer(self, meanDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Mean layer to the network.

        Args:
            meanDescriptor (meanDescriptor): Parameters for the mean operation.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddMeanLayer(self, meanDescriptor, name)

    def AddMergeLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Merge layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddMergeLayer(self, name)

    def AddMinimumLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Minimum layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddMinimumLayer(self, name)

    def AddMultiplicationLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Multiplication layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddMultiplicationLayer(self, name)

    def AddNormalizationLayer(self, normalizationDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Normalization layer to the network.

        Args:
            normalizationDescriptor (NormalizationDescriptor): Parameters to configure the normalization.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddNormalizationLayer(self, normalizationDescriptor, name)

    def AddPadLayer(self, padDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Pad layer to the network.

        Args:
            padDescriptor (PadDescriptor): Padding configuration for the layer. See `PadDescriptor` for more details.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddPadLayer(self, padDescriptor, name)

    def AddPermuteLayer(self, permuteDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Permute layer to the network.

        Args:
            permuteDescriptor (PermuteDescriptor): Configuration of the permutation layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddPermuteLayer(self, permuteDescriptor, name)

    def AddPooling2dLayer(self, pooling2dDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Pooling layer to the network. Type of pooling is decided by the configuration.

        Args:
            pooling2dDescriptor (Pooling2dDescriptor): Configuration for the pooling layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddPooling2dLayer(self, pooling2dDescriptor, name)

    def AddPreluLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a PReLU layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddPreluLayer(self, name)

    def AddQuantizeLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Quantize layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddQuantizeLayer(self, name)

    def AddQuantizedLstmLayer(self, params, name=None):
        r&#34;&#34;&#34;

        Adds a Quantized Long Short-Term Memory layer to the network.

        Args:
            params (QuantizedLstmInputParams): The weights and biases for the Quantized LSTM cell.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddQuantizedLstmLayer(self, params, name)

    def AddReshapeLayer(self, reshapeDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Reshape layer to the network.

        Args:
            reshapeDescriptor (ReshapeDescriptor): Parameters for the reshape operation.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddReshapeLayer(self, reshapeDescriptor, name)

    def AddResizeLayer(self, resizeDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Resize layer to the network.

        Args:
            resizeDescriptor (ResizeDescriptor): Configuration for the resize layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddResizeLayer(self, resizeDescriptor, name)

    def AddRsqrtLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds Reciprocal of square root layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddRsqrtLayer(self, name)

    def AddSoftmaxLayer(self, softmaxDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Softmax layer to the network.

        If the data type is `DataType_QuantisedAsymm8`, then the output quantization parameters
        must have a scale of 1/256 and an offset of 0.

        Args:
            softmaxDescriptor (SoftmaxDescriptor): Configuration for the softmax layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddSoftmaxLayer(self, softmaxDescriptor, name)

    def AddSpaceToBatchNdLayer(self, spaceToBatchNdDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Space To Batch layer to the network.

        Args:
            spaceToBatchNdDescriptor (SpaceToBatchNdDescriptor): Configuration for the space to batch layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddSpaceToBatchNdLayer(self, spaceToBatchNdDescriptor, name)

    def AddSpaceToDepthLayer(self, spaceToDepthDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a space to depth layer to the network.

        Args:
            spaceToDepthDescriptor (SpaceToDepthDescriptor): Parameters for the space to depth operation.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddSpaceToDepthLayer(self, spaceToDepthDescriptor, name)

    def AddSplitterLayer(self, splitterDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Splitter layer to the network.

        Args:
            splitterDescriptor (SplitterDescriptor): Parameters to configure the splitter layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddSplitterLayer(self, splitterDescriptor, name)

    def AddStackLayer(self, descriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Stack layer to the network.

        Args:
            descriptor (StackDescriptor):  Descriptor to configure the stack layer.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddStackLayer(self, descriptor, name)

    def AddStridedSliceLayer(self, stridedSliceDescriptor, name=None):
        r&#34;&#34;&#34;

        Adds a Strided Slice layer to the network.

        Args:
            stridedSliceDescriptor (StridedSliceDescriptor): Parameters for the strided slice operation.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddStridedSliceLayer(self, stridedSliceDescriptor, name)

    def AddSubtractionLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Subtraction layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddSubtractionLayer(self, name)

    def AddSwitchLayer(self, name=None):
        r&#34;&#34;&#34;

        Adds a Switch layer to the network.

        Args:
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddSwitchLayer(self, name)

    def __init__(self):
        _pyarmnn.INetwork_swiginit(self, _pyarmnn.new_INetwork())
    __swig_destroy__ = _pyarmnn.delete_INetwork

    def AddFullyConnectedLayer(self, fullyConnectedDescriptor, weights, biases=None, name=None):
        r&#34;&#34;&#34;

        Adds a Fully Connected layer to the network. Also known as a Linear or Dense layer.

        Args:
            fullyConnectedDescriptor (FullyConnectedDescriptor): Description of the fully connected layer.
            weights (ConstTensor): Tensor for the weights data.
            biases (ConstTensor): Optional tensor for the bias data.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddFullyConnectedLayer(self, fullyConnectedDescriptor, weights, biases, name)

    def AddTransposeConvolution2dLayer(self, descriptor, weights, biases=None, name=None):
        r&#34;&#34;&#34;

        Adds a 2D Transpose Convolution layer to the network.

        Args:
            descriptor (TransposeConvolution2dDescriptor): Descriptor containing all parameters to configure this layer.
            weights (ConstTensor): Tensor for the weights data.
            biases (ConstTensor): Optional tensor for the bias data.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddTransposeConvolution2dLayer(self, descriptor, weights, biases, name)

    def AddConvolution2dLayer(self, convolution2dDescriptor, weights, biases=None, name=None):
        r&#34;&#34;&#34;

        Adds a 2D Convolution layer to the network.

        Args:
            convolution2dDescriptor (Convolution2dDescriptor): Description of the 2D convolution layer.
            weights (ConstTensor): Tensor for the weights data.
            biases (ConstTensor): Optional tensor for the bias data. If specified, must match the output tensor shape.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddConvolution2dLayer(self, convolution2dDescriptor, weights, biases, name)

    def AddDepthwiseConvolution2dLayer(self, convolution2dDescriptor, weights, biases=None, name=None):
        r&#34;&#34;&#34;

        Adds a 2D Depthwise Convolution layer to the network.

        Args:
            convolution2dDescriptor (DepthwiseConvolution2dDescriptor): Description of the 2D depthwise convolution layer.
            weights (ConstTensor): Tensor for the weights. Expected format: [channelMultiplier, inputChannels, height, width].
            biases (ConstTensor): Optional tensor for the bias data. If specified, must match the output tensor shape.
            name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

        &#34;&#34;&#34;
        return _pyarmnn.INetwork_AddDepthwiseConvolution2dLayer(self, convolution2dDescriptor, weights, biases, name)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.INetwork.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.INetwork.AddActivationLayer"><code class="name flex">
<span>def <span class="ident">AddActivationLayer</span></span>(<span>self, activationDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds an Activation layer to the network. Type of activation is decided by activationDescriptor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>activationDescriptor</code></strong> :&ensp;<a title="pyarmnn.ActivationDescriptor" href="#pyarmnn.ActivationDescriptor"><code>ActivationDescriptor</code></a></dt>
<dd>ActivationDescriptor to configure the activation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddActivationLayer(self, activationDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds an Activation layer to the network. Type of activation is decided by activationDescriptor.

    Args:
        activationDescriptor (ActivationDescriptor): ActivationDescriptor to configure the activation.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddActivationLayer(self, activationDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddAdditionLayer"><code class="name flex">
<span>def <span class="ident">AddAdditionLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds an addition layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddAdditionLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds an addition layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddAdditionLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddBatchNormalizationLayer"><code class="name flex">
<span>def <span class="ident">AddBatchNormalizationLayer</span></span>(<span>self, desc, mean, variance, beta, gamma, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Batch Normalization layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mean</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Pre-calculated mean for each channel.</dd>
<dt><strong><code>variance</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Pre-calculated variance for each channel.</dd>
<dt><strong><code>beta</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Per-channel additive factor.</dd>
<dt><strong><code>gamma</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Per-channel multiplicative factor.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddBatchNormalizationLayer(self, desc, mean, variance, beta, gamma, name=None):
    r&#34;&#34;&#34;

    Adds a Batch Normalization layer to the network.

    Args:
        mean (ConstTensor): Pre-calculated mean for each channel.
        variance (ConstTensor): Pre-calculated variance for each channel.
        beta (ConstTensor): Per-channel additive factor.
        gamma (ConstTensor): Per-channel multiplicative factor.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddBatchNormalizationLayer(self, desc, mean, variance, beta, gamma, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddBatchToSpaceNdLayer"><code class="name flex">
<span>def <span class="ident">AddBatchToSpaceNdLayer</span></span>(<span>self, batchToSpaceNdDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Batch To Space ND layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batchToSpaceNdDescriptor</code></strong> :&ensp;<a title="pyarmnn.BatchToSpaceNdDescriptor" href="#pyarmnn.BatchToSpaceNdDescriptor"><code>BatchToSpaceNdDescriptor</code></a></dt>
<dd>Configuration parameters for the layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddBatchToSpaceNdLayer(self, batchToSpaceNdDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Batch To Space ND layer to the network.

    Args:
        batchToSpaceNdDescriptor (BatchToSpaceNdDescriptor): Configuration parameters for the layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddBatchToSpaceNdLayer(self, batchToSpaceNdDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddConcatLayer"><code class="name flex">
<span>def <span class="ident">AddConcatLayer</span></span>(<span>self, concatDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Concatenation layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>concatDescriptor</code></strong> :&ensp;<a title="pyarmnn.ConcatDescriptor" href="#pyarmnn.ConcatDescriptor"><code>ConcatDescriptor</code></a></dt>
<dd>Parameters to configure the Concatenation layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddConcatLayer(self, concatDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Concatenation layer to the network.

    Args:
        concatDescriptor (ConcatDescriptor): Parameters to configure the Concatenation layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddConcatLayer(self, concatDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddConstantLayer"><code class="name flex">
<span>def <span class="ident">AddConstantLayer</span></span>(<span>self, input, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a layer with no inputs and a single output, which always corresponds to the passed in constant tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Tensor to be provided as the only output of the layer. The layer will maintain
its own copy of the tensor data, meaning the memory referenced by input can
be freed or reused after this function is called.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddConstantLayer(self, input, name=None):
    r&#34;&#34;&#34;

    Adds a layer with no inputs and a single output, which always corresponds to the passed in constant tensor.

    Args:
        input (ConstTensor): Tensor to be provided as the only output of the layer. The layer will maintain
                its own copy of the tensor data, meaning the memory referenced by input can
                be freed or reused after this function is called.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddConstantLayer(self, input, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddConvolution2dLayer"><code class="name flex">
<span>def <span class="ident">AddConvolution2dLayer</span></span>(<span>self, convolution2dDescriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a 2D Convolution layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>convolution2dDescriptor</code></strong> :&ensp;<a title="pyarmnn.Convolution2dDescriptor" href="#pyarmnn.Convolution2dDescriptor"><code>Convolution2dDescriptor</code></a></dt>
<dd>Description of the 2D convolution layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Tensor for the weights data.</dd>
<dt><strong><code>biases</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Optional tensor for the bias data. If specified, must match the output tensor shape.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddConvolution2dLayer(self, convolution2dDescriptor, weights, biases=None, name=None):
    r&#34;&#34;&#34;

    Adds a 2D Convolution layer to the network.

    Args:
        convolution2dDescriptor (Convolution2dDescriptor): Description of the 2D convolution layer.
        weights (ConstTensor): Tensor for the weights data.
        biases (ConstTensor): Optional tensor for the bias data. If specified, must match the output tensor shape.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddConvolution2dLayer(self, convolution2dDescriptor, weights, biases, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddDepthwiseConvolution2dLayer"><code class="name flex">
<span>def <span class="ident">AddDepthwiseConvolution2dLayer</span></span>(<span>self, convolution2dDescriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a 2D Depthwise Convolution layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>convolution2dDescriptor</code></strong> :&ensp;<a title="pyarmnn.DepthwiseConvolution2dDescriptor" href="#pyarmnn.DepthwiseConvolution2dDescriptor"><code>DepthwiseConvolution2dDescriptor</code></a></dt>
<dd>Description of the 2D depthwise convolution layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Tensor for the weights. Expected format: [channelMultiplier, inputChannels, height, width].</dd>
<dt><strong><code>biases</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Optional tensor for the bias data. If specified, must match the output tensor shape.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddDepthwiseConvolution2dLayer(self, convolution2dDescriptor, weights, biases=None, name=None):
    r&#34;&#34;&#34;

    Adds a 2D Depthwise Convolution layer to the network.

    Args:
        convolution2dDescriptor (DepthwiseConvolution2dDescriptor): Description of the 2D depthwise convolution layer.
        weights (ConstTensor): Tensor for the weights. Expected format: [channelMultiplier, inputChannels, height, width].
        biases (ConstTensor): Optional tensor for the bias data. If specified, must match the output tensor shape.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddDepthwiseConvolution2dLayer(self, convolution2dDescriptor, weights, biases, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddDequantizeLayer"><code class="name flex">
<span>def <span class="ident">AddDequantizeLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Dequantize layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddDequantizeLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Dequantize layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddDequantizeLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddDetectionPostProcessLayer"><code class="name flex">
<span>def <span class="ident">AddDetectionPostProcessLayer</span></span>(<span>self, descriptor, anchors, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Detection PostProcess layer to the network. Detection PostProcess is a custom layer for SSD MobilenetV1.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<a title="pyarmnn.DetectionPostProcessDescriptor" href="#pyarmnn.DetectionPostProcessDescriptor"><code>DetectionPostProcessDescriptor</code></a></dt>
<dd>Description of the Detection PostProcess layer.</dd>
<dt><strong><code>anchors</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Tensor for anchors.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddDetectionPostProcessLayer(self, descriptor, anchors, name=None):
    r&#34;&#34;&#34;

    Adds a Detection PostProcess layer to the network. Detection PostProcess is a custom layer for SSD MobilenetV1.

    Args:
        descriptor (DetectionPostProcessDescriptor): Description of the Detection PostProcess layer.
        anchors (ConstTensor): Tensor for anchors.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddDetectionPostProcessLayer(self, descriptor, anchors, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddDivisionLayer"><code class="name flex">
<span>def <span class="ident">AddDivisionLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Division layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddDivisionLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Division layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddDivisionLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddFloorLayer"><code class="name flex">
<span>def <span class="ident">AddFloorLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Floor layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddFloorLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Floor layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddFloorLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddFullyConnectedLayer"><code class="name flex">
<span>def <span class="ident">AddFullyConnectedLayer</span></span>(<span>self, fullyConnectedDescriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Fully Connected layer to the network. Also known as a Linear or Dense layer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fullyConnectedDescriptor</code></strong> :&ensp;<a title="pyarmnn.FullyConnectedDescriptor" href="#pyarmnn.FullyConnectedDescriptor"><code>FullyConnectedDescriptor</code></a></dt>
<dd>Description of the fully connected layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Tensor for the weights data.</dd>
<dt><strong><code>biases</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Optional tensor for the bias data.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddFullyConnectedLayer(self, fullyConnectedDescriptor, weights, biases=None, name=None):
    r&#34;&#34;&#34;

    Adds a Fully Connected layer to the network. Also known as a Linear or Dense layer.

    Args:
        fullyConnectedDescriptor (FullyConnectedDescriptor): Description of the fully connected layer.
        weights (ConstTensor): Tensor for the weights data.
        biases (ConstTensor): Optional tensor for the bias data.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddFullyConnectedLayer(self, fullyConnectedDescriptor, weights, biases, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddGatherLayer"><code class="name flex">
<span>def <span class="ident">AddGatherLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Add Gather layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddGatherLayer(self, name=None):
    r&#34;&#34;&#34;

    Add Gather layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddGatherLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddInputLayer"><code class="name flex">
<span>def <span class="ident">AddInputLayer</span></span>(<span>self, id, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds an input layer to the network. Input layers are placed at the start of a network and used for feeding input data during inference.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong> :&ensp;<code>int</code></dt>
<dd>User generated id to uniquely identify a particular input. The same id needs to be specified
when passing the inputs to the IRuntime::EnqueueWorkload() function.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddInputLayer(self, id, name=None):
    r&#34;&#34;&#34;

    Adds an input layer to the network. Input layers are placed at the start of a network and used for feeding input data during inference.

    Args:
        id (int): User generated id to uniquely identify a particular input. The same id needs to be specified
                  when passing the inputs to the IRuntime::EnqueueWorkload() function.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddInputLayer(self, id, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddL2NormalizationLayer"><code class="name flex">
<span>def <span class="ident">AddL2NormalizationLayer</span></span>(<span>self, desc, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds an L2 Normalization layer to the network.
Normalization is performed along dimension 1, but requires a 4d input.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>desc</code></strong> :&ensp;<a title="pyarmnn.L2NormalizationDescriptor" href="#pyarmnn.L2NormalizationDescriptor"><code>L2NormalizationDescriptor</code></a></dt>
<dd>Parameters for the L2 normalization operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddL2NormalizationLayer(self, desc, name=None):
    r&#34;&#34;&#34;

    Adds an L2 Normalization layer to the network.
    Normalization is performed along dimension 1, but requires a 4d input.

    Args:
        desc (L2NormalizationDescriptor): Parameters for the L2 normalization operation.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddL2NormalizationLayer(self, desc, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddLstmLayer"><code class="name flex">
<span>def <span class="ident">AddLstmLayer</span></span>(<span>self, descriptor, params, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Add a Long Short-Term Memory layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<a title="pyarmnn.LstmDescriptor" href="#pyarmnn.LstmDescriptor"><code>LstmDescriptor</code></a></dt>
<dd>Parameters for the Lstm operation.</dd>
<dt><strong><code>params</code></strong> :&ensp;<a title="pyarmnn.LstmInputParams" href="#pyarmnn.LstmInputParams"><code>LstmInputParams</code></a></dt>
<dd>Weights and biases for the LSTM cell.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddLstmLayer(self, descriptor, params, name=None):
    r&#34;&#34;&#34;

    Add a Long Short-Term Memory layer to the network.

    Args:
        descriptor (LstmDescriptor): Parameters for the Lstm operation.
        params (LstmInputParams): Weights and biases for the LSTM cell.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddLstmLayer(self, descriptor, params, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddMaximumLayer"><code class="name flex">
<span>def <span class="ident">AddMaximumLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Add a Maximum layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddMaximumLayer(self, name=None):
    r&#34;&#34;&#34;

    Add a Maximum layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddMaximumLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddMeanLayer"><code class="name flex">
<span>def <span class="ident">AddMeanLayer</span></span>(<span>self, meanDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Mean layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>meanDescriptor</code></strong> :&ensp;<code>meanDescriptor</code></dt>
<dd>Parameters for the mean operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddMeanLayer(self, meanDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Mean layer to the network.

    Args:
        meanDescriptor (meanDescriptor): Parameters for the mean operation.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddMeanLayer(self, meanDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddMergeLayer"><code class="name flex">
<span>def <span class="ident">AddMergeLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Merge layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddMergeLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Merge layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddMergeLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddMinimumLayer"><code class="name flex">
<span>def <span class="ident">AddMinimumLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Minimum layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddMinimumLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Minimum layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddMinimumLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddMultiplicationLayer"><code class="name flex">
<span>def <span class="ident">AddMultiplicationLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Multiplication layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddMultiplicationLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Multiplication layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddMultiplicationLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddNormalizationLayer"><code class="name flex">
<span>def <span class="ident">AddNormalizationLayer</span></span>(<span>self, normalizationDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Normalization layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>normalizationDescriptor</code></strong> :&ensp;<a title="pyarmnn.NormalizationDescriptor" href="#pyarmnn.NormalizationDescriptor"><code>NormalizationDescriptor</code></a></dt>
<dd>Parameters to configure the normalization.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddNormalizationLayer(self, normalizationDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Normalization layer to the network.

    Args:
        normalizationDescriptor (NormalizationDescriptor): Parameters to configure the normalization.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddNormalizationLayer(self, normalizationDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddOutputLayer"><code class="name flex">
<span>def <span class="ident">AddOutputLayer</span></span>(<span>self, id, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds an output layer to the network. Output layer is the final layer in your network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong> :&ensp;<code>int</code></dt>
<dd>User generated id to uniquely identify a particular input. The same id needs to be specified
when passing the inputs to <a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload"><code>IRuntime.EnqueueWorkload()</code></a>.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<p>Returns:
IConnectableLayer: Interface for configuring the layer.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddOutputLayer(self, id, name=None):
    r&#34;&#34;&#34;

        Adds an output layer to the network. Output layer is the final layer in your network.

    Args:
        id (int): User generated id to uniquely identify a particular input. The same id needs to be specified
                  when passing the inputs to `IRuntime.EnqueueWorkload()`.
        name (str): Optional name for the layer.

        Returns:
            IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddOutputLayer(self, id, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddPadLayer"><code class="name flex">
<span>def <span class="ident">AddPadLayer</span></span>(<span>self, padDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Pad layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>padDescriptor</code></strong> :&ensp;<a title="pyarmnn.PadDescriptor" href="#pyarmnn.PadDescriptor"><code>PadDescriptor</code></a></dt>
<dd>Padding configuration for the layer. See <a title="pyarmnn.PadDescriptor" href="#pyarmnn.PadDescriptor"><code>PadDescriptor</code></a> for more details.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddPadLayer(self, padDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Pad layer to the network.

    Args:
        padDescriptor (PadDescriptor): Padding configuration for the layer. See `PadDescriptor` for more details.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddPadLayer(self, padDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddPermuteLayer"><code class="name flex">
<span>def <span class="ident">AddPermuteLayer</span></span>(<span>self, permuteDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Permute layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>permuteDescriptor</code></strong> :&ensp;<a title="pyarmnn.PermuteDescriptor" href="#pyarmnn.PermuteDescriptor"><code>PermuteDescriptor</code></a></dt>
<dd>Configuration of the permutation layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddPermuteLayer(self, permuteDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Permute layer to the network.

    Args:
        permuteDescriptor (PermuteDescriptor): Configuration of the permutation layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddPermuteLayer(self, permuteDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddPooling2dLayer"><code class="name flex">
<span>def <span class="ident">AddPooling2dLayer</span></span>(<span>self, pooling2dDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Pooling layer to the network. Type of pooling is decided by the configuration.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>pooling2dDescriptor</code></strong> :&ensp;<a title="pyarmnn.Pooling2dDescriptor" href="#pyarmnn.Pooling2dDescriptor"><code>Pooling2dDescriptor</code></a></dt>
<dd>Configuration for the pooling layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddPooling2dLayer(self, pooling2dDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Pooling layer to the network. Type of pooling is decided by the configuration.

    Args:
        pooling2dDescriptor (Pooling2dDescriptor): Configuration for the pooling layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddPooling2dLayer(self, pooling2dDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddPreluLayer"><code class="name flex">
<span>def <span class="ident">AddPreluLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a PReLU layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddPreluLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a PReLU layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddPreluLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddQuantizeLayer"><code class="name flex">
<span>def <span class="ident">AddQuantizeLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Quantize layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddQuantizeLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Quantize layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddQuantizeLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddQuantizedLstmLayer"><code class="name flex">
<span>def <span class="ident">AddQuantizedLstmLayer</span></span>(<span>self, params, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Quantized Long Short-Term Memory layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>QuantizedLstmInputParams</code></dt>
<dd>The weights and biases for the Quantized LSTM cell.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddQuantizedLstmLayer(self, params, name=None):
    r&#34;&#34;&#34;

    Adds a Quantized Long Short-Term Memory layer to the network.

    Args:
        params (QuantizedLstmInputParams): The weights and biases for the Quantized LSTM cell.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddQuantizedLstmLayer(self, params, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddReshapeLayer"><code class="name flex">
<span>def <span class="ident">AddReshapeLayer</span></span>(<span>self, reshapeDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Reshape layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reshapeDescriptor</code></strong> :&ensp;<a title="pyarmnn.ReshapeDescriptor" href="#pyarmnn.ReshapeDescriptor"><code>ReshapeDescriptor</code></a></dt>
<dd>Parameters for the reshape operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddReshapeLayer(self, reshapeDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Reshape layer to the network.

    Args:
        reshapeDescriptor (ReshapeDescriptor): Parameters for the reshape operation.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddReshapeLayer(self, reshapeDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddResizeLayer"><code class="name flex">
<span>def <span class="ident">AddResizeLayer</span></span>(<span>self, resizeDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Resize layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>resizeDescriptor</code></strong> :&ensp;<a title="pyarmnn.ResizeDescriptor" href="#pyarmnn.ResizeDescriptor"><code>ResizeDescriptor</code></a></dt>
<dd>Configuration for the resize layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddResizeLayer(self, resizeDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Resize layer to the network.

    Args:
        resizeDescriptor (ResizeDescriptor): Configuration for the resize layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddResizeLayer(self, resizeDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddRsqrtLayer"><code class="name flex">
<span>def <span class="ident">AddRsqrtLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds Reciprocal of square root layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddRsqrtLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds Reciprocal of square root layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddRsqrtLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddSoftmaxLayer"><code class="name flex">
<span>def <span class="ident">AddSoftmaxLayer</span></span>(<span>self, softmaxDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Softmax layer to the network.</p>
<p>If the data type is <code>DataType_QuantisedAsymm8</code>, then the output quantization parameters
must have a scale of 1/256 and an offset of 0.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>softmaxDescriptor</code></strong> :&ensp;<a title="pyarmnn.SoftmaxDescriptor" href="#pyarmnn.SoftmaxDescriptor"><code>SoftmaxDescriptor</code></a></dt>
<dd>Configuration for the softmax layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddSoftmaxLayer(self, softmaxDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Softmax layer to the network.

    If the data type is `DataType_QuantisedAsymm8`, then the output quantization parameters
    must have a scale of 1/256 and an offset of 0.

    Args:
        softmaxDescriptor (SoftmaxDescriptor): Configuration for the softmax layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddSoftmaxLayer(self, softmaxDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddSpaceToBatchNdLayer"><code class="name flex">
<span>def <span class="ident">AddSpaceToBatchNdLayer</span></span>(<span>self, spaceToBatchNdDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Space To Batch layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spaceToBatchNdDescriptor</code></strong> :&ensp;<a title="pyarmnn.SpaceToBatchNdDescriptor" href="#pyarmnn.SpaceToBatchNdDescriptor"><code>SpaceToBatchNdDescriptor</code></a></dt>
<dd>Configuration for the space to batch layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddSpaceToBatchNdLayer(self, spaceToBatchNdDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Space To Batch layer to the network.

    Args:
        spaceToBatchNdDescriptor (SpaceToBatchNdDescriptor): Configuration for the space to batch layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddSpaceToBatchNdLayer(self, spaceToBatchNdDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddSpaceToDepthLayer"><code class="name flex">
<span>def <span class="ident">AddSpaceToDepthLayer</span></span>(<span>self, spaceToDepthDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a space to depth layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spaceToDepthDescriptor</code></strong> :&ensp;<a title="pyarmnn.SpaceToDepthDescriptor" href="#pyarmnn.SpaceToDepthDescriptor"><code>SpaceToDepthDescriptor</code></a></dt>
<dd>Parameters for the space to depth operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddSpaceToDepthLayer(self, spaceToDepthDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a space to depth layer to the network.

    Args:
        spaceToDepthDescriptor (SpaceToDepthDescriptor): Parameters for the space to depth operation.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddSpaceToDepthLayer(self, spaceToDepthDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddSplitterLayer"><code class="name flex">
<span>def <span class="ident">AddSplitterLayer</span></span>(<span>self, splitterDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Splitter layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>splitterDescriptor</code></strong> :&ensp;<a title="pyarmnn.SplitterDescriptor" href="#pyarmnn.SplitterDescriptor"><code>SplitterDescriptor</code></a></dt>
<dd>Parameters to configure the splitter layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddSplitterLayer(self, splitterDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Splitter layer to the network.

    Args:
        splitterDescriptor (SplitterDescriptor): Parameters to configure the splitter layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddSplitterLayer(self, splitterDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddStackLayer"><code class="name flex">
<span>def <span class="ident">AddStackLayer</span></span>(<span>self, descriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Stack layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<a title="pyarmnn.StackDescriptor" href="#pyarmnn.StackDescriptor"><code>StackDescriptor</code></a></dt>
<dd>Descriptor to configure the stack layer.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddStackLayer(self, descriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Stack layer to the network.

    Args:
        descriptor (StackDescriptor):  Descriptor to configure the stack layer.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddStackLayer(self, descriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddStridedSliceLayer"><code class="name flex">
<span>def <span class="ident">AddStridedSliceLayer</span></span>(<span>self, stridedSliceDescriptor, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Strided Slice layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>stridedSliceDescriptor</code></strong> :&ensp;<a title="pyarmnn.StridedSliceDescriptor" href="#pyarmnn.StridedSliceDescriptor"><code>StridedSliceDescriptor</code></a></dt>
<dd>Parameters for the strided slice operation.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddStridedSliceLayer(self, stridedSliceDescriptor, name=None):
    r&#34;&#34;&#34;

    Adds a Strided Slice layer to the network.

    Args:
        stridedSliceDescriptor (StridedSliceDescriptor): Parameters for the strided slice operation.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddStridedSliceLayer(self, stridedSliceDescriptor, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddSubtractionLayer"><code class="name flex">
<span>def <span class="ident">AddSubtractionLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Subtraction layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddSubtractionLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Subtraction layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddSubtractionLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddSwitchLayer"><code class="name flex">
<span>def <span class="ident">AddSwitchLayer</span></span>(<span>self, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a Switch layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddSwitchLayer(self, name=None):
    r&#34;&#34;&#34;

    Adds a Switch layer to the network.

    Args:
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddSwitchLayer(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.INetwork.AddTransposeConvolution2dLayer"><code class="name flex">
<span>def <span class="ident">AddTransposeConvolution2dLayer</span></span>(<span>self, descriptor, weights, biases=None, name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds a 2D Transpose Convolution layer to the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>descriptor</code></strong> :&ensp;<a title="pyarmnn.TransposeConvolution2dDescriptor" href="#pyarmnn.TransposeConvolution2dDescriptor"><code>TransposeConvolution2dDescriptor</code></a></dt>
<dd>Descriptor containing all parameters to configure this layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Tensor for the weights data.</dd>
<dt><strong><code>biases</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Optional tensor for the bias data.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def AddTransposeConvolution2dLayer(self, descriptor, weights, biases=None, name=None):
    r&#34;&#34;&#34;

    Adds a 2D Transpose Convolution layer to the network.

    Args:
        descriptor (TransposeConvolution2dDescriptor): Descriptor containing all parameters to configure this layer.
        weights (ConstTensor): Tensor for the weights data.
        biases (ConstTensor): Optional tensor for the bias data.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;
    return _pyarmnn.INetwork_AddTransposeConvolution2dLayer(self, descriptor, weights, biases, name)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IOnnxParser"><code class="flex name class">
<span>class <span class="ident">IOnnxParser</span></span>
</code></dt>
<dd>
<section class="desc"><p>Interface for creating a parser object using ONNX (<a href="https://onnx.ai/">https://onnx.ai/</a>) onnx files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IOnnxParser(object):
    r&#34;&#34;&#34;

    Interface for creating a parser object using ONNX (https://onnx.ai/) onnx files.

    Parsers are used to automatically construct Arm NN graphs from model files.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def GetNetworkInputBindingInfo(self, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.

        Args:
            name (string): Name of the input node.

        Returns:
            tuple: (`int`, `TensorInfo`)

        &#34;&#34;&#34;
        return _pyarmnn_onnxparser.IOnnxParser_GetNetworkInputBindingInfo(self, name)

    def GetNetworkOutputBindingInfo(self, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.

        Args:
            name (string): Name of the output node.

        Returns:
            tuple: (`int`, `TensorInfo`)

        &#34;&#34;&#34;
        return _pyarmnn_onnxparser.IOnnxParser_GetNetworkOutputBindingInfo(self, name)

    def __init__(self):
        _pyarmnn_onnxparser.IOnnxParser_swiginit(self, _pyarmnn_onnxparser.new_IOnnxParser())
    __swig_destroy__ = _pyarmnn_onnxparser.delete_IOnnxParser

    def CreateNetworkFromBinaryFile(self, graphFile):
        r&#34;&#34;&#34;

        Create the network from a binary file on disk.

        Args:
            graphFile (str): Path to the onnx model to be parsed.

        Returns:
            INetwork: Parsed network.

        Raises:
            RuntimeError: If model file was not found.

        &#34;&#34;&#34;
        return _pyarmnn_onnxparser.IOnnxParser_CreateNetworkFromBinaryFile(self, graphFile)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IOnnxParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IOnnxParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile)</span>
</code></dt>
<dd>
<section class="desc"><p>Create the network from a binary file on disk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the onnx model to be parsed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork"><code>INetwork</code></a></strong></dt>
<dd>Parsed network.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If model file was not found.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CreateNetworkFromBinaryFile(self, graphFile):
    r&#34;&#34;&#34;

    Create the network from a binary file on disk.

    Args:
        graphFile (str): Path to the onnx model to be parsed.

    Returns:
        INetwork: Parsed network.

    Raises:
        RuntimeError: If model file was not found.

    &#34;&#34;&#34;
    return _pyarmnn_onnxparser.IOnnxParser_CreateNetworkFromBinaryFile(self, graphFile)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOnnxParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the input node.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkInputBindingInfo(self, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.

    Args:
        name (string): Name of the input node.

    Returns:
        tuple: (`int`, `TensorInfo`)

    &#34;&#34;&#34;
    return _pyarmnn_onnxparser.IOnnxParser_GetNetworkInputBindingInfo(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOnnxParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the output node.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkOutputBindingInfo(self, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.

    Args:
        name (string): Name of the output node.

    Returns:
        tuple: (`int`, `TensorInfo`)

    &#34;&#34;&#34;
    return _pyarmnn_onnxparser.IOnnxParser_GetNetworkOutputBindingInfo(self, name)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IOptimizedNetwork"><code class="flex name class">
<span>class <span class="ident">IOptimizedNetwork</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Interface class for an optimzied network object. Optimized networks are obtained after running <a title="pyarmnn.Optimize" href="#pyarmnn.Optimize"><code>Optimize()</code></a> on
an <a title="pyarmnn.INetwork" href="#pyarmnn.INetwork"><code>INetwork</code></a> object.
Optimized networks are passed to <code>EnqueueWorkload</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>convolution2dDescriptor</code></strong> :&ensp;<a title="pyarmnn.DepthwiseConvolution2dDescriptor" href="#pyarmnn.DepthwiseConvolution2dDescriptor"><code>DepthwiseConvolution2dDescriptor</code></a></dt>
<dd>Description of the 2D depthwise convolution layer.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Tensor for the weights. Expected format: [channelMultiplier, inputChannels, height, width].</dd>
<dt><strong><code>biases</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>Optional tensor for the bias data. If specified, must match the output tensor shape.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional name for the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer"><code>IConnectableLayer</code></a></strong></dt>
<dd>Interface for configuring the layer.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IOptimizedNetwork(object):
    r&#34;&#34;&#34;

    Interface class for an optimzied network object. Optimized networks are obtained after running `Optimize` on
    an `INetwork` object.
    Optimized networks are passed to `EnqueueWorkload`.

    Args:
        convolution2dDescriptor (DepthwiseConvolution2dDescriptor): Description of the 2D depthwise convolution layer.
        weights (ConstTensor): Tensor for the weights. Expected format: [channelMultiplier, inputChannels, height, width].
        biases (ConstTensor): Optional tensor for the bias data. If specified, must match the output tensor shape.
        name (str): Optional name for the layer.

    Returns:
        IConnectableLayer: Interface for configuring the layer.

    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)

    def __init__(self, *args, **kwargs):
        raise AttributeError(&#34;No constructor defined&#34;)
    __repr__ = _swig_repr
    __swig_destroy__ = _pyarmnn.delete_IOptimizedNetwork

    def SerializeToDot(self, fileName):
        r&#34;&#34;&#34;

        Saves optimized network graph as dot file.

        Args:
            fileName (str): File path to save to.
        Raises:
            RuntimeError: If serialization failure.

        &#34;&#34;&#34;
        return _pyarmnn.IOptimizedNetwork_SerializeToDot(self, fileName)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IOptimizedNetwork.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IOptimizedNetwork.SerializeToDot"><code class="name flex">
<span>def <span class="ident">SerializeToDot</span></span>(<span>self, fileName)</span>
</code></dt>
<dd>
<section class="desc"><p>Saves optimized network graph as dot file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fileName</code></strong> :&ensp;<code>str</code></dt>
<dd>File path to save to.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If serialization failure.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SerializeToDot(self, fileName):
    r&#34;&#34;&#34;

    Saves optimized network graph as dot file.

    Args:
        fileName (str): File path to save to.
    Raises:
        RuntimeError: If serialization failure.

    &#34;&#34;&#34;
    return _pyarmnn.IOptimizedNetwork_SerializeToDot(self, fileName)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IOutputSlot"><code class="flex name class">
<span>class <span class="ident">IOutputSlot</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>An output connection slot for a layer. Slot lifecycle is managed by the layer.</p>
<p>The output slot may be connected to 1 or more input slots of subsequent layers in the graph.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IOutputSlot(object):
    r&#34;&#34;&#34;

    An output connection slot for a layer. Slot lifecycle is managed by the layer.

    The output slot may be connected to 1 or more input slots of subsequent layers in the graph.

    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)

    def __init__(self, *args, **kwargs):
        raise AttributeError(&#34;No constructor defined&#34;)
    __repr__ = _swig_repr

    def GetNumConnections(self):
        r&#34;&#34;&#34;

        Returns the total number of connected input slots.

        The same result could be obtained by calling `len()`:

        &gt;&gt;&gt; output_slot = ...
        &gt;&gt;&gt; size = len(output_slot)
        &gt;&gt;&gt; assert size == output_slot.GetNumConnections()

        Returns:
            int: Number of connected input slots.

        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_GetNumConnections(self)

    def GetConnection(self, index):
        r&#34;&#34;&#34;

        Retrieves connected input slot by index.

        The same result could be obtained by using square brackets:

        &gt;&gt;&gt; output_slot = ...
        &gt;&gt;&gt; connected_input_slot = output_slot[0]

        Args:
           index (int): Slot index.

        Returns:
            IInputSlot: Borrowed reference to connected input slot with given index.

        Raises:
            RuntimeError: If index out of bounds.

        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_GetConnection(self, index)

    def SetTensorInfo(self, tensorInfo):
        r&#34;&#34;&#34;

        Sets tensor info for output slot.
        Operation does not change TensorInfo ownership.
        Args:
            tensorInfo (TensorInfo): Output tensor info.


        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_SetTensorInfo(self, tensorInfo)

    def GetTensorInfo(self):
        r&#34;&#34;&#34;

        Gets tensor info for output slot.

        Args:
            tensorInfo (TensorInfo): Output tensor info.


        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_GetTensorInfo(self)

    def IsTensorInfoSet(self):
        r&#34;&#34;&#34;

        Checks if tensor info was set previously.

        Returns:
            bool: True if output tensor info was set, False - otherwise.


        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_IsTensorInfoSet(self)

    def Connect(self, destination):
        r&#34;&#34;&#34;

        Connects this output slot with given input slot.
        Input slot is updated with this output connection.

        Args:
            destination (IInputSlot): Output tensor info.

        Returns:
            int: Total number of connections.

        Raises:
            RuntimeError: If input slot was already connected.


        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_Connect(self, destination)

    def Disconnect(self, slot):
        r&#34;&#34;&#34;

        Disconnects this output slot from given input slot.

        Args:
            slot (IInputSlot): Input slot to disconnect from.


        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_Disconnect(self, slot)

    def CalculateIndexOnOwner(self):
        r&#34;&#34;&#34;

        Calculates the index of this slot for the layer.

        Returns:
            int: Slot index.


        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_CalculateIndexOnOwner(self)

    def GetOwningLayerGuid(self):
        r&#34;&#34;&#34;

        Returns the index of the layer. Same value as `IConnectableLayer.GetGuid`.

        Returns:
            int: Layer id.


        &#34;&#34;&#34;
        return _pyarmnn.IOutputSlot_GetOwningLayerGuid(self)

    def __getitem__(self, index):
        return _pyarmnn.IOutputSlot___getitem__(self, index)

    def __len__(self):
        return _pyarmnn.IOutputSlot___len__(self)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IOutputSlot.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IOutputSlot.CalculateIndexOnOwner"><code class="name flex">
<span>def <span class="ident">CalculateIndexOnOwner</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculates the index of this slot for the layer.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Slot index.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CalculateIndexOnOwner(self):
    r&#34;&#34;&#34;

    Calculates the index of this slot for the layer.

    Returns:
        int: Slot index.


    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_CalculateIndexOnOwner(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.Connect"><code class="name flex">
<span>def <span class="ident">Connect</span></span>(<span>self, destination)</span>
</code></dt>
<dd>
<section class="desc"><p>Connects this output slot with given input slot.
Input slot is updated with this output connection.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>destination</code></strong> :&ensp;<a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot"><code>IInputSlot</code></a></dt>
<dd>Output tensor info.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Total number of connections.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If input slot was already connected.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Connect(self, destination):
    r&#34;&#34;&#34;

    Connects this output slot with given input slot.
    Input slot is updated with this output connection.

    Args:
        destination (IInputSlot): Output tensor info.

    Returns:
        int: Total number of connections.

    Raises:
        RuntimeError: If input slot was already connected.


    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_Connect(self, destination)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.Disconnect"><code class="name flex">
<span>def <span class="ident">Disconnect</span></span>(<span>self, slot)</span>
</code></dt>
<dd>
<section class="desc"><p>Disconnects this output slot from given input slot.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>slot</code></strong> :&ensp;<a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot"><code>IInputSlot</code></a></dt>
<dd>Input slot to disconnect from.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Disconnect(self, slot):
    r&#34;&#34;&#34;

    Disconnects this output slot from given input slot.

    Args:
        slot (IInputSlot): Input slot to disconnect from.


    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_Disconnect(self, slot)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.GetConnection"><code class="name flex">
<span>def <span class="ident">GetConnection</span></span>(<span>self, index)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieves connected input slot by index.</p>
<p>The same result could be obtained by using square brackets:</p>
<pre><code>&gt;&gt;&gt; output_slot = ...
&gt;&gt;&gt; connected_input_slot = output_slot[0]
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>Slot index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot"><code>IInputSlot</code></a></strong></dt>
<dd>Borrowed reference to connected input slot with given index.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If index out of bounds.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetConnection(self, index):
    r&#34;&#34;&#34;

    Retrieves connected input slot by index.

    The same result could be obtained by using square brackets:

    &gt;&gt;&gt; output_slot = ...
    &gt;&gt;&gt; connected_input_slot = output_slot[0]

    Args:
       index (int): Slot index.

    Returns:
        IInputSlot: Borrowed reference to connected input slot with given index.

    Raises:
        RuntimeError: If index out of bounds.

    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_GetConnection(self, index)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.GetNumConnections"><code class="name flex">
<span>def <span class="ident">GetNumConnections</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the total number of connected input slots.</p>
<p>The same result could be obtained by calling <code>len()</code>:</p>
<pre><code>&gt;&gt;&gt; output_slot = ...
&gt;&gt;&gt; size = len(output_slot)
&gt;&gt;&gt; assert size == output_slot.GetNumConnections()
</code></pre>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Number of connected input slots.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumConnections(self):
    r&#34;&#34;&#34;

    Returns the total number of connected input slots.

    The same result could be obtained by calling `len()`:

    &gt;&gt;&gt; output_slot = ...
    &gt;&gt;&gt; size = len(output_slot)
    &gt;&gt;&gt; assert size == output_slot.GetNumConnections()

    Returns:
        int: Number of connected input slots.

    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_GetNumConnections(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.GetOwningLayerGuid"><code class="name flex">
<span>def <span class="ident">GetOwningLayerGuid</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the index of the layer. Same value as <a title="pyarmnn.IConnectableLayer.GetGuid" href="#pyarmnn.IConnectableLayer.GetGuid"><code>IConnectableLayer.GetGuid()</code></a>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Layer id.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetOwningLayerGuid(self):
    r&#34;&#34;&#34;

    Returns the index of the layer. Same value as `IConnectableLayer.GetGuid`.

    Returns:
        int: Layer id.


    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_GetOwningLayerGuid(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.GetTensorInfo"><code class="name flex">
<span>def <span class="ident">GetTensorInfo</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets tensor info for output slot.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tensorInfo</code></strong> :&ensp;<a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a></dt>
<dd>Output tensor info.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetTensorInfo(self):
    r&#34;&#34;&#34;

    Gets tensor info for output slot.

    Args:
        tensorInfo (TensorInfo): Output tensor info.


    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_GetTensorInfo(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.IsTensorInfoSet"><code class="name flex">
<span>def <span class="ident">IsTensorInfoSet</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Checks if tensor info was set previously.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>bool</code></strong></dt>
<dd>True if output tensor info was set, False - otherwise.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def IsTensorInfoSet(self):
    r&#34;&#34;&#34;

    Checks if tensor info was set previously.

    Returns:
        bool: True if output tensor info was set, False - otherwise.


    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_IsTensorInfoSet(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IOutputSlot.SetTensorInfo"><code class="name flex">
<span>def <span class="ident">SetTensorInfo</span></span>(<span>self, tensorInfo)</span>
</code></dt>
<dd>
<section class="desc"><p>Sets tensor info for output slot.
Operation does not change TensorInfo ownership.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tensorInfo</code></strong> :&ensp;<a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a></dt>
<dd>Output tensor info.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetTensorInfo(self, tensorInfo):
    r&#34;&#34;&#34;

    Sets tensor info for output slot.
    Operation does not change TensorInfo ownership.
    Args:
        tensorInfo (TensorInfo): Output tensor info.


    &#34;&#34;&#34;
    return _pyarmnn.IOutputSlot_SetTensorInfo(self, tensorInfo)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IProfiler"><code class="flex name class">
<span>class <span class="ident">IProfiler</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Interface for profiling Arm NN. See <a title="pyarmnn.IRuntime.GetProfiler" href="#pyarmnn.IRuntime.GetProfiler"><code>IRuntime.GetProfiler()</code></a>.</p>
<p>IProfiler object allows you to enable profiling and get various profiling results.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IProfiler(object):
    r&#34;&#34;&#34;

    Interface for profiling Arm NN. See `IRuntime.GetProfiler`.

    IProfiler object allows you to enable profiling and get various profiling results.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)

    def __init__(self, *args, **kwargs):
        raise AttributeError(&#34;No constructor defined&#34;)
    __repr__ = _swig_repr

    def EnableProfiling(self, enableProfiling):
        r&#34;&#34;&#34;

        Sets the profiler to start/stop profiling.

        Args:
            enableProfiling (bool): Flag to enable/disable profiling.


        &#34;&#34;&#34;
        return _pyarmnn.IProfiler_EnableProfiling(self, enableProfiling)

    def IsProfilingEnabled(self):
        r&#34;&#34;&#34;

        Checks if profiling is enabled.

        Returns:
            bool: If profiling is enabled or not.


        &#34;&#34;&#34;
        return _pyarmnn.IProfiler_IsProfilingEnabled(self)

    def event_log(self):
        r&#34;&#34;&#34;

        Gets the string value of the profiling events analysis log.

        Returns:
            str: The profiling events analysis log.


        &#34;&#34;&#34;
        return _pyarmnn.IProfiler_event_log(self)

    def as_json(self):
        r&#34;&#34;&#34;

        Gets the profiling log as the JSON string.

        Returns:
            str: Profiling log as JSON formatted string.


        &#34;&#34;&#34;
        return _pyarmnn.IProfiler_as_json(self)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IProfiler.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IProfiler.EnableProfiling"><code class="name flex">
<span>def <span class="ident">EnableProfiling</span></span>(<span>self, enableProfiling)</span>
</code></dt>
<dd>
<section class="desc"><p>Sets the profiler to start/stop profiling.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>enableProfiling</code></strong> :&ensp;<code>bool</code></dt>
<dd>Flag to enable/disable profiling.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def EnableProfiling(self, enableProfiling):
    r&#34;&#34;&#34;

    Sets the profiler to start/stop profiling.

    Args:
        enableProfiling (bool): Flag to enable/disable profiling.


    &#34;&#34;&#34;
    return _pyarmnn.IProfiler_EnableProfiling(self, enableProfiling)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IProfiler.IsProfilingEnabled"><code class="name flex">
<span>def <span class="ident">IsProfilingEnabled</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Checks if profiling is enabled.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>bool</code></strong></dt>
<dd>If profiling is enabled or not.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def IsProfilingEnabled(self):
    r&#34;&#34;&#34;

    Checks if profiling is enabled.

    Returns:
        bool: If profiling is enabled or not.


    &#34;&#34;&#34;
    return _pyarmnn.IProfiler_IsProfilingEnabled(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IProfiler.as_json"><code class="name flex">
<span>def <span class="ident">as_json</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the profiling log as the JSON string.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>Profiling log as JSON formatted string.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def as_json(self):
    r&#34;&#34;&#34;

    Gets the profiling log as the JSON string.

    Returns:
        str: Profiling log as JSON formatted string.


    &#34;&#34;&#34;
    return _pyarmnn.IProfiler_as_json(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IProfiler.event_log"><code class="name flex">
<span>def <span class="ident">event_log</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets the string value of the profiling events analysis log.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>str</code></strong></dt>
<dd>The profiling events analysis log.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def event_log(self):
    r&#34;&#34;&#34;

    Gets the string value of the profiling events analysis log.

    Returns:
        str: The profiling events analysis log.


    &#34;&#34;&#34;
    return _pyarmnn.IProfiler_event_log(self)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.IRuntime"><code class="flex name class">
<span>class <span class="ident">IRuntime</span></span>
<span>(</span><span>options)</span>
</code></dt>
<dd>
<section class="desc"><p>Interface for runtime objects.</p>
<p>Runtime objects are responsible for performing inference on an <a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork"><code>IOptimizedNetwork</code></a>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>options</code></strong> :&ensp;<a title="pyarmnn.CreationOptions" href="#pyarmnn.CreationOptions"><code>CreationOptions</code></a></dt>
<dd>CreationOptions data struct.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IRuntime(object):
    r&#34;&#34;&#34;

    Interface for runtime objects.

    Runtime objects are responsible for performing inference on an `IOptimizedNetwork`.

    Args:
        options (CreationOptions): CreationOptions data struct.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def GetInputTensorInfo(self, networkId, layerId):
        r&#34;&#34;&#34;

        Get information relating to networks input tensor.

        Args:
            networkId (int): Unique ID of the network being run.
            layerId (int): Unique ID of the input layer.

        Returns:
            TensorInfo: Information relating to the input tensor a network.

        &#34;&#34;&#34;
        return _pyarmnn.IRuntime_GetInputTensorInfo(self, networkId, layerId)

    def GetOutputTensorInfo(self, networkId, layerId):
        r&#34;&#34;&#34;

        Get information relating to networks output tensor.

        Args:
            networkId (int): Unique ID of the network being run.
            layerId (int): Unique ID of the output layer.

        Returns:
            TensorInfo: Information relating to the output tensor a network.

        &#34;&#34;&#34;
        return _pyarmnn.IRuntime_GetOutputTensorInfo(self, networkId, layerId)

    def GetDeviceSpec(self):
        r&#34;&#34;&#34;

        Get information relating supported compute backends on current device.

        Returns:
            IDeviceSpec: Device spec information detailing all supported backends on current platform.

        &#34;&#34;&#34;
        return _pyarmnn.IRuntime_GetDeviceSpec(self)

    def EnqueueWorkload(self, networkId, inputTensors, outputTensors):
        r&#34;&#34;&#34;

        Calling this function will perform an inference on your network.

        Args:
            networkId (int): Unique ID of the network to run.
            inputTensors (list): A list of tuples (int, ConstTensor), see `make_input_tensors`.
            outputTensors (list): A list of tuples (int, Tensor), see `make_output_tensors`.


        &#34;&#34;&#34;
        return _pyarmnn.IRuntime_EnqueueWorkload(self, networkId, inputTensors, outputTensors)

    def LoadNetwork(self, network):
        r&#34;&#34;&#34;

        Loads a complete network into the IRuntime.
        The runtime takes ownership of the network once passed in.
        Args:
            network (IOptimizedNetwork): An optimized network to load into the IRuntime.
            networkProperties (INetworkProperties): Properties that allows the user to opt-in to import/export behavior. Default: None.
        Returns:
            tuple: (int, str) Network id and non fatal failure or warning messsages.
        Raises:
            RuntimeError: If process fails.

        &#34;&#34;&#34;
        return _pyarmnn.IRuntime_LoadNetwork(self, network)

    def UnloadNetwork(self, networkId):
        r&#34;&#34;&#34;

        Unload a currently loaded network from the runtime.

        Args:
            networkId (int): Unique ID of the network to unload.


        &#34;&#34;&#34;
        return _pyarmnn.IRuntime_UnloadNetwork(self, networkId)

    def GetProfiler(self, networkId):
        r&#34;&#34;&#34;

        Returns the IProfiler instance registered against the working thread, and stored on the loaded network.
        Be aware that if the runtime has Unloaded the network, or if the runtime is destroyed,
        that the IProfiler instance will also be destroyed, and will cause a segmentation fault.

        Args:
            networkId (int): The ID of the loaded network you want to profile.

        Returns:
            IProfiler: IProfiler instance the given loaded network has stored.

        Raises:
            RuntimeError: If no profiler is found.

        &#34;&#34;&#34;
        return _pyarmnn.IRuntime_GetProfiler(self, networkId)
    __swig_destroy__ = _pyarmnn.delete_IRuntime

    def __init__(self, options):
        _pyarmnn.IRuntime_swiginit(self, _pyarmnn.new_IRuntime(options))</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.IRuntime.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.IRuntime.EnqueueWorkload"><code class="name flex">
<span>def <span class="ident">EnqueueWorkload</span></span>(<span>self, networkId, inputTensors, outputTensors)</span>
</code></dt>
<dd>
<section class="desc"><p>Calling this function will perform an inference on your network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network to run.</dd>
<dt><strong><code>inputTensors</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of tuples (int, ConstTensor), see <a title="pyarmnn.make_input_tensors" href="#pyarmnn.make_input_tensors"><code>make_input_tensors()</code></a>.</dd>
<dt><strong><code>outputTensors</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of tuples (int, Tensor), see <a title="pyarmnn.make_output_tensors" href="#pyarmnn.make_output_tensors"><code>make_output_tensors()</code></a>.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def EnqueueWorkload(self, networkId, inputTensors, outputTensors):
    r&#34;&#34;&#34;

    Calling this function will perform an inference on your network.

    Args:
        networkId (int): Unique ID of the network to run.
        inputTensors (list): A list of tuples (int, ConstTensor), see `make_input_tensors`.
        outputTensors (list): A list of tuples (int, Tensor), see `make_output_tensors`.


    &#34;&#34;&#34;
    return _pyarmnn.IRuntime_EnqueueWorkload(self, networkId, inputTensors, outputTensors)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IRuntime.GetDeviceSpec"><code class="name flex">
<span>def <span class="ident">GetDeviceSpec</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get information relating supported compute backends on current device.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IDeviceSpec" href="#pyarmnn.IDeviceSpec"><code>IDeviceSpec</code></a></strong></dt>
<dd>Device spec information detailing all supported backends on current platform.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetDeviceSpec(self):
    r&#34;&#34;&#34;

    Get information relating supported compute backends on current device.

    Returns:
        IDeviceSpec: Device spec information detailing all supported backends on current platform.

    &#34;&#34;&#34;
    return _pyarmnn.IRuntime_GetDeviceSpec(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IRuntime.GetInputTensorInfo"><code class="name flex">
<span>def <span class="ident">GetInputTensorInfo</span></span>(<span>self, networkId, layerId)</span>
</code></dt>
<dd>
<section class="desc"><p>Get information relating to networks input tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network being run.</dd>
<dt><strong><code>layerId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the input layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a></strong></dt>
<dd>Information relating to the input tensor a network.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetInputTensorInfo(self, networkId, layerId):
    r&#34;&#34;&#34;

    Get information relating to networks input tensor.

    Args:
        networkId (int): Unique ID of the network being run.
        layerId (int): Unique ID of the input layer.

    Returns:
        TensorInfo: Information relating to the input tensor a network.

    &#34;&#34;&#34;
    return _pyarmnn.IRuntime_GetInputTensorInfo(self, networkId, layerId)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IRuntime.GetOutputTensorInfo"><code class="name flex">
<span>def <span class="ident">GetOutputTensorInfo</span></span>(<span>self, networkId, layerId)</span>
</code></dt>
<dd>
<section class="desc"><p>Get information relating to networks output tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network being run.</dd>
<dt><strong><code>layerId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the output layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a></strong></dt>
<dd>Information relating to the output tensor a network.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetOutputTensorInfo(self, networkId, layerId):
    r&#34;&#34;&#34;

    Get information relating to networks output tensor.

    Args:
        networkId (int): Unique ID of the network being run.
        layerId (int): Unique ID of the output layer.

    Returns:
        TensorInfo: Information relating to the output tensor a network.

    &#34;&#34;&#34;
    return _pyarmnn.IRuntime_GetOutputTensorInfo(self, networkId, layerId)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IRuntime.GetProfiler"><code class="name flex">
<span>def <span class="ident">GetProfiler</span></span>(<span>self, networkId)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the IProfiler instance registered against the working thread, and stored on the loaded network.
Be aware that if the runtime has Unloaded the network, or if the runtime is destroyed,
that the IProfiler instance will also be destroyed, and will cause a segmentation fault.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>The ID of the loaded network you want to profile.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.IProfiler" href="#pyarmnn.IProfiler"><code>IProfiler</code></a></strong></dt>
<dd>IProfiler instance the given loaded network has stored.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If no profiler is found.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetProfiler(self, networkId):
    r&#34;&#34;&#34;

    Returns the IProfiler instance registered against the working thread, and stored on the loaded network.
    Be aware that if the runtime has Unloaded the network, or if the runtime is destroyed,
    that the IProfiler instance will also be destroyed, and will cause a segmentation fault.

    Args:
        networkId (int): The ID of the loaded network you want to profile.

    Returns:
        IProfiler: IProfiler instance the given loaded network has stored.

    Raises:
        RuntimeError: If no profiler is found.

    &#34;&#34;&#34;
    return _pyarmnn.IRuntime_GetProfiler(self, networkId)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IRuntime.LoadNetwork"><code class="name flex">
<span>def <span class="ident">LoadNetwork</span></span>(<span>self, network)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads a complete network into the IRuntime.
The runtime takes ownership of the network once passed in.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>network</code></strong> :&ensp;<a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork"><code>IOptimizedNetwork</code></a></dt>
<dd>An optimized network to load into the IRuntime.</dd>
<dt><strong><code>networkProperties</code></strong> :&ensp;<code>INetworkProperties</code></dt>
<dd>Properties that allows the user to opt-in to import/export behavior. Default: None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(int, str) Network id and non fatal failure or warning messsages.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If process fails.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def LoadNetwork(self, network):
    r&#34;&#34;&#34;

    Loads a complete network into the IRuntime.
    The runtime takes ownership of the network once passed in.
    Args:
        network (IOptimizedNetwork): An optimized network to load into the IRuntime.
        networkProperties (INetworkProperties): Properties that allows the user to opt-in to import/export behavior. Default: None.
    Returns:
        tuple: (int, str) Network id and non fatal failure or warning messsages.
    Raises:
        RuntimeError: If process fails.

    &#34;&#34;&#34;
    return _pyarmnn.IRuntime_LoadNetwork(self, network)</code></pre>
</details>
</dd>
<dt id="pyarmnn.IRuntime.UnloadNetwork"><code class="name flex">
<span>def <span class="ident">UnloadNetwork</span></span>(<span>self, networkId)</span>
</code></dt>
<dd>
<section class="desc"><p>Unload a currently loaded network from the runtime.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>networkId</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique ID of the network to unload.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def UnloadNetwork(self, networkId):
    r&#34;&#34;&#34;

    Unload a currently loaded network from the runtime.

    Args:
        networkId (int): Unique ID of the network to unload.


    &#34;&#34;&#34;
    return _pyarmnn.IRuntime_UnloadNetwork(self, networkId)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ITfLiteParser"><code class="flex name class">
<span>class <span class="ident">ITfLiteParser</span></span>
</code></dt>
<dd>
<section class="desc"><p>Interface for creating a parser object using TfLite (<a href="https://www.tensorflow.org/lite">https://www.tensorflow.org/lite</a>) tflite files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ITfLiteParser(object):
    r&#34;&#34;&#34;

    Interface for creating a parser object using TfLite (https://www.tensorflow.org/lite) tflite files.

    Parsers are used to automatically construct Arm NN graphs from model files.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def GetNetworkInputBindingInfo(self, subgraphId, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name and subgraph id.
        Args:
            subgraphId (int): The subgraph id.
            name (str): Name of the input.

        Returns:
            tuple: (`int`, `TensorInfo`).

        &#34;&#34;&#34;
        return _pyarmnn_tfliteparser.ITfLiteParser_GetNetworkInputBindingInfo(self, subgraphId, name)

    def GetNetworkOutputBindingInfo(self, subgraphId, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name and subgraph id.

        Args:
            subgraphId (int): The subgraphID.
            name (str): Name of the output.

        Returns:
            tuple: (`int`, `TensorInfo`).

        &#34;&#34;&#34;
        return _pyarmnn_tfliteparser.ITfLiteParser_GetNetworkOutputBindingInfo(self, subgraphId, name)

    def GetSubgraphCount(self):
        r&#34;&#34;&#34;

        Return the number of subgraphs in the parsed model.
        Returns:
            int: The number of subgraphs.

        &#34;&#34;&#34;
        return _pyarmnn_tfliteparser.ITfLiteParser_GetSubgraphCount(self)

    def GetSubgraphInputTensorNames(self, subgraphId):
        r&#34;&#34;&#34;

        Return the input tensor names for a given subgraph.

        Args:
            subgraphId (int): The subgraph id.

        Returns:
            list: A list of the input tensor names for the given model.

        &#34;&#34;&#34;
        return _pyarmnn_tfliteparser.ITfLiteParser_GetSubgraphInputTensorNames(self, subgraphId)

    def GetSubgraphOutputTensorNames(self, subgraphId):
        r&#34;&#34;&#34;

        Return the output tensor names for a given subgraph.

        Args:
            subgraphId (int): The subgraph id

        Returns:
            list: A list of the output tensor names for the given model.

        &#34;&#34;&#34;
        return _pyarmnn_tfliteparser.ITfLiteParser_GetSubgraphOutputTensorNames(self, subgraphId)

    def __init__(self):
        _pyarmnn_tfliteparser.ITfLiteParser_swiginit(self, _pyarmnn_tfliteparser.new_ITfLiteParser())
    __swig_destroy__ = _pyarmnn_tfliteparser.delete_ITfLiteParser

    def CreateNetworkFromBinaryFile(self, graphFile):
        r&#34;&#34;&#34;

        Create the network from a flatbuffers binary file.

        Args:
            graphFile (str): Path to the tflite model to be parsed.

        Returns:
            INetwork: Parsed network.

        Raises:
            RuntimeError: If model file was not found.

        &#34;&#34;&#34;
        return _pyarmnn_tfliteparser.ITfLiteParser_CreateNetworkFromBinaryFile(self, graphFile)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ITfLiteParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ITfLiteParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile)</span>
</code></dt>
<dd>
<section class="desc"><p>Create the network from a flatbuffers binary file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the tflite model to be parsed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork"><code>INetwork</code></a></strong></dt>
<dd>Parsed network.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If model file was not found.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CreateNetworkFromBinaryFile(self, graphFile):
    r&#34;&#34;&#34;

    Create the network from a flatbuffers binary file.

    Args:
        graphFile (str): Path to the tflite model to be parsed.

    Returns:
        INetwork: Parsed network.

    Raises:
        RuntimeError: If model file was not found.

    &#34;&#34;&#34;
    return _pyarmnn_tfliteparser.ITfLiteParser_CreateNetworkFromBinaryFile(self, graphFile)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, subgraphId, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name and subgraph id.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraph id.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the input.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>).</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkInputBindingInfo(self, subgraphId, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name and subgraph id.
    Args:
        subgraphId (int): The subgraph id.
        name (str): Name of the input.

    Returns:
        tuple: (`int`, `TensorInfo`).

    &#34;&#34;&#34;
    return _pyarmnn_tfliteparser.ITfLiteParser_GetNetworkInputBindingInfo(self, subgraphId, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, subgraphId, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name and subgraph id.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraphID.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the output.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>).</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkOutputBindingInfo(self, subgraphId, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name and subgraph id.

    Args:
        subgraphId (int): The subgraphID.
        name (str): Name of the output.

    Returns:
        tuple: (`int`, `TensorInfo`).

    &#34;&#34;&#34;
    return _pyarmnn_tfliteparser.ITfLiteParser_GetNetworkOutputBindingInfo(self, subgraphId, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetSubgraphCount"><code class="name flex">
<span>def <span class="ident">GetSubgraphCount</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Return the number of subgraphs in the parsed model.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>The number of subgraphs.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetSubgraphCount(self):
    r&#34;&#34;&#34;

    Return the number of subgraphs in the parsed model.
    Returns:
        int: The number of subgraphs.

    &#34;&#34;&#34;
    return _pyarmnn_tfliteparser.ITfLiteParser_GetSubgraphCount(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetSubgraphInputTensorNames"><code class="name flex">
<span>def <span class="ident">GetSubgraphInputTensorNames</span></span>(<span>self, subgraphId)</span>
</code></dt>
<dd>
<section class="desc"><p>Return the input tensor names for a given subgraph.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraph id.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>A list of the input tensor names for the given model.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetSubgraphInputTensorNames(self, subgraphId):
    r&#34;&#34;&#34;

    Return the input tensor names for a given subgraph.

    Args:
        subgraphId (int): The subgraph id.

    Returns:
        list: A list of the input tensor names for the given model.

    &#34;&#34;&#34;
    return _pyarmnn_tfliteparser.ITfLiteParser_GetSubgraphInputTensorNames(self, subgraphId)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ITfLiteParser.GetSubgraphOutputTensorNames"><code class="name flex">
<span>def <span class="ident">GetSubgraphOutputTensorNames</span></span>(<span>self, subgraphId)</span>
</code></dt>
<dd>
<section class="desc"><p>Return the output tensor names for a given subgraph.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subgraphId</code></strong> :&ensp;<code>int</code></dt>
<dd>The subgraph id</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>A list of the output tensor names for the given model.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetSubgraphOutputTensorNames(self, subgraphId):
    r&#34;&#34;&#34;

    Return the output tensor names for a given subgraph.

    Args:
        subgraphId (int): The subgraph id

    Returns:
        list: A list of the output tensor names for the given model.

    &#34;&#34;&#34;
    return _pyarmnn_tfliteparser.ITfLiteParser_GetSubgraphOutputTensorNames(self, subgraphId)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ITfParser"><code class="flex name class">
<span>class <span class="ident">ITfParser</span></span>
</code></dt>
<dd>
<section class="desc"><p>Interface for creating a parser object using TensorFlow (<a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a>) frozen pb files.</p>
<p>Parsers are used to automatically construct Arm NN graphs from model files.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ITfParser(object):
    r&#34;&#34;&#34;

    Interface for creating a parser object using TensorFlow (https://www.tensorflow.org/) frozen pb files.

    Parsers are used to automatically construct Arm NN graphs from model files.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def GetNetworkInputBindingInfo(self, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.

        Args:
            name (str): Name of the input.

        Returns:
            tuple: (`int`, `TensorInfo`).

        &#34;&#34;&#34;
        return _pyarmnn_tfparser.ITfParser_GetNetworkInputBindingInfo(self, name)

    def GetNetworkOutputBindingInfo(self, name):
        r&#34;&#34;&#34;

        Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.

        Args:
            name (str): Name of the output.

        Returns:
            tuple: (`int`, `TensorInfo`).

        &#34;&#34;&#34;
        return _pyarmnn_tfparser.ITfParser_GetNetworkOutputBindingInfo(self, name)

    def __init__(self):
        _pyarmnn_tfparser.ITfParser_swiginit(self, _pyarmnn_tfparser.new_ITfParser())
    __swig_destroy__ = _pyarmnn_tfparser.delete_ITfParser

    def CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs):
        r&#34;&#34;&#34;

        Create the network from a pb Protocol buffer file.

        Args:
            graphFile (str): Path to the tf model to be parsed.
            inputShapes (dict): A dict containing the input name as a key &amp; TensorShape as a value.
            requestedOutputs (list of str): A list of the output tensor names.

        Returns:
            INetwork: Parsed network.

        Raises:
            RuntimeError: If model file was not found.

        &#34;&#34;&#34;
        return _pyarmnn_tfparser.ITfParser_CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ITfParser.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.ITfParser.CreateNetworkFromBinaryFile"><code class="name flex">
<span>def <span class="ident">CreateNetworkFromBinaryFile</span></span>(<span>self, graphFile, inputShapes, requestedOutputs)</span>
</code></dt>
<dd>
<section class="desc"><p>Create the network from a pb Protocol buffer file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>graphFile</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the tf model to be parsed.</dd>
<dt><strong><code>inputShapes</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dict containing the input name as a key &amp; TensorShape as a value.</dd>
<dt><strong><code>requestedOutputs</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>A list of the output tensor names.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork"><code>INetwork</code></a></strong></dt>
<dd>Parsed network.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If model file was not found.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs):
    r&#34;&#34;&#34;

    Create the network from a pb Protocol buffer file.

    Args:
        graphFile (str): Path to the tf model to be parsed.
        inputShapes (dict): A dict containing the input name as a key &amp; TensorShape as a value.
        requestedOutputs (list of str): A list of the output tensor names.

    Returns:
        INetwork: Parsed network.

    Raises:
        RuntimeError: If model file was not found.

    &#34;&#34;&#34;
    return _pyarmnn_tfparser.ITfParser_CreateNetworkFromBinaryFile(self, graphFile, inputShapes, requestedOutputs)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ITfParser.GetNetworkInputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkInputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the input.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>).</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkInputBindingInfo(self, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network input identified by the given layer name.

    Args:
        name (str): Name of the input.

    Returns:
        tuple: (`int`, `TensorInfo`).

    &#34;&#34;&#34;
    return _pyarmnn_tfparser.ITfParser_GetNetworkInputBindingInfo(self, name)</code></pre>
</details>
</dd>
<dt id="pyarmnn.ITfParser.GetNetworkOutputBindingInfo"><code class="name flex">
<span>def <span class="ident">GetNetworkOutputBindingInfo</span></span>(<span>self, name)</span>
</code></dt>
<dd>
<section class="desc"><p>Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the output.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tuple</code></strong></dt>
<dd>(<code>int</code>, <a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>).</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNetworkOutputBindingInfo(self, name):
    r&#34;&#34;&#34;

    Retrieve binding info (layer id and tensor info) for the network output identified by the given layer name.

    Args:
        name (str): Name of the output.

    Returns:
        tuple: (`int`, `TensorInfo`).

    &#34;&#34;&#34;
    return _pyarmnn_tfparser.ITfParser_GetNetworkOutputBindingInfo(self, name)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.L2NormalizationDescriptor"><code class="flex name class">
<span>class <span class="ident">L2NormalizationDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A Descriptor for the L2Normalization layer. See <a title="pyarmnn.INetwork.AddL2NormalizationLayer" href="#pyarmnn.INetwork.AddL2NormalizationLayer"><code>INetwork.AddL2NormalizationLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Eps</code></strong> :&ensp;<code>float</code></dt>
<dd>Used to avoid dividing by zero.. Default: 1e-12f.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class L2NormalizationDescriptor(object):
    r&#34;&#34;&#34;

    A Descriptor for the L2Normalization layer. See `INetwork.AddL2NormalizationLayer()`.

    Contains:
        m_Eps (float): Used to avoid dividing by zero.. Default: 1e-12f.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.L2NormalizationDescriptor_swiginit(self, _pyarmnn.new_L2NormalizationDescriptor())
    m_Eps = property(_pyarmnn.L2NormalizationDescriptor_m_Eps_get, _pyarmnn.L2NormalizationDescriptor_m_Eps_set)
    m_DataLayout = property(_pyarmnn.L2NormalizationDescriptor_m_DataLayout_get, _pyarmnn.L2NormalizationDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_L2NormalizationDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.L2NormalizationDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.L2NormalizationDescriptor.m_Eps"><code class="name">var <span class="ident">m_Eps</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.L2NormalizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.LstmDescriptor"><code class="flex name class">
<span>class <span class="ident">LstmDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the LSTM layer. See <a title="pyarmnn.INetwork.AddLstmLayer" href="#pyarmnn.INetwork.AddLstmLayer"><code>INetwork.AddLstmLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_ActivationFunc</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. The activation function to use. 0: None, 1: Relu, 3: Relu6, 4: Tanh, 6: Sigmoid.
Default: 1.</dd>
<dt><strong><code>m_ClippingThresCell</code></strong> :&ensp;<code>float</code></dt>
<dd>Clipping threshold value for the cell state. Default: 0.0.</dd>
<dt><strong><code>m_ClippingThresProj</code></strong> :&ensp;<code>float</code></dt>
<dd>Clipping threshold value for the projection. Default: 0.0.</dd>
<dt><strong><code>m_CifgEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable cifg (coupled input &amp; forget gate). Default: true.</dd>
<dt><strong><code>m_PeepholeEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable peephole. Default: false.</dd>
<dt><strong><code>m_ProjectionEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable the projection layer. Default: false.</dd>
<dt><strong><code>m_LayerNormEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable layer normalization. Default: false.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LstmDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the LSTM layer. See `INetwork.AddLstmLayer()`.

    Contains:
        m_ActivationFunc (int): Underlying C++ data type is `uint32_t`. The activation function to use. 0: None, 1: Relu, 3: Relu6, 4: Tanh, 6: Sigmoid.
                                     Default: 1.
        m_ClippingThresCell (float): Clipping threshold value for the cell state. Default: 0.0.
        m_ClippingThresProj (float): Clipping threshold value for the projection. Default: 0.0.
        m_CifgEnabled (bool): Enable/disable cifg (coupled input &amp; forget gate). Default: true.
        m_PeepholeEnabled (bool): Enable/disable peephole. Default: false.
        m_ProjectionEnabled (bool): Enable/disable the projection layer. Default: false.
        m_LayerNormEnabled (bool): Enable/disable layer normalization. Default: false.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.LstmDescriptor_swiginit(self, _pyarmnn.new_LstmDescriptor())
    m_ActivationFunc = property(_pyarmnn.LstmDescriptor_m_ActivationFunc_get, _pyarmnn.LstmDescriptor_m_ActivationFunc_set)
    m_ClippingThresCell = property(_pyarmnn.LstmDescriptor_m_ClippingThresCell_get, _pyarmnn.LstmDescriptor_m_ClippingThresCell_set)
    m_ClippingThresProj = property(_pyarmnn.LstmDescriptor_m_ClippingThresProj_get, _pyarmnn.LstmDescriptor_m_ClippingThresProj_set)
    m_CifgEnabled = property(_pyarmnn.LstmDescriptor_m_CifgEnabled_get, _pyarmnn.LstmDescriptor_m_CifgEnabled_set)
    m_PeepholeEnabled = property(_pyarmnn.LstmDescriptor_m_PeepholeEnabled_get, _pyarmnn.LstmDescriptor_m_PeepholeEnabled_set)
    m_ProjectionEnabled = property(_pyarmnn.LstmDescriptor_m_ProjectionEnabled_get, _pyarmnn.LstmDescriptor_m_ProjectionEnabled_set)
    m_LayerNormEnabled = property(_pyarmnn.LstmDescriptor_m_LayerNormEnabled_get, _pyarmnn.LstmDescriptor_m_LayerNormEnabled_set)
    __swig_destroy__ = _pyarmnn.delete_LstmDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.LstmDescriptor.m_ActivationFunc"><code class="name">var <span class="ident">m_ActivationFunc</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_CifgEnabled"><code class="name">var <span class="ident">m_CifgEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_ClippingThresCell"><code class="name">var <span class="ident">m_ClippingThresCell</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_ClippingThresProj"><code class="name">var <span class="ident">m_ClippingThresProj</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_LayerNormEnabled"><code class="name">var <span class="ident">m_LayerNormEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_PeepholeEnabled"><code class="name">var <span class="ident">m_PeepholeEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmDescriptor.m_ProjectionEnabled"><code class="name">var <span class="ident">m_ProjectionEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.LstmInputParams"><code class="flex name class">
<span>class <span class="ident">LstmInputParams</span></span>
</code></dt>
<dd>
<section class="desc"><p>Long Short-Term Memory layer input parameters.</p>
<p>See <a title="pyarmnn.INetwork.AddLstmLayer" href="#pyarmnn.INetwork.AddLstmLayer"><code>INetwork.AddLstmLayer()</code></a>.
Operation described by the following equations:</p>
<p>[i_t=\sigma(W_{xi}x_t+W_{hi}h_{t-1}+W_{ci}C_{t-1}+b_i) \
f_t=\sigma(W_{xf}x_t+W_{hf}h_{t-1}+W_{cf}C_{t-1}+b_f) \
C_t=clip(f_t \odot C_{t-1} + i_t \odot g(W_{xc}x_t+W_{hc}h_{t-1}+b_c),\ t_{cell}) \
o_t = \sigma(W_{xo}x_t+W_{ho}h_{t-1}+W_{co}C_t+b_o)
\
h_t = clip(W_{proj}(o_t \odot g(C_t))+b_{proj},\ t_{proj})\ if\ there\ is\ a\ projection;
\
h_t = o_t \odot g(C_t)\ otherwise. ]
Where:
(x_t) - input;
(i_t) - input gate;
(f_t) - forget gate;
(C_t) - cell state;
(o_t) - output;
(h_t) - output state;
(\sigma) - logistic sigmoid function;
(g) - cell input and cell output activation function, see <a title="pyarmnn.LstmDescriptor.m_ActivationFunc" href="#pyarmnn.LstmDescriptor.m_ActivationFunc"><code>LstmDescriptor.m_ActivationFunc</code></a>;
(t_{cell}) - threshold for clipping the cell state, see <a title="pyarmnn.LstmDescriptor.m_ClippingThresCell" href="#pyarmnn.LstmDescriptor.m_ClippingThresCell"><code>LstmDescriptor.m_ClippingThresCell</code></a>;
(t_{proj}) - threshold for clipping the projected output, see <a title="pyarmnn.LstmDescriptor.m_ClippingThresProj" href="#pyarmnn.LstmDescriptor.m_ClippingThresProj"><code>LstmDescriptor.m_ClippingThresProj</code></a>;</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_InputToInputWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{xi}), input-to-input weight matrix.</dd>
<dt><strong><code>m_InputToForgetWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{xf}), input-to-forget weight matrix.</dd>
<dt><strong><code>m_InputToCellWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{xc}), input-to-cell weight matrix.</dd>
<dt><strong><code>m_InputToOutputWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{xo}), input-to-output weight matrix.</dd>
<dt><strong><code>m_RecurrentToInputWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{hi}), recurrent-to-input weight matrix.</dd>
<dt><strong><code>m_RecurrentToForgetWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{hf}), recurrent-to-forget weight matrix.</dd>
<dt><strong><code>m_RecurrentToCellWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{hc}), recurrent-to-cell weight matrix.</dd>
<dt><strong><code>m_RecurrentToOutputWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{ho}), recurrent-to-output weight matrix.</dd>
<dt><strong><code>m_CellToInputWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{ci}), cell-to-input weight matrix. Has effect if <a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled"><code>LstmDescriptor.m_PeepholeEnabled</code></a>.</dd>
<dt><strong><code>m_CellToForgetWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{cf}), cell-to-forget weight matrix. Has effect if <a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled"><code>LstmDescriptor.m_PeepholeEnabled</code></a>.</dd>
<dt><strong><code>m_CellToOutputWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{co}), cell-to-output weight matrix. Has effect if <a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled"><code>LstmDescriptor.m_PeepholeEnabled</code></a>.</dd>
<dt><strong><code>m_InputGateBias</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(b_i), input gate bias.</dd>
<dt><strong><code>m_ForgetGateBias</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(b_f), forget gate bias.</dd>
<dt><strong><code>m_CellBias</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(b_c), cell bias.</dd>
<dt><strong><code>m_OutputGateBias</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(b_o),
output gate bias.</dd>
<dt><strong><code>m_ProjectionWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(W_{proj}), projection weight matrix.
Has effect if <a title="pyarmnn.LstmDescriptor.m_ProjectionEnabled" href="#pyarmnn.LstmDescriptor.m_ProjectionEnabled"><code>LstmDescriptor.m_ProjectionEnabled</code></a> is set to True.</dd>
<dt><strong><code>m_ProjectionBias</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>(b_{proj}), projection bias.
Has effect if <a title="pyarmnn.LstmDescriptor.m_ProjectionEnabled" href="#pyarmnn.LstmDescriptor.m_ProjectionEnabled"><code>LstmDescriptor.m_ProjectionEnabled</code></a> is set to True.</dd>
<dt><strong><code>m_InputLayerNormWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>normalisation weights for input,
has effect if <a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled"><code>LstmDescriptor.m_LayerNormEnabled</code></a> set to True.</dd>
<dt><strong><code>m_ForgetLayerNormWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>normalisation weights for forget gate,
has effect if <a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled"><code>LstmDescriptor.m_LayerNormEnabled</code></a> set to True.</dd>
<dt><strong><code>m_CellLayerNormWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>normalisation weights for current cell,
has effect if <a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled"><code>LstmDescriptor.m_LayerNormEnabled</code></a> set to True.</dd>
<dt><strong><code>m_OutputLayerNormWeights</code></strong> :&ensp;<a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor"><code>ConstTensor</code></a></dt>
<dd>normalisation weights for output gate,
has effect if <a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled"><code>LstmDescriptor.m_LayerNormEnabled</code></a> set to True.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LstmInputParams(object):
    r&#34;&#34;&#34;

    Long Short-Term Memory layer input parameters.

    See `INetwork.AddLstmLayer()`.
    Operation described by the following equations:

     \[i_t=\sigma(W_{xi}x_t+W_{hi}h_{t-1}+W_{ci}C_{t-1}+b_i) \\
        f_t=\sigma(W_{xf}x_t+W_{hf}h_{t-1}+W_{cf}C_{t-1}+b_f) \\
        C_t=clip(f_t \odot C_{t-1} + i_t \odot g(W_{xc}x_t+W_{hc}h_{t-1}+b_c),\ t_{cell}) \\
        o_t = \sigma(W_{xo}x_t+W_{ho}h_{t-1}+W_{co}C_t+b_o)  \\
        h_t = clip(W_{proj}(o_t \odot g(C_t))+b_{proj},\ t_{proj})\ if\ there\ is\ a\ projection;  \\
        h_t = o_t \odot g(C_t)\ otherwise. \]
        Where:
        \(x_t\) - input;
        \(i_t\) - input gate;
        \(f_t\) - forget gate;
        \(C_t\) - cell state;
        \(o_t\) - output;
        \(h_t\) - output state;
        \(\sigma\) - logistic sigmoid function;
        \(g\) - cell input and cell output activation function, see `LstmDescriptor.m_ActivationFunc`;
        \(t_{cell}\) - threshold for clipping the cell state, see `LstmDescriptor.m_ClippingThresCell`;
        \(t_{proj}\) - threshold for clipping the projected output, see `LstmDescriptor.m_ClippingThresProj`;

    Contains:
        m_InputToInputWeights (ConstTensor): \(W_{xi}\), input-to-input weight matrix.
        m_InputToForgetWeights (ConstTensor): \(W_{xf}\), input-to-forget weight matrix.
        m_InputToCellWeights (ConstTensor): \(W_{xc}\), input-to-cell weight matrix.
        m_InputToOutputWeights (ConstTensor): \(W_{xo}\), input-to-output weight matrix.

        m_RecurrentToInputWeights (ConstTensor): \(W_{hi}\), recurrent-to-input weight matrix.
        m_RecurrentToForgetWeights (ConstTensor): \(W_{hf}\), recurrent-to-forget weight matrix.
        m_RecurrentToCellWeights (ConstTensor): \(W_{hc}\), recurrent-to-cell weight matrix.
        m_RecurrentToOutputWeights (ConstTensor): \(W_{ho}\), recurrent-to-output weight matrix.

        m_CellToInputWeights (ConstTensor): \(W_{ci}\), cell-to-input weight matrix. Has effect if `LstmDescriptor.m_PeepholeEnabled`.
        m_CellToForgetWeights (ConstTensor): \(W_{cf}\), cell-to-forget weight matrix. Has effect if `LstmDescriptor.m_PeepholeEnabled`.
        m_CellToOutputWeights (ConstTensor): \(W_{co}\), cell-to-output weight matrix. Has effect if `LstmDescriptor.m_PeepholeEnabled`.

        m_InputGateBias (ConstTensor): \(b_i\), input gate bias.
        m_ForgetGateBias (ConstTensor): \(b_f\), forget gate bias.
        m_CellBias (ConstTensor): \(b_c\), cell bias.
        m_OutputGateBias (ConstTensor): \(b_o\),  output gate bias.

        m_ProjectionWeights (ConstTensor): \(W_{proj}\), projection weight matrix.
                                           Has effect if `LstmDescriptor.m_ProjectionEnabled` is set to True.
        m_ProjectionBias (ConstTensor): \(b_{proj}\), projection bias.
                                        Has effect if `LstmDescriptor.m_ProjectionEnabled` is set to True.
        m_InputLayerNormWeights (ConstTensor): normalisation weights for input,
                                               has effect if `LstmDescriptor.m_LayerNormEnabled` set to True.
        m_ForgetLayerNormWeights (ConstTensor): normalisation weights for forget gate,
                                                has effect if `LstmDescriptor.m_LayerNormEnabled` set to True.
        m_CellLayerNormWeights (ConstTensor): normalisation weights for current cell,
                                              has effect if `LstmDescriptor.m_LayerNormEnabled` set to True.
        m_OutputLayerNormWeights (ConstTensor): normalisation weights for output gate,
                                                has effect if `LstmDescriptor.m_LayerNormEnabled` set to True.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.LstmInputParams_swiginit(self, _pyarmnn.new_LstmInputParams())
    m_InputToInputWeights = property(_pyarmnn.LstmInputParams_m_InputToInputWeights_get, _pyarmnn.LstmInputParams_m_InputToInputWeights_set)
    m_InputToForgetWeights = property(_pyarmnn.LstmInputParams_m_InputToForgetWeights_get, _pyarmnn.LstmInputParams_m_InputToForgetWeights_set)
    m_InputToCellWeights = property(_pyarmnn.LstmInputParams_m_InputToCellWeights_get, _pyarmnn.LstmInputParams_m_InputToCellWeights_set)
    m_InputToOutputWeights = property(_pyarmnn.LstmInputParams_m_InputToOutputWeights_get, _pyarmnn.LstmInputParams_m_InputToOutputWeights_set)
    m_RecurrentToInputWeights = property(_pyarmnn.LstmInputParams_m_RecurrentToInputWeights_get, _pyarmnn.LstmInputParams_m_RecurrentToInputWeights_set)
    m_RecurrentToForgetWeights = property(_pyarmnn.LstmInputParams_m_RecurrentToForgetWeights_get, _pyarmnn.LstmInputParams_m_RecurrentToForgetWeights_set)
    m_RecurrentToCellWeights = property(_pyarmnn.LstmInputParams_m_RecurrentToCellWeights_get, _pyarmnn.LstmInputParams_m_RecurrentToCellWeights_set)
    m_RecurrentToOutputWeights = property(_pyarmnn.LstmInputParams_m_RecurrentToOutputWeights_get, _pyarmnn.LstmInputParams_m_RecurrentToOutputWeights_set)
    m_CellToInputWeights = property(_pyarmnn.LstmInputParams_m_CellToInputWeights_get, _pyarmnn.LstmInputParams_m_CellToInputWeights_set)
    m_CellToForgetWeights = property(_pyarmnn.LstmInputParams_m_CellToForgetWeights_get, _pyarmnn.LstmInputParams_m_CellToForgetWeights_set)
    m_CellToOutputWeights = property(_pyarmnn.LstmInputParams_m_CellToOutputWeights_get, _pyarmnn.LstmInputParams_m_CellToOutputWeights_set)
    m_InputGateBias = property(_pyarmnn.LstmInputParams_m_InputGateBias_get, _pyarmnn.LstmInputParams_m_InputGateBias_set)
    m_ForgetGateBias = property(_pyarmnn.LstmInputParams_m_ForgetGateBias_get, _pyarmnn.LstmInputParams_m_ForgetGateBias_set)
    m_CellBias = property(_pyarmnn.LstmInputParams_m_CellBias_get, _pyarmnn.LstmInputParams_m_CellBias_set)
    m_OutputGateBias = property(_pyarmnn.LstmInputParams_m_OutputGateBias_get, _pyarmnn.LstmInputParams_m_OutputGateBias_set)
    m_ProjectionWeights = property(_pyarmnn.LstmInputParams_m_ProjectionWeights_get, _pyarmnn.LstmInputParams_m_ProjectionWeights_set)
    m_ProjectionBias = property(_pyarmnn.LstmInputParams_m_ProjectionBias_get, _pyarmnn.LstmInputParams_m_ProjectionBias_set)
    m_InputLayerNormWeights = property(_pyarmnn.LstmInputParams_m_InputLayerNormWeights_get, _pyarmnn.LstmInputParams_m_InputLayerNormWeights_set)
    m_ForgetLayerNormWeights = property(_pyarmnn.LstmInputParams_m_ForgetLayerNormWeights_get, _pyarmnn.LstmInputParams_m_ForgetLayerNormWeights_set)
    m_CellLayerNormWeights = property(_pyarmnn.LstmInputParams_m_CellLayerNormWeights_get, _pyarmnn.LstmInputParams_m_CellLayerNormWeights_set)
    m_OutputLayerNormWeights = property(_pyarmnn.LstmInputParams_m_OutputLayerNormWeights_get, _pyarmnn.LstmInputParams_m_OutputLayerNormWeights_set)
    __swig_destroy__ = _pyarmnn.delete_LstmInputParams</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.LstmInputParams.m_CellBias"><code class="name">var <span class="ident">m_CellBias</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellLayerNormWeights"><code class="name">var <span class="ident">m_CellLayerNormWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellToForgetWeights"><code class="name">var <span class="ident">m_CellToForgetWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellToInputWeights"><code class="name">var <span class="ident">m_CellToInputWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_CellToOutputWeights"><code class="name">var <span class="ident">m_CellToOutputWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ForgetGateBias"><code class="name">var <span class="ident">m_ForgetGateBias</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ForgetLayerNormWeights"><code class="name">var <span class="ident">m_ForgetLayerNormWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputGateBias"><code class="name">var <span class="ident">m_InputGateBias</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputLayerNormWeights"><code class="name">var <span class="ident">m_InputLayerNormWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToCellWeights"><code class="name">var <span class="ident">m_InputToCellWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToForgetWeights"><code class="name">var <span class="ident">m_InputToForgetWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToInputWeights"><code class="name">var <span class="ident">m_InputToInputWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_InputToOutputWeights"><code class="name">var <span class="ident">m_InputToOutputWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_OutputGateBias"><code class="name">var <span class="ident">m_OutputGateBias</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_OutputLayerNormWeights"><code class="name">var <span class="ident">m_OutputLayerNormWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ProjectionBias"><code class="name">var <span class="ident">m_ProjectionBias</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_ProjectionWeights"><code class="name">var <span class="ident">m_ProjectionWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToCellWeights"><code class="name">var <span class="ident">m_RecurrentToCellWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToForgetWeights"><code class="name">var <span class="ident">m_RecurrentToForgetWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToInputWeights"><code class="name">var <span class="ident">m_RecurrentToInputWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.m_RecurrentToOutputWeights"><code class="name">var <span class="ident">m_RecurrentToOutputWeights</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.LstmInputParams.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.MeanDescriptor"><code class="flex name class">
<span>class <span class="ident">MeanDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Mean layer. See <a title="pyarmnn.INetwork.AddMeanLayer" href="#pyarmnn.INetwork.AddMeanLayer"><code>INetwork.AddMeanLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Axis</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>Underlying C++ data type is std::vector<unsigned int>. Used to avoid dividing by zero. Values for the dimensions to reduce.</dd>
<dt><strong><code>m_KeepDims</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable keep dimensions. If true, then the reduced dimensions that are of length 1 are kept. Default: False.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MeanDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Mean layer. See `INetwork.AddMeanLayer()`.

    Contains:
        m_Axis (list of int): Underlying C++ data type is std::vector&lt;unsigned int&gt;. Used to avoid dividing by zero. Values for the dimensions to reduce.
        m_KeepDims (bool): Enable/disable keep dimensions. If true, then the reduced dimensions that are of length 1 are kept. Default: False.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.MeanDescriptor_swiginit(self, _pyarmnn.new_MeanDescriptor(*args))
    m_Axis = property(_pyarmnn.MeanDescriptor_m_Axis_get, _pyarmnn.MeanDescriptor_m_Axis_set)
    m_KeepDims = property(_pyarmnn.MeanDescriptor_m_KeepDims_get, _pyarmnn.MeanDescriptor_m_KeepDims_set)
    __swig_destroy__ = _pyarmnn.delete_MeanDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.MeanDescriptor.m_Axis"><code class="name">var <span class="ident">m_Axis</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.MeanDescriptor.m_KeepDims"><code class="name">var <span class="ident">m_KeepDims</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.MeanDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.NormalizationDescriptor"><code class="flex name class">
<span>class <span class="ident">NormalizationDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Normalization layer. See <a title="pyarmnn.INetwork.AddNormalizationLayer" href="#pyarmnn.INetwork.AddNormalizationLayer"><code>INetwork.AddNormalizationLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_NormChannelType</code></strong> :&ensp;<code>int</code></dt>
<dd>Normalization channel algorithm to use (NormalizationAlgorithmMethod_Across, NormalizationAlgorithmMethod_Within).
Default: NormalizationAlgorithmChannel_Across.</dd>
<dt><strong><code>m_NormMethodType</code></strong> :&ensp;<code>int</code></dt>
<dd>Normalization method algorithm to use (NormalizationAlgorithmMethod_LocalBrightness, NormalizationAlgorithmMethod_LocalContrast).
Default: NormalizationAlgorithmMethod_LocalBrightness.</dd>
<dt><strong><code>m_NormSize</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Depth radius value. Default: 0.</dd>
<dt><strong><code>m_Alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>Alpha value for the normalization equation. Default: 0.0.</dd>
<dt><strong><code>m_Beta</code></strong> :&ensp;<code>float</code></dt>
<dd>Beta value for the normalization equation. Default: 0.0.</dd>
<dt><strong><code>m_K</code></strong> :&ensp;<code>float</code></dt>
<dd>Kappa value used for the across channel normalization equation. Default: 0.0.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NormalizationDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Normalization layer. See `INetwork.AddNormalizationLayer()`.

    Contains:
        m_NormChannelType (int): Normalization channel algorithm to use (NormalizationAlgorithmMethod_Across, NormalizationAlgorithmMethod_Within).
                                                           Default: NormalizationAlgorithmChannel_Across.
        m_NormMethodType (int): Normalization method algorithm to use (NormalizationAlgorithmMethod_LocalBrightness, NormalizationAlgorithmMethod_LocalContrast).
                                                         Default: NormalizationAlgorithmMethod_LocalBrightness.
        m_NormSize (int): Underlying C++ data type is `uint32_t`. Depth radius value. Default: 0.
        m_Alpha (float): Alpha value for the normalization equation. Default: 0.0.
        m_Beta (float): Beta value for the normalization equation. Default: 0.0.
        m_K (float): Kappa value used for the across channel normalization equation. Default: 0.0.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.NormalizationDescriptor_swiginit(self, _pyarmnn.new_NormalizationDescriptor())
    m_NormChannelType = property(_pyarmnn.NormalizationDescriptor_m_NormChannelType_get, _pyarmnn.NormalizationDescriptor_m_NormChannelType_set)
    m_NormMethodType = property(_pyarmnn.NormalizationDescriptor_m_NormMethodType_get, _pyarmnn.NormalizationDescriptor_m_NormMethodType_set)
    m_NormSize = property(_pyarmnn.NormalizationDescriptor_m_NormSize_get, _pyarmnn.NormalizationDescriptor_m_NormSize_set)
    m_Alpha = property(_pyarmnn.NormalizationDescriptor_m_Alpha_get, _pyarmnn.NormalizationDescriptor_m_Alpha_set)
    m_Beta = property(_pyarmnn.NormalizationDescriptor_m_Beta_get, _pyarmnn.NormalizationDescriptor_m_Beta_set)
    m_K = property(_pyarmnn.NormalizationDescriptor_m_K_get, _pyarmnn.NormalizationDescriptor_m_K_set)
    m_DataLayout = property(_pyarmnn.NormalizationDescriptor_m_DataLayout_get, _pyarmnn.NormalizationDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_NormalizationDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.NormalizationDescriptor.m_Alpha"><code class="name">var <span class="ident">m_Alpha</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_Beta"><code class="name">var <span class="ident">m_Beta</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_K"><code class="name">var <span class="ident">m_K</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_NormChannelType"><code class="name">var <span class="ident">m_NormChannelType</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_NormMethodType"><code class="name">var <span class="ident">m_NormMethodType</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.m_NormSize"><code class="name">var <span class="ident">m_NormSize</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.NormalizationDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.OptimizerOptions"><code class="flex name class">
<span>class <span class="ident">OptimizerOptions</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>Struct for holding options relating to the Arm NN optimizer. See <a title="pyarmnn.Optimize" href="#pyarmnn.Optimize"><code>Optimize()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_debug</code></strong> :&ensp;<code>bool</code></dt>
<dd>&hellip;</dd>
<dt><strong><code>m_ReduceFp32ToFp16</code></strong> :&ensp;<code>bool</code></dt>
<dd>&hellip;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OptimizerOptions(object):
    r&#34;&#34;&#34;

    Struct for holding options relating to the Arm NN optimizer. See `Optimize`.

    Contains:
        m_debug (bool): ...
        m_ReduceFp32ToFp16 (bool): ...


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.OptimizerOptions_swiginit(self, _pyarmnn.new_OptimizerOptions(*args))
    m_ReduceFp32ToFp16 = property(_pyarmnn.OptimizerOptions_m_ReduceFp32ToFp16_get, _pyarmnn.OptimizerOptions_m_ReduceFp32ToFp16_set)
    m_Debug = property(_pyarmnn.OptimizerOptions_m_Debug_get, _pyarmnn.OptimizerOptions_m_Debug_set)
    __swig_destroy__ = _pyarmnn.delete_OptimizerOptions</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.OptimizerOptions.m_Debug"><code class="name">var <span class="ident">m_Debug</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.OptimizerOptions.m_ReduceFp32ToFp16"><code class="name">var <span class="ident">m_ReduceFp32ToFp16</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.OptimizerOptions.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.PadDescriptor"><code class="flex name class">
<span>class <span class="ident">PadDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Pad layer. See <a title="pyarmnn.INetwork.AddPadLayer" href="#pyarmnn.INetwork.AddPadLayer"><code>INetwork.AddPadLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_PadList</code></strong> :&ensp;<code>list</code> of <code>tuple</code></dt>
<dd>specifies the padding for input dimension.
The first tuple value is the number of values to add before the tensor in the dimension.
The second tuple value is the number of values to add after the tensor in the dimension.
The number of pairs should match the number of dimensions in the input tensor.</dd>
<dt><strong><code>m_PadValue</code></strong> :&ensp;<code>bool</code></dt>
<dd>Optional value to use for padding. Default: 0.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PadDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Pad layer. See `INetwork.AddPadLayer()`.

    Contains:
        m_PadList (list of tuple): specifies the padding for input dimension.
                                   The first tuple value is the number of values to add before the tensor in the dimension.
                                   The second tuple value is the number of values to add after the tensor in the dimension.
                                   The number of pairs should match the number of dimensions in the input tensor.
        m_PadValue (bool): Optional value to use for padding. Default: 0.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.PadDescriptor_swiginit(self, _pyarmnn.new_PadDescriptor(*args))
    m_PadList = property(_pyarmnn.PadDescriptor_m_PadList_get, _pyarmnn.PadDescriptor_m_PadList_set)
    m_PadValue = property(_pyarmnn.PadDescriptor_m_PadValue_get, _pyarmnn.PadDescriptor_m_PadValue_set)
    __swig_destroy__ = _pyarmnn.delete_PadDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.PadDescriptor.m_PadList"><code class="name">var <span class="ident">m_PadList</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.PadDescriptor.m_PadValue"><code class="name">var <span class="ident">m_PadValue</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.PadDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.PermutationVector"><code class="flex name class">
<span>class <span class="ident">PermutationVector</span></span>
<span>(</span><span>dimMappings)</span>
</code></dt>
<dd>
<section class="desc"><p>Vector used to permute a tensor.</p>
<p>For a 4-d tensor laid out in a memory with the format (Batch Element, Height, Width, Channels),
which is to be passed as an input to Arm NN, each source dimension is mapped to the corresponding
Arm NN dimension. The Batch dimension remains the same (0 -&gt; 0). The source Height dimension is mapped
to the location of the ArmNN Height dimension (1 -&gt; 2). Similar arguments are made for the Width and
Channels (2 -&gt; 3 and 3 -&gt; 1). This will lead to m_DimMappings pointing to the following array:
[ 0, 2, 3, 1 ].</p>
<p>Note that the mapping should be reversed if considering the case of Arm NN 4-d outputs (Batch Element,
Channels, Height, Width) being written to a destination with the format mentioned above. We now have
0 -&gt; 0, 2 -&gt; 1, 3 -&gt; 2, 1 -&gt; 3, which, when reordered, lead to the following m_DimMappings contents:
[ 0, 3, 1, 2 ].</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dimMappings</code></strong> :&ensp;<code>list</code></dt>
<dd>Indicates how to translate tensor elements from a given source into the target destination,
when source and target potentially have different memory layouts.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PermutationVector(object):
    r&#34;&#34;&#34;

    Vector used to permute a tensor.

    For a 4-d tensor laid out in a memory with the format (Batch Element, Height, Width, Channels),
    which is to be passed as an input to Arm NN, each source dimension is mapped to the corresponding
    Arm NN dimension. The Batch dimension remains the same (0 -&gt; 0). The source Height dimension is mapped
    to the location of the ArmNN Height dimension (1 -&gt; 2). Similar arguments are made for the Width and
    Channels (2 -&gt; 3 and 3 -&gt; 1). This will lead to m_DimMappings pointing to the following array:
    [ 0, 2, 3, 1 ].

    Note that the mapping should be reversed if considering the case of Arm NN 4-d outputs (Batch Element,
    Channels, Height, Width) being written to a destination with the format mentioned above. We now have
    0 -&gt; 0, 2 -&gt; 1, 3 -&gt; 2, 1 -&gt; 3, which, when reordered, lead to the following m_DimMappings contents:
    [ 0, 3, 1, 2 ].

    Args:
        dimMappings (list): Indicates how to translate tensor elements from a given source into the target destination,
                            when source and target potentially have different memory layouts.

    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, dimMappings):
        _pyarmnn.PermutationVector_swiginit(self, _pyarmnn.new_PermutationVector(dimMappings))

    def GetSize(self):
        r&#34;&#34;&#34;

        Get the PermutationVector size.

        Return:
            SizeType: Current size of the PermutationVector.


        &#34;&#34;&#34;
        return _pyarmnn.PermutationVector_GetSize(self)

    def IsInverse(self, other):
        r&#34;&#34;&#34;

        Checks if a specified permutation vector is its inverse

        Return:
            bool: returns true if the specified Permutation vector is its inverse.


        &#34;&#34;&#34;
        return _pyarmnn.PermutationVector_IsInverse(self, other)

    def __getitem__(self, i):
        return _pyarmnn.PermutationVector___getitem__(self, i)

    def __eq__(self, other):
        return _pyarmnn.PermutationVector___eq__(self, other)
    __swig_destroy__ = _pyarmnn.delete_PermutationVector</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.PermutationVector.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.PermutationVector.GetSize"><code class="name flex">
<span>def <span class="ident">GetSize</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the PermutationVector size.</p>
<h2 id="return">Return</h2>
<dl>
<dt><strong><code>SizeType</code></strong></dt>
<dd>Current size of the PermutationVector.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetSize(self):
    r&#34;&#34;&#34;

    Get the PermutationVector size.

    Return:
        SizeType: Current size of the PermutationVector.


    &#34;&#34;&#34;
    return _pyarmnn.PermutationVector_GetSize(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.PermutationVector.IsInverse"><code class="name flex">
<span>def <span class="ident">IsInverse</span></span>(<span>self, other)</span>
</code></dt>
<dd>
<section class="desc"><p>Checks if a specified permutation vector is its inverse</p>
<h2 id="return">Return</h2>
<dl>
<dt><strong><code>bool</code></strong></dt>
<dd>returns true if the specified Permutation vector is its inverse.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def IsInverse(self, other):
    r&#34;&#34;&#34;

    Checks if a specified permutation vector is its inverse

    Return:
        bool: returns true if the specified Permutation vector is its inverse.


    &#34;&#34;&#34;
    return _pyarmnn.PermutationVector_IsInverse(self, other)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.PermuteDescriptor"><code class="flex name class">
<span>class <span class="ident">PermuteDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Permute layer. See <a title="pyarmnn.INetwork.AddPermuteLayer" href="#pyarmnn.INetwork.AddPermuteLayer"><code>INetwork.AddPermuteLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_DimMappings</code></strong> :&ensp;<a title="pyarmnn.PermutationVector" href="#pyarmnn.PermutationVector"><code>PermutationVector</code></a></dt>
<dd>Indicates how to translate tensor elements from a given source into the target destination,
when source and target potentially have different memory layouts e.g. {0U, 3U, 1U, 2U}.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PermuteDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Permute layer. See `INetwork.AddPermuteLayer()`.

    Contains:
        m_DimMappings (PermutationVector): Indicates how to translate tensor elements from a given source into the target destination,
                                           when source and target potentially have different memory layouts e.g. {0U, 3U, 1U, 2U}.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.PermuteDescriptor_swiginit(self, _pyarmnn.new_PermuteDescriptor(*args))
    m_DimMappings = property(_pyarmnn.PermuteDescriptor_m_DimMappings_get, _pyarmnn.PermuteDescriptor_m_DimMappings_set)
    __swig_destroy__ = _pyarmnn.delete_PermuteDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.PermuteDescriptor.m_DimMappings"><code class="name">var <span class="ident">m_DimMappings</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.PermuteDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor"><code class="flex name class">
<span>class <span class="ident">Pooling2dDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Pooling2d layer. See <a title="pyarmnn.INetwork.AddPooling2dLayer" href="#pyarmnn.INetwork.AddPooling2dLayer"><code>INetwork.AddPooling2dLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_PoolType</code></strong> :&ensp;<code>int</code></dt>
<dd>The pooling algorithm to use (<code>PoolingAlgorithm_Max</code>, <code>PoolingAlgorithm_Average</code>, <code>PoolingAlgorithm_L2</code>). Default: <code>PoolingAlgorithm_Max</code>.</dd>
<dt><strong><code>m_PadLeft</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadRight</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadTop</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_PadBottom</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_PoolWidth</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Pooling width value. Default: 0.</dd>
<dt><strong><code>m_PoolHeight</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Pooling height value. Default: 0.</dd>
<dt><strong><code>m_StrideX</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.</dd>
<dt><strong><code>m_StrideY</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.</dd>
<dt><strong><code>m_OutputShapeRounding</code></strong> :&ensp;<code>int</code></dt>
<dd>The rounding method for the output shape. (OutputShapeRounding_Floor, OutputShapeRounding_Ceiling).
Default: OutputShapeRounding_Floor.</dd>
<dt><strong><code>m_PaddingMethod</code></strong> :&ensp;<code>int</code></dt>
<dd>The padding method to be used. (PaddingMethod_Exclude, PaddingMethod_IgnoreValue).
Default: PaddingMethod_Exclude.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Pooling2dDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Pooling2d layer. See `INetwork.AddPooling2dLayer()`.

    Contains:
        m_PoolType (int): The pooling algorithm to use (`PoolingAlgorithm_Max`, `PoolingAlgorithm_Average`, `PoolingAlgorithm_L2`). Default: `PoolingAlgorithm_Max`.
        m_PadLeft (int): Underlying C++ data type is `uint32_t`. Padding left value in the width dimension. Default: 0.
        m_PadRight (int): Underlying C++ data type is `uint32_t`. Padding right value in the width dimension. Default: 0.
        m_PadTop (int): Underlying C++ data type is `uint32_t`. Padding top value in the height dimension. Default: 0.
        m_PadBottom (int): Underlying C++ data type is `uint32_t`. Padding bottom value in the height dimension. Default: 0.
        m_PoolWidth (int): Underlying C++ data type is `uint32_t`. Pooling width value. Default: 0.
        m_PoolHeight (int): Underlying C++ data type is `uint32_t`. Pooling height value. Default: 0.
        m_StrideX (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the width dimension. Default: 0.
        m_StrideY (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the height dimension. Default: 0.
        m_OutputShapeRounding (int):  The rounding method for the output shape. (OutputShapeRounding_Floor, OutputShapeRounding_Ceiling).
                                                      Default: OutputShapeRounding_Floor.
        m_PaddingMethod (int): The padding method to be used. (PaddingMethod_Exclude, PaddingMethod_IgnoreValue).
                                         Default: PaddingMethod_Exclude.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.Pooling2dDescriptor_swiginit(self, _pyarmnn.new_Pooling2dDescriptor())
    m_PoolType = property(_pyarmnn.Pooling2dDescriptor_m_PoolType_get, _pyarmnn.Pooling2dDescriptor_m_PoolType_set)
    m_PadLeft = property(_pyarmnn.Pooling2dDescriptor_m_PadLeft_get, _pyarmnn.Pooling2dDescriptor_m_PadLeft_set)
    m_PadRight = property(_pyarmnn.Pooling2dDescriptor_m_PadRight_get, _pyarmnn.Pooling2dDescriptor_m_PadRight_set)
    m_PadTop = property(_pyarmnn.Pooling2dDescriptor_m_PadTop_get, _pyarmnn.Pooling2dDescriptor_m_PadTop_set)
    m_PadBottom = property(_pyarmnn.Pooling2dDescriptor_m_PadBottom_get, _pyarmnn.Pooling2dDescriptor_m_PadBottom_set)
    m_PoolWidth = property(_pyarmnn.Pooling2dDescriptor_m_PoolWidth_get, _pyarmnn.Pooling2dDescriptor_m_PoolWidth_set)
    m_PoolHeight = property(_pyarmnn.Pooling2dDescriptor_m_PoolHeight_get, _pyarmnn.Pooling2dDescriptor_m_PoolHeight_set)
    m_StrideX = property(_pyarmnn.Pooling2dDescriptor_m_StrideX_get, _pyarmnn.Pooling2dDescriptor_m_StrideX_set)
    m_StrideY = property(_pyarmnn.Pooling2dDescriptor_m_StrideY_get, _pyarmnn.Pooling2dDescriptor_m_StrideY_set)
    m_OutputShapeRounding = property(_pyarmnn.Pooling2dDescriptor_m_OutputShapeRounding_get, _pyarmnn.Pooling2dDescriptor_m_OutputShapeRounding_set)
    m_PaddingMethod = property(_pyarmnn.Pooling2dDescriptor_m_PaddingMethod_get, _pyarmnn.Pooling2dDescriptor_m_PaddingMethod_set)
    m_DataLayout = property(_pyarmnn.Pooling2dDescriptor_m_DataLayout_get, _pyarmnn.Pooling2dDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_Pooling2dDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.Pooling2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_OutputShapeRounding"><code class="name">var <span class="ident">m_OutputShapeRounding</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PaddingMethod"><code class="name">var <span class="ident">m_PaddingMethod</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PoolHeight"><code class="name">var <span class="ident">m_PoolHeight</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PoolType"><code class="name">var <span class="ident">m_PoolType</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_PoolWidth"><code class="name">var <span class="ident">m_PoolWidth</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.Pooling2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ProfilerData"><code class="flex name class">
<span>class <span class="ident">ProfilerData</span></span>
<span>(</span><span>inference_data, per_workload_execution_data)</span>
</code></dt>
<dd>
<section class="desc"><p>Container to hold the profiling inference data, and the profiling data per workload.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>inference_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>holds end-to-end inference performance data. Keys:
'time_unit' - timer units.
'execution_time' - list of total inference execution times for each inference run.
</dd>
<dt><strong><code>per_workload_execution_data</code></strong> :&ensp;<code>dict</code></dt>
<dd>holds per operation performance data, key is a operation name
Each operation has
'time_unit' - timer units. <br>
'execution_time' - list of total execution times for each inference run.
'backend' - backend used for this operation.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code>&gt;&gt;&gt; data = get_profiling_data(profiler)
&gt;&gt;&gt; print(data)
&gt;&gt;&gt; ProfilerData(inference_data={'time_unit': 'us', 
                                 'execution_time': [8901372.972]},


            per_workload_execution_data={'CopyMemGeneric_Execute_#3': {'time_unit': 'us', 
                                                                       'execution_time': [28.941], 
                                                                       'backend': 'Unknown'}, 
                                         'RefConvolution2dWorkload_Execute_#5': {'time_unit': 'us', 
                                                                                 'execution_time': [126838.071], 
                                                                                 'backend': 'CpuRef'}, 
                                         'RefDepthwiseConvolution2dWorkload_Execute_#6': {'time_unit': 'us', 
                                                                                          'execution_time': [49886.208], 
                                                                                          'backend': 'CpuRef'}
                                         ...etc
                                         }
            )
</code></pre></section>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ProfilerData.inference_data"><code class="name">var <span class="ident">inference_data</span></code></dt>
<dd>
<section class="desc"><p>Alias for field number 0</p></section>
</dd>
<dt id="pyarmnn.ProfilerData.per_workload_execution_data"><code class="name">var <span class="ident">per_workload_execution_data</span></code></dt>
<dd>
<section class="desc"><p>Alias for field number 1</p></section>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ReshapeDescriptor"><code class="flex name class">
<span>class <span class="ident">ReshapeDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Reshape layer. See <a title="pyarmnn.INetwork.AddReshapeLayer" href="#pyarmnn.INetwork.AddReshapeLayer"><code>INetwork.AddReshapeLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_TargetShape</code></strong> :&ensp;<a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape"><code>TensorShape</code></a></dt>
<dd>Target shape value.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ReshapeDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Reshape layer. See `INetwork.AddReshapeLayer()`.

    Contains:
        m_TargetShape (TensorShape): Target shape value.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.ReshapeDescriptor_swiginit(self, _pyarmnn.new_ReshapeDescriptor(*args))
    m_TargetShape = property(_pyarmnn.ReshapeDescriptor_m_TargetShape_get, _pyarmnn.ReshapeDescriptor_m_TargetShape_set)
    __swig_destroy__ = _pyarmnn.delete_ReshapeDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ReshapeDescriptor.m_TargetShape"><code class="name">var <span class="ident">m_TargetShape</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ReshapeDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.ResizeDescriptor"><code class="flex name class">
<span>class <span class="ident">ResizeDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Resize layer. See <a title="pyarmnn.INetwork.AddResizeLayer" href="#pyarmnn.INetwork.AddResizeLayer"><code>INetwork.AddResizeLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_TargetWidth</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Target width value. Default: 0.</dd>
<dt><strong><code>m_TargetHeight</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Target height value. Default: 0.</dd>
<dt><strong><code>m_Method</code></strong> :&ensp;<code>int</code></dt>
<dd>The Interpolation method to use (ResizeMethod_Bilinear, ResizeMethod_NearestNeighbor).
Default: ResizeMethod_NearestNeighbor.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ResizeDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Resize layer. See `INetwork.AddResizeLayer()`.

    Contains:
        m_TargetWidth (int): Underlying C++ data type is `uint32_t`. Target width value. Default: 0.
        m_TargetHeight (int): Underlying C++ data type is `uint32_t`. Target height value. Default: 0.
        m_Method (int): The Interpolation method to use (ResizeMethod_Bilinear, ResizeMethod_NearestNeighbor).
                        Default: ResizeMethod_NearestNeighbor.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.ResizeDescriptor_swiginit(self, _pyarmnn.new_ResizeDescriptor())
    m_TargetWidth = property(_pyarmnn.ResizeDescriptor_m_TargetWidth_get, _pyarmnn.ResizeDescriptor_m_TargetWidth_set)
    m_TargetHeight = property(_pyarmnn.ResizeDescriptor_m_TargetHeight_get, _pyarmnn.ResizeDescriptor_m_TargetHeight_set)
    m_Method = property(_pyarmnn.ResizeDescriptor_m_Method_get, _pyarmnn.ResizeDescriptor_m_Method_set)
    m_DataLayout = property(_pyarmnn.ResizeDescriptor_m_DataLayout_get, _pyarmnn.ResizeDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_ResizeDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.ResizeDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ResizeDescriptor.m_Method"><code class="name">var <span class="ident">m_Method</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ResizeDescriptor.m_TargetHeight"><code class="name">var <span class="ident">m_TargetHeight</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ResizeDescriptor.m_TargetWidth"><code class="name">var <span class="ident">m_TargetWidth</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.ResizeDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SoftmaxDescriptor"><code class="flex name class">
<span>class <span class="ident">SoftmaxDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Softmax layer. See <a title="pyarmnn.INetwork.AddSoftmaxLayer" href="#pyarmnn.INetwork.AddSoftmaxLayer"><code>INetwork.AddSoftmaxLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Beta</code></strong> :&ensp;<code>float</code></dt>
<dd>Exponentiation value.</dd>
<dt><strong><code>m_Axis</code></strong> :&ensp;<code>int</code></dt>
<dd>Scalar, defaulted to the last index (-1), specifying the dimension the activation will be performed on.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SoftmaxDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Softmax layer. See `INetwork.AddSoftmaxLayer()`.

    Contains:
        m_Beta (float): Exponentiation value.
        m_Axis (int): Scalar, defaulted to the last index (-1), specifying the dimension the activation will be performed on.

    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.SoftmaxDescriptor_swiginit(self, _pyarmnn.new_SoftmaxDescriptor())
    m_Beta = property(_pyarmnn.SoftmaxDescriptor_m_Beta_get, _pyarmnn.SoftmaxDescriptor_m_Beta_set)
    m_Axis = property(_pyarmnn.SoftmaxDescriptor_m_Axis_get, _pyarmnn.SoftmaxDescriptor_m_Axis_set)
    __swig_destroy__ = _pyarmnn.delete_SoftmaxDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SoftmaxDescriptor.m_Axis"><code class="name">var <span class="ident">m_Axis</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.SoftmaxDescriptor.m_Beta"><code class="name">var <span class="ident">m_Beta</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.SoftmaxDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor"><code class="flex name class">
<span>class <span class="ident">SpaceToBatchNdDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Space To Batch N-dimensions layer. See <a title="pyarmnn.INetwork.AddSpaceToBatchNdLayer" href="#pyarmnn.INetwork.AddSpaceToBatchNdLayer"><code>INetwork.AddSpaceToBatchNdLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_BlockShape</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>Underlying C++ data type is std::vector<unsigned int>. Block shape values. Default: [1, 1].</dd>
<dt><strong><code>m_Crops</code></strong> :&ensp;<code>list</code> of <code>tuple</code></dt>
<dd>Specifies the padding values for the input dimension:
[heightPad - (top, bottom) widthPad - (left, right)].
Default: [(0, 0), (0, 0)].</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SpaceToBatchNdDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Space To Batch N-dimensions layer. See `INetwork.AddSpaceToBatchNdLayer()`.

    Contains:
        m_BlockShape (list of int): Underlying C++ data type is std::vector&lt;unsigned int&gt;. Block shape values. Default: [1, 1].
        m_Crops (list of tuple): Specifies the padding values for the input dimension:
                                 [heightPad - (top, bottom) widthPad - (left, right)].
                                 Default: [(0, 0), (0, 0)].
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.

    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.SpaceToBatchNdDescriptor_swiginit(self, _pyarmnn.new_SpaceToBatchNdDescriptor(*args))
    m_BlockShape = property(_pyarmnn.SpaceToBatchNdDescriptor_m_BlockShape_get, _pyarmnn.SpaceToBatchNdDescriptor_m_BlockShape_set)
    m_PadList = property(_pyarmnn.SpaceToBatchNdDescriptor_m_PadList_get, _pyarmnn.SpaceToBatchNdDescriptor_m_PadList_set)
    m_DataLayout = property(_pyarmnn.SpaceToBatchNdDescriptor_m_DataLayout_get, _pyarmnn.SpaceToBatchNdDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_SpaceToBatchNdDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.m_BlockShape"><code class="name">var <span class="ident">m_BlockShape</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.m_PadList"><code class="name">var <span class="ident">m_PadList</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.SpaceToBatchNdDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SpaceToDepthDescriptor"><code class="flex name class">
<span>class <span class="ident">SpaceToDepthDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the SpaceToDepth layer. See <a title="pyarmnn.INetwork.AddSpaceToDepthLayer" href="#pyarmnn.INetwork.AddSpaceToDepthLayer"><code>INetwork.AddSpaceToDepthLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_BlockSize</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ type is <code>unsigned int</code>.
Scalar specifying the input block size. It must be &gt;= 1. Default: 1.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NHWC.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SpaceToDepthDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the SpaceToDepth layer. See `INetwork.AddSpaceToDepthLayer()`.

    Contains:
        m_BlockSize (int): Underlying C++ type is `unsigned int`.  Scalar specifying the input block size. It must be &gt;= 1. Default: 1.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NHWC.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.SpaceToDepthDescriptor_swiginit(self, _pyarmnn.new_SpaceToDepthDescriptor())
    m_BlockSize = property(_pyarmnn.SpaceToDepthDescriptor_m_BlockSize_get, _pyarmnn.SpaceToDepthDescriptor_m_BlockSize_set)
    m_DataLayout = property(_pyarmnn.SpaceToDepthDescriptor_m_DataLayout_get, _pyarmnn.SpaceToDepthDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_SpaceToDepthDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SpaceToDepthDescriptor.m_BlockSize"><code class="name">var <span class="ident">m_BlockSize</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.SpaceToDepthDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.SpaceToDepthDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.SplitterDescriptor"><code class="flex name class">
<span>class <span class="ident">SplitterDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for a Splitter layer. See <a title="pyarmnn.INetwork.AddSplitterLayer" href="#pyarmnn.INetwork.AddSplitterLayer"><code>INetwork.AddSplitterLayer()</code></a>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>numViews</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of views, the value
must be equal to the number of outputs of a layer.</dd>
<dt><strong><code>numDimensions</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of dimensions. Default value is 4.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SplitterDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for a Splitter layer. See `INetwork.AddSplitterLayer()`.

    Args:
        numViews (int): Number of views, the value  must be equal to the number of outputs of a layer.
        numDimensions (int): Number of dimensions. Default value is 4.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.SplitterDescriptor_swiginit(self, _pyarmnn.new_SplitterDescriptor(*args))

    def GetNumViews(self):
        r&#34;&#34;&#34;

        Get the number of views.
        Returns:
            int: number of views.

        &#34;&#34;&#34;
        return _pyarmnn.SplitterDescriptor_GetNumViews(self)

    def GetNumDimensions(self):
        r&#34;&#34;&#34;

        Get the number of dimensions.

        Returns:
            int: Number of dimensions.


        &#34;&#34;&#34;
        return _pyarmnn.SplitterDescriptor_GetNumDimensions(self)

    def GetViewOrigin(self, idx):
        r&#34;&#34;&#34;

        Get the output view origin (shape) by index, the order matches the outputs.

        e.g. first view corresponds to the first output, second view to the second output, etc.
        Args:
            idx (int): Index.
        Returns:
            list: View origin (shape) as a list of ints.

        &#34;&#34;&#34;
        return _pyarmnn.SplitterDescriptor_GetViewOrigin(self, idx)

    def GetViewSizes(self, idx):
        r&#34;&#34;&#34;

        Get the view sizes by index.
        Args:
            idx (int): Index.
        Returns:
            list: Sizes for the specified index as a list of ints.

        &#34;&#34;&#34;
        return _pyarmnn.SplitterDescriptor_GetViewSizes(self, idx)

    def GetOrigins(self):
        r&#34;&#34;&#34;

        Get the view origins that describe how the splitting process is configured.

        The number of views is the number of outputs, and their order match.
        Returns:
            OriginsDescriptor: A descriptor for the origins view.

        &#34;&#34;&#34;
        return _pyarmnn.SplitterDescriptor_GetOrigins(self)

    def SetViewOriginCoord(self, view, coord, value):
        r&#34;&#34;&#34;

        Set the value of a specific origin view input coordinate.

        Contains:
            view (int): Origin view index.
            coord (int): Coordinate of the origin view to set.
            value (int): Value to set.
        Raises:
            RuntimeError: If the `view` is greater than or equal to GetNumViews().
                          If the `coord` is greater than or equal to GetNumDimensions().

        &#34;&#34;&#34;
        return _pyarmnn.SplitterDescriptor_SetViewOriginCoord(self, view, coord, value)

    def SetViewSize(self, view, coord, value):
        r&#34;&#34;&#34;

        Set the size of the views.

        Args:
            view (int): View index.
            coord (int): Coordinate of the origin view to set.
            value (int): Value to set.
        Raises:
            RuntimeError: If the `view` is greater than or equal to GetNumViews().
                          If the `coord` is greater than or equal to GetNumDimensions().

        &#34;&#34;&#34;
        return _pyarmnn.SplitterDescriptor_SetViewSize(self, view, coord, value)
    __swig_destroy__ = _pyarmnn.delete_SplitterDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.SplitterDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.SplitterDescriptor.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the number of dimensions.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Number of dimensions.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumDimensions(self):
    r&#34;&#34;&#34;

    Get the number of dimensions.

    Returns:
        int: Number of dimensions.


    &#34;&#34;&#34;
    return _pyarmnn.SplitterDescriptor_GetNumDimensions(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetNumViews"><code class="name flex">
<span>def <span class="ident">GetNumViews</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the number of views.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>number of views.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumViews(self):
    r&#34;&#34;&#34;

    Get the number of views.
    Returns:
        int: number of views.

    &#34;&#34;&#34;
    return _pyarmnn.SplitterDescriptor_GetNumViews(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetOrigins"><code class="name flex">
<span>def <span class="ident">GetOrigins</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the view origins that describe how the splitting process is configured.</p>
<p>The number of views is the number of outputs, and their order match.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>OriginsDescriptor</code></strong></dt>
<dd>A descriptor for the origins view.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetOrigins(self):
    r&#34;&#34;&#34;

    Get the view origins that describe how the splitting process is configured.

    The number of views is the number of outputs, and their order match.
    Returns:
        OriginsDescriptor: A descriptor for the origins view.

    &#34;&#34;&#34;
    return _pyarmnn.SplitterDescriptor_GetOrigins(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetViewOrigin"><code class="name flex">
<span>def <span class="ident">GetViewOrigin</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the output view origin (shape) by index, the order matches the outputs.</p>
<p>e.g. first view corresponds to the first output, second view to the second output, etc.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>View origin (shape) as a list of ints.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetViewOrigin(self, idx):
    r&#34;&#34;&#34;

    Get the output view origin (shape) by index, the order matches the outputs.

    e.g. first view corresponds to the first output, second view to the second output, etc.
    Args:
        idx (int): Index.
    Returns:
        list: View origin (shape) as a list of ints.

    &#34;&#34;&#34;
    return _pyarmnn.SplitterDescriptor_GetViewOrigin(self, idx)</code></pre>
</details>
</dd>
<dt id="pyarmnn.SplitterDescriptor.GetViewSizes"><code class="name flex">
<span>def <span class="ident">GetViewSizes</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the view sizes by index.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>list</code></strong></dt>
<dd>Sizes for the specified index as a list of ints.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetViewSizes(self, idx):
    r&#34;&#34;&#34;

    Get the view sizes by index.
    Args:
        idx (int): Index.
    Returns:
        list: Sizes for the specified index as a list of ints.

    &#34;&#34;&#34;
    return _pyarmnn.SplitterDescriptor_GetViewSizes(self, idx)</code></pre>
</details>
</dd>
<dt id="pyarmnn.SplitterDescriptor.SetViewOriginCoord"><code class="name flex">
<span>def <span class="ident">SetViewOriginCoord</span></span>(<span>self, view, coord, value)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the value of a specific origin view input coordinate.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>view</code></strong> :&ensp;<code>int</code></dt>
<dd>Origin view index.</dd>
<dt><strong><code>coord</code></strong> :&ensp;<code>int</code></dt>
<dd>Coordinate of the origin view to set.</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code></dt>
<dd>Value to set.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If the <code>view</code> is greater than or equal to GetNumViews().
If the <code>coord</code> is greater than or equal to GetNumDimensions().</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetViewOriginCoord(self, view, coord, value):
    r&#34;&#34;&#34;

    Set the value of a specific origin view input coordinate.

    Contains:
        view (int): Origin view index.
        coord (int): Coordinate of the origin view to set.
        value (int): Value to set.
    Raises:
        RuntimeError: If the `view` is greater than or equal to GetNumViews().
                      If the `coord` is greater than or equal to GetNumDimensions().

    &#34;&#34;&#34;
    return _pyarmnn.SplitterDescriptor_SetViewOriginCoord(self, view, coord, value)</code></pre>
</details>
</dd>
<dt id="pyarmnn.SplitterDescriptor.SetViewSize"><code class="name flex">
<span>def <span class="ident">SetViewSize</span></span>(<span>self, view, coord, value)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the size of the views.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>view</code></strong> :&ensp;<code>int</code></dt>
<dd>View index.</dd>
<dt><strong><code>coord</code></strong> :&ensp;<code>int</code></dt>
<dd>Coordinate of the origin view to set.</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>int</code></dt>
<dd>Value to set.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>RuntimeError</code></strong></dt>
<dd>If the <code>view</code> is greater than or equal to GetNumViews().
If the <code>coord</code> is greater than or equal to GetNumDimensions().</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetViewSize(self, view, coord, value):
    r&#34;&#34;&#34;

    Set the size of the views.

    Args:
        view (int): View index.
        coord (int): Coordinate of the origin view to set.
        value (int): Value to set.
    Raises:
        RuntimeError: If the `view` is greater than or equal to GetNumViews().
                      If the `coord` is greater than or equal to GetNumDimensions().

    &#34;&#34;&#34;
    return _pyarmnn.SplitterDescriptor_SetViewSize(self, view, coord, value)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.StackDescriptor"><code class="flex name class">
<span>class <span class="ident">StackDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the Stack layer. See <a title="pyarmnn.INetwork.AddStackLayer" href="#pyarmnn.INetwork.AddStackLayer"><code>INetwork.AddStackLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Axis</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ type is <code>unsigned int</code>. 0-based axis along which to stack the input tensors. Default: 0.</dd>
<dt><strong><code>m_NumInputs</code></strong> :&ensp;<code>int</code></dt>
<dd>Required shape of all input tensors. Default: 0.</dd>
<dt><strong><code>m_InputShape</code></strong> :&ensp;<a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape"><code>TensorShape</code></a></dt>
<dd>Required shape of all input tensors.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StackDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the Stack layer. See `INetwork.AddStackLayer()`.

    Contains:
        m_Axis (int): Underlying C++ type is `unsigned int`. 0-based axis along which to stack the input tensors. Default: 0.
        m_NumInputs (int): Required shape of all input tensors. Default: 0.
        m_InputShape (TensorShape): Required shape of all input tensors.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.StackDescriptor_swiginit(self, _pyarmnn.new_StackDescriptor(*args))
    m_Axis = property(_pyarmnn.StackDescriptor_m_Axis_get, _pyarmnn.StackDescriptor_m_Axis_set)
    m_NumInputs = property(_pyarmnn.StackDescriptor_m_NumInputs_get, _pyarmnn.StackDescriptor_m_NumInputs_set)
    m_InputShape = property(_pyarmnn.StackDescriptor_m_InputShape_get, _pyarmnn.StackDescriptor_m_InputShape_set)
    __swig_destroy__ = _pyarmnn.delete_StackDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.StackDescriptor.m_Axis"><code class="name">var <span class="ident">m_Axis</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StackDescriptor.m_InputShape"><code class="name">var <span class="ident">m_InputShape</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StackDescriptor.m_NumInputs"><code class="name">var <span class="ident">m_NumInputs</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StackDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor"><code class="flex name class">
<span>class <span class="ident">StridedSliceDescriptor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the StridedSlice layer. See <a title="pyarmnn.INetwork.AddStridedSliceLayer" href="#pyarmnn.INetwork.AddStridedSliceLayer"><code>INetwork.AddStridedSliceLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_Begin</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>Underlying C++ data type is <code>std::vector&lt;int&gt;</code>. Begin values for the input that will be sliced.</dd>
<dt><strong><code>m_End</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>Underlying C++ data type is <code>std::vector&lt;int&gt;</code>. End values for the input that will be sliced.</dd>
<dt><strong><code>m_Stride</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>Underlying C++ data type is <code>std::vector&lt;int&gt;</code>. Stride values for the input that will be sliced.</dd>
<dt><strong><code>m_BeginMask</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>int32_t</code>. Begin mask value. If set, then the begin is disregarded and
the fullest range is used for the dimension. Default: 0.</dd>
<dt><strong><code>m_EndMask</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>int32_t</code>. End mask value. If set, then the end is disregarded and
the fullest range is used for the dimension.Default: 0.</dd>
<dt><strong><code>m_ShrinkAxisMask</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>int32_t</code>. Shrink axis mask value. If set, the nth specification shrinks the dimensionality by 1. Default: 0.</dd>
<dt><strong><code>m_EllipsisMask</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>int32_t</code>. Ellipsis mask value. Default: 0.</dd>
<dt><strong><code>m_NewAxisMask</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>int32_t</code>. New axis mask value. If set, the begin, end and stride is disregarded and
a new 1 dimension is inserted to this location of the output tensor. Default: 0.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StridedSliceDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the StridedSlice layer. See `INetwork.AddStridedSliceLayer()`.

    Contains:
        m_Begin (list of int): Underlying C++ data type is `std::vector&lt;int&gt;`. Begin values for the input that will be sliced.

        m_End (list of int): Underlying C++ data type is `std::vector&lt;int&gt;`. End values for the input that will be sliced.

        m_Stride (list of int): Underlying C++ data type is `std::vector&lt;int&gt;`. Stride values for the input that will be sliced.

        m_BeginMask (int): Underlying C++ data type is `int32_t`. Begin mask value. If set, then the begin is disregarded and
                               the fullest range is used for the dimension. Default: 0.

        m_EndMask (int): Underlying C++ data type is `int32_t`. End mask value. If set, then the end is disregarded and
                             the fullest range is used for the dimension.Default: 0.

        m_ShrinkAxisMask (int): Underlying C++ data type is `int32_t`. Shrink axis mask value. If set, the nth specification shrinks the dimensionality by 1. Default: 0.

        m_EllipsisMask (int): Underlying C++ data type is `int32_t`. Ellipsis mask value. Default: 0.

        m_NewAxisMask (int): Underlying C++ data type is `int32_t`. New axis mask value. If set, the begin, end and stride is disregarded and
                                  a new 1 dimension is inserted to this location of the output tensor. Default: 0.

        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.StridedSliceDescriptor_swiginit(self, _pyarmnn.new_StridedSliceDescriptor(*args))

    def GetStartForAxis(self, inputShape, axis):
        return _pyarmnn.StridedSliceDescriptor_GetStartForAxis(self, inputShape, axis)

    def GetStopForAxis(self, inputShape, axis, startForAxis):
        return _pyarmnn.StridedSliceDescriptor_GetStopForAxis(self, inputShape, axis, startForAxis)
    m_Begin = property(_pyarmnn.StridedSliceDescriptor_m_Begin_get, _pyarmnn.StridedSliceDescriptor_m_Begin_set)
    m_End = property(_pyarmnn.StridedSliceDescriptor_m_End_get, _pyarmnn.StridedSliceDescriptor_m_End_set)
    m_Stride = property(_pyarmnn.StridedSliceDescriptor_m_Stride_get, _pyarmnn.StridedSliceDescriptor_m_Stride_set)
    m_BeginMask = property(_pyarmnn.StridedSliceDescriptor_m_BeginMask_get, _pyarmnn.StridedSliceDescriptor_m_BeginMask_set)
    m_EndMask = property(_pyarmnn.StridedSliceDescriptor_m_EndMask_get, _pyarmnn.StridedSliceDescriptor_m_EndMask_set)
    m_ShrinkAxisMask = property(_pyarmnn.StridedSliceDescriptor_m_ShrinkAxisMask_get, _pyarmnn.StridedSliceDescriptor_m_ShrinkAxisMask_set)
    m_EllipsisMask = property(_pyarmnn.StridedSliceDescriptor_m_EllipsisMask_get, _pyarmnn.StridedSliceDescriptor_m_EllipsisMask_set)
    m_NewAxisMask = property(_pyarmnn.StridedSliceDescriptor_m_NewAxisMask_get, _pyarmnn.StridedSliceDescriptor_m_NewAxisMask_set)
    m_DataLayout = property(_pyarmnn.StridedSliceDescriptor_m_DataLayout_get, _pyarmnn.StridedSliceDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_StridedSliceDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.StridedSliceDescriptor.m_Begin"><code class="name">var <span class="ident">m_Begin</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_BeginMask"><code class="name">var <span class="ident">m_BeginMask</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_EllipsisMask"><code class="name">var <span class="ident">m_EllipsisMask</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_End"><code class="name">var <span class="ident">m_End</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_EndMask"><code class="name">var <span class="ident">m_EndMask</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_NewAxisMask"><code class="name">var <span class="ident">m_NewAxisMask</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_ShrinkAxisMask"><code class="name">var <span class="ident">m_ShrinkAxisMask</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.m_Stride"><code class="name">var <span class="ident">m_Stride</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.StridedSliceDescriptor.GetStartForAxis"><code class="name flex">
<span>def <span class="ident">GetStartForAxis</span></span>(<span>self, inputShape, axis)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetStartForAxis(self, inputShape, axis):
    return _pyarmnn.StridedSliceDescriptor_GetStartForAxis(self, inputShape, axis)</code></pre>
</details>
</dd>
<dt id="pyarmnn.StridedSliceDescriptor.GetStopForAxis"><code class="name flex">
<span>def <span class="ident">GetStopForAxis</span></span>(<span>self, inputShape, axis, startForAxis)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetStopForAxis(self, inputShape, axis, startForAxis):
    return _pyarmnn.StridedSliceDescriptor_GetStopForAxis(self, inputShape, axis, startForAxis)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.Tensor"><code class="flex name class">
<span>class <span class="ident">Tensor</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>pyArmnn Tensor object</p>
<p>This class overrides the swig generated Tensor class. The aim of
this is to create an easy to use public api for the Tensor object.</p>
<p>Memory is allocated and managed by this class, avoiding the need to manage
a separate memory area for the tensor compared to the swig generated api.</p>
<p>Create Tensor object.</p>
<p>Supported tensor data types:
DataType_QuantisedAsymm8,
DataType_QuantisedSymm16,
DataType_Signed32,
DataType_Float32,
DataType_Float16</p>
<h2 id="examples">Examples</h2>
<p>Create an empty tensor</p>
<pre><code>&gt;&gt;&gt; import pyarmnn as ann
&gt;&gt;&gt; ann.Tensor()
</code></pre>
<p>Create tensor given tensor information</p>
<pre><code>&gt;&gt;&gt; ann.Tensor(ann.TensorInfo(...))
</code></pre>
<p>Create tensor from another tensor i.e. copy a tensor</p>
<pre><code>&gt;&gt;&gt; ann.Tensor(ann.Tensor())
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt>tensor(Tensor, optional): Create Tensor from a Tensor i.e. copy.</dt>
<dt><strong><code>tensor_info</code></strong> :&ensp;<a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo"><code>TensorInfo</code></a>, optional</dt>
<dd>Tensor information.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><strong><code>TypeError</code></strong></dt>
<dd>unsupported input data type.</dd>
<dt><strong><code>ValueError</code></strong></dt>
<dd>appropriate constructor could not be found with provided arguments.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Tensor(annTensor):
    &#34;&#34;&#34;pyArmnn Tensor object

    This class overrides the swig generated Tensor class. The aim of
    this is to create an easy to use public api for the Tensor object.

    Memory is allocated and managed by this class, avoiding the need to manage
    a separate memory area for the tensor compared to the swig generated api.

    &#34;&#34;&#34;

    def __init__(self, *args):
        &#34;&#34;&#34; Create Tensor object.

        Supported tensor data types:
            DataType_QuantisedAsymm8,
            DataType_QuantisedSymm16,
            DataType_Signed32,
            DataType_Float32,
            DataType_Float16

        Examples:
            Create an empty tensor
            &gt;&gt;&gt; import pyarmnn as ann
            &gt;&gt;&gt; ann.Tensor()

            Create tensor given tensor information
            &gt;&gt;&gt; ann.Tensor(ann.TensorInfo(...))

            Create tensor from another tensor i.e. copy a tensor
            &gt;&gt;&gt; ann.Tensor(ann.Tensor())

        Args:
            tensor(Tensor, optional): Create Tensor from a Tensor i.e. copy.
            tensor_info (TensorInfo, optional): Tensor information.

        Raises:
            TypeError: unsupported input data type.
            ValueError: appropriate constructor could not be found with provided arguments.

        &#34;&#34;&#34;
        self.__memory_area = None

        # TensorInfo as first argument, we need to create memory area manually
        if len(args) &gt; 0 and isinstance(args[0], TensorInfo):
            self.__create_memory_area(args[0].GetDataType(), args[0].GetNumElements())
            super().__init__(args[0], self.__memory_area.data)

        # copy constructor - reference to memory area is passed from copied tensor
        # and armnn&#39;s copy constructor is called
        elif len(args) &gt; 0 and isinstance(args[0], Tensor):
            self.__memory_area = args[0].get_memory_area()
            super().__init__(args[0])

        # empty constructor
        elif len(args) == 0:
            super().__init__()

        else:
            raise ValueError(&#39;Incorrect number of arguments or type of arguments provided to create Tensor.&#39;)

    def __copy__(self) -&gt; &#39;Tensor&#39;:
        &#34;&#34;&#34; Make copy of a tensor.

        Make tensor copyable using the python copy operation.

        Note:
            The tensor memory area is NOT copied. Instead, the new tensor maintains a
            reference to the same memory area as the old tensor.

        Example:
            Copy empty tensor
            &gt;&gt;&gt; from copy import copy
            &gt;&gt;&gt; import pyarmnn as ann
            &gt;&gt;&gt; tensor = ann.Tensor()
            &gt;&gt;&gt; copied_tensor = copy(tensor)

        Returns:
            Tensor: a copy of the tensor object provided.

        &#34;&#34;&#34;
        return Tensor(self)

    def __create_memory_area(self, data_type: int, num_elements: int):
        &#34;&#34;&#34; Create the memory area used by the tensor to output its results.

        Args:
            data_type (int): The type of data that will be stored in the memory area.
                             See DataType_*.
            num_elements (int): Determines the size of the memory area that will be created.

        &#34;&#34;&#34;
        np_data_type_mapping = {DataType_QuantisedAsymm8: np.uint8,
                                DataType_Float32: np.float32,
                                DataType_QuantisedSymm16: np.int16,
                                DataType_Signed32: np.int32,
                                DataType_Float16: np.float16}

        if data_type not in np_data_type_mapping:
            raise ValueError(&#34;The data type provided for this Tensor is not supported.&#34;)

        self.__memory_area = np.empty(shape=(num_elements,), dtype=np_data_type_mapping[data_type])

    def get_memory_area(self) -&gt; np.ndarray:
        &#34;&#34;&#34; Get values that are stored by the tensor.

        Returns:
            ndarray : Tensor data (as numpy array).

        &#34;&#34;&#34;
        return self.__memory_area</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pyarmnn._generated.pyarmnn.Tensor</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.Tensor.get_memory_area"><code class="name flex">
<span>def <span class="ident">get_memory_area</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get values that are stored by the tensor.</p>
<h2 id="returns">Returns</h2>
<p>ndarray : Tensor data (as numpy array).</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_memory_area(self) -&gt; np.ndarray:
    &#34;&#34;&#34; Get values that are stored by the tensor.

    Returns:
        ndarray : Tensor data (as numpy array).

    &#34;&#34;&#34;
    return self.__memory_area</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.TensorInfo"><code class="flex name class">
<span>class <span class="ident">TensorInfo</span></span>
<span>(</span><span>*args)</span>
</code></dt>
<dd>
<section class="desc"><p>Class for holding the tensor information of an Arm NN tensor such as quantization, datatype, shape etc.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TensorInfo(object):
    r&#34;&#34;&#34;

    Class for holding the tensor information of an Arm NN tensor such as quantization, datatype, shape etc.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, *args):
        _pyarmnn.TensorInfo_swiginit(self, _pyarmnn.new_TensorInfo(*args))

    def GetShape(self):
        r&#34;&#34;&#34;

        Get the tensor shape.

        Return:
            TensorShape: Current shape of the tensor.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_GetShape(self)

    def SetShape(self, newShape):
        r&#34;&#34;&#34;

        Set the tensor shape. Must have the same number of elements as current tensor.

        Args:
            newShape (TensorShape): New tensor shape to reshape to.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_SetShape(self, newShape)

    def GetNumDimensions(self):
        r&#34;&#34;&#34;

        Returns the number of dimensions in this Tensor.

        Returns:
            int: The number of dimensions in this Tensor.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_GetNumDimensions(self)

    def GetNumElements(self):
        r&#34;&#34;&#34;

        Returns the total number of elements for this Tensor.

        Returns:
            int: The total number of elements for this Tensor.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_GetNumElements(self)

    def GetDataType(self):
        r&#34;&#34;&#34;

        Get the tensor datatype.

        Returns:
            DataType: Current tensor DataType.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_GetDataType(self)

    def SetDataType(self, type):
        r&#34;&#34;&#34;

        Set the tensor datatype.

        Args:
            type (DataType): DataType to set the tensor to.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_SetDataType(self, type)

    def GetQuantizationScale(self):
        r&#34;&#34;&#34;

        Get the value of the tensors quantization scale.

        Returns:
            float: Tensor quantization scale value.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_GetQuantizationScale(self)

    def GetQuantizationOffset(self):
        r&#34;&#34;&#34;

        Get the value of the tensors quantization offset.

        Returns:
            int: Tensor quantization offset value.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_GetQuantizationOffset(self)

    def SetQuantizationScale(self, scale):
        r&#34;&#34;&#34;

        Set the value of the tensors quantization scale.

        Args:
            scale (float): Scale value to set.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_SetQuantizationScale(self, scale)

    def SetQuantizationOffset(self, offset):
        r&#34;&#34;&#34;

        Set the value of the tensors quantization offset.

        Args:
            offset (int): Offset value to set.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_SetQuantizationOffset(self, offset)

    def IsQuantized(self):
        r&#34;&#34;&#34;

        Returns true if the tensor is a quantized data type.

        Returns:
            bool: True if the tensor is a quantized data type.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_IsQuantized(self)

    def IsTypeSpaceMatch(self, other):
        r&#34;&#34;&#34;

        Check that the types are the same and, if quantize, that the quantization parameters are the same.

        Returns:
            bool: True if matched, else False.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_IsTypeSpaceMatch(self, other)

    def GetNumBytes(self):
        r&#34;&#34;&#34;

        Get the number of bytes needed for this tensor.

        Returns:
            int: Number of bytes consumed by this tensor.


        &#34;&#34;&#34;
        return _pyarmnn.TensorInfo_GetNumBytes(self)

    def __str__(self):
        return _pyarmnn.TensorInfo___str__(self)
    __swig_destroy__ = _pyarmnn.delete_TensorInfo</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.TensorInfo.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.TensorInfo.GetDataType"><code class="name flex">
<span>def <span class="ident">GetDataType</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the tensor datatype.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>DataType</code></strong></dt>
<dd>Current tensor DataType.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetDataType(self):
    r&#34;&#34;&#34;

    Get the tensor datatype.

    Returns:
        DataType: Current tensor DataType.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_GetDataType(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.GetNumBytes"><code class="name flex">
<span>def <span class="ident">GetNumBytes</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the number of bytes needed for this tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Number of bytes consumed by this tensor.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumBytes(self):
    r&#34;&#34;&#34;

    Get the number of bytes needed for this tensor.

    Returns:
        int: Number of bytes consumed by this tensor.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_GetNumBytes(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the number of dimensions in this Tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>The number of dimensions in this Tensor.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumDimensions(self):
    r&#34;&#34;&#34;

    Returns the number of dimensions in this Tensor.

    Returns:
        int: The number of dimensions in this Tensor.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_GetNumDimensions(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.GetNumElements"><code class="name flex">
<span>def <span class="ident">GetNumElements</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the total number of elements for this Tensor.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>The total number of elements for this Tensor.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumElements(self):
    r&#34;&#34;&#34;

    Returns the total number of elements for this Tensor.

    Returns:
        int: The total number of elements for this Tensor.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_GetNumElements(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.GetQuantizationOffset"><code class="name flex">
<span>def <span class="ident">GetQuantizationOffset</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the value of the tensors quantization offset.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>Tensor quantization offset value.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetQuantizationOffset(self):
    r&#34;&#34;&#34;

    Get the value of the tensors quantization offset.

    Returns:
        int: Tensor quantization offset value.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_GetQuantizationOffset(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.GetQuantizationScale"><code class="name flex">
<span>def <span class="ident">GetQuantizationScale</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the value of the tensors quantization scale.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>float</code></strong></dt>
<dd>Tensor quantization scale value.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetQuantizationScale(self):
    r&#34;&#34;&#34;

    Get the value of the tensors quantization scale.

    Returns:
        float: Tensor quantization scale value.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_GetQuantizationScale(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.GetShape"><code class="name flex">
<span>def <span class="ident">GetShape</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Get the tensor shape.</p>
<h2 id="return">Return</h2>
<dl>
<dt><strong><a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape"><code>TensorShape</code></a></strong></dt>
<dd>Current shape of the tensor.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetShape(self):
    r&#34;&#34;&#34;

    Get the tensor shape.

    Return:
        TensorShape: Current shape of the tensor.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_GetShape(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.IsQuantized"><code class="name flex">
<span>def <span class="ident">IsQuantized</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns true if the tensor is a quantized data type.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>bool</code></strong></dt>
<dd>True if the tensor is a quantized data type.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def IsQuantized(self):
    r&#34;&#34;&#34;

    Returns true if the tensor is a quantized data type.

    Returns:
        bool: True if the tensor is a quantized data type.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_IsQuantized(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.IsTypeSpaceMatch"><code class="name flex">
<span>def <span class="ident">IsTypeSpaceMatch</span></span>(<span>self, other)</span>
</code></dt>
<dd>
<section class="desc"><p>Check that the types are the same and, if quantize, that the quantization parameters are the same.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>bool</code></strong></dt>
<dd>True if matched, else False.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def IsTypeSpaceMatch(self, other):
    r&#34;&#34;&#34;

    Check that the types are the same and, if quantize, that the quantization parameters are the same.

    Returns:
        bool: True if matched, else False.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_IsTypeSpaceMatch(self, other)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.SetDataType"><code class="name flex">
<span>def <span class="ident">SetDataType</span></span>(<span>self, type)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the tensor datatype.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>type</code></strong> :&ensp;<code>DataType</code></dt>
<dd>DataType to set the tensor to.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetDataType(self, type):
    r&#34;&#34;&#34;

    Set the tensor datatype.

    Args:
        type (DataType): DataType to set the tensor to.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_SetDataType(self, type)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.SetQuantizationOffset"><code class="name flex">
<span>def <span class="ident">SetQuantizationOffset</span></span>(<span>self, offset)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the value of the tensors quantization offset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>offset</code></strong> :&ensp;<code>int</code></dt>
<dd>Offset value to set.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetQuantizationOffset(self, offset):
    r&#34;&#34;&#34;

    Set the value of the tensors quantization offset.

    Args:
        offset (int): Offset value to set.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_SetQuantizationOffset(self, offset)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.SetQuantizationScale"><code class="name flex">
<span>def <span class="ident">SetQuantizationScale</span></span>(<span>self, scale)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the value of the tensors quantization scale.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>scale</code></strong> :&ensp;<code>float</code></dt>
<dd>Scale value to set.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetQuantizationScale(self, scale):
    r&#34;&#34;&#34;

    Set the value of the tensors quantization scale.

    Args:
        scale (float): Scale value to set.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_SetQuantizationScale(self, scale)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorInfo.SetShape"><code class="name flex">
<span>def <span class="ident">SetShape</span></span>(<span>self, newShape)</span>
</code></dt>
<dd>
<section class="desc"><p>Set the tensor shape. Must have the same number of elements as current tensor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>newShape</code></strong> :&ensp;<a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape"><code>TensorShape</code></a></dt>
<dd>New tensor shape to reshape to.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def SetShape(self, newShape):
    r&#34;&#34;&#34;

    Set the tensor shape. Must have the same number of elements as current tensor.

    Args:
        newShape (TensorShape): New tensor shape to reshape to.


    &#34;&#34;&#34;
    return _pyarmnn.TensorInfo_SetShape(self, newShape)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.TensorShape"><code class="flex name class">
<span>class <span class="ident">TensorShape</span></span>
<span>(</span><span>numDimensions)</span>
</code></dt>
<dd>
<section class="desc"><p>Class for holding the shape information of an Arm NN tensor.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TensorShape(object):
    r&#34;&#34;&#34;

    Class for holding the shape information of an Arm NN tensor.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self, numDimensions):
        _pyarmnn.TensorShape_swiginit(self, _pyarmnn.new_TensorShape(numDimensions))

    def GetNumDimensions(self):
        r&#34;&#34;&#34;

        Returns the number of dimensions in this TensorShape.

        Returns:
            int: The number of dimensions in this TensorShape.


        &#34;&#34;&#34;
        return _pyarmnn.TensorShape_GetNumDimensions(self)

    def GetNumElements(self):
        r&#34;&#34;&#34;

        Returns the total number of elements for a tensor with this TensorShape.

        Returns:
            int: The total number of elements for a tensor with this TensorShape.


        &#34;&#34;&#34;
        return _pyarmnn.TensorShape_GetNumElements(self)

    def __getitem__(self, i):
        return _pyarmnn.TensorShape___getitem__(self, i)

    def __setitem__(self, i, val):
        return _pyarmnn.TensorShape___setitem__(self, i, val)

    def __str__(self):
        return _pyarmnn.TensorShape___str__(self)
    __swig_destroy__ = _pyarmnn.delete_TensorShape</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.TensorShape.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pyarmnn.TensorShape.GetNumDimensions"><code class="name flex">
<span>def <span class="ident">GetNumDimensions</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the number of dimensions in this TensorShape.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>The number of dimensions in this TensorShape.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumDimensions(self):
    r&#34;&#34;&#34;

    Returns the number of dimensions in this TensorShape.

    Returns:
        int: The number of dimensions in this TensorShape.


    &#34;&#34;&#34;
    return _pyarmnn.TensorShape_GetNumDimensions(self)</code></pre>
</details>
</dd>
<dt id="pyarmnn.TensorShape.GetNumElements"><code class="name flex">
<span>def <span class="ident">GetNumElements</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the total number of elements for a tensor with this TensorShape.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>int</code></strong></dt>
<dd>The total number of elements for a tensor with this TensorShape.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def GetNumElements(self):
    r&#34;&#34;&#34;

    Returns the total number of elements for a tensor with this TensorShape.

    Returns:
        int: The total number of elements for a tensor with this TensorShape.


    &#34;&#34;&#34;
    return _pyarmnn.TensorShape_GetNumElements(self)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor"><code class="flex name class">
<span>class <span class="ident">TransposeConvolution2dDescriptor</span></span>
</code></dt>
<dd>
<section class="desc"><p>A descriptor for the TransposeConvolution2d layer. See <a title="pyarmnn.INetwork.AddTransposeConvolution2dLayer" href="#pyarmnn.INetwork.AddTransposeConvolution2dLayer"><code>INetwork.AddTransposeConvolution2dLayer()</code></a>.</p>
<h2 id="contains">Contains</h2>
<dl>
<dt><strong><code>m_PadLeft</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding left value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadRight</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding right value in the width dimension. Default: 0.</dd>
<dt><strong><code>m_PadTop</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding top value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_PadBottom</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Padding bottom value in the height dimension. Default: 0.</dd>
<dt><strong><code>m_StrideX</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the width dimension. Default: 0.</dd>
<dt><strong><code>m_StrideY</code></strong> :&ensp;<code>int</code></dt>
<dd>Underlying C++ data type is <code>uint32_t</code>. Stride value when proceeding through input for the height dimension. Default: 0.</dd>
<dt><strong><code>m_BiasEnabled</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enable/disable bias. Default: false.</dd>
<dt><strong><code>m_DataLayout</code></strong> :&ensp;<code>int</code></dt>
<dd>The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TransposeConvolution2dDescriptor(object):
    r&#34;&#34;&#34;

    A descriptor for the TransposeConvolution2d layer. See `INetwork.AddTransposeConvolution2dLayer()`.

    Contains:
        m_PadLeft (int): Underlying C++ data type is `uint32_t`. Padding left value in the width dimension. Default: 0.
        m_PadRight (int): Underlying C++ data type is `uint32_t`. Padding right value in the width dimension. Default: 0.
        m_PadTop (int): Underlying C++ data type is `uint32_t`. Padding top value in the height dimension. Default: 0.
        m_PadBottom (int): Underlying C++ data type is `uint32_t`. Padding bottom value in the height dimension. Default: 0.
        m_StrideX (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the width dimension. Default: 0.
        m_StrideY (int): Underlying C++ data type is `uint32_t`. Stride value when proceeding through input for the height dimension. Default: 0.
        m_BiasEnabled (bool): Enable/disable bias. Default: false.
        m_DataLayout (int): The data layout to be used (DataLayout_NCHW, DataLayout_NHWC). Default: DataLayout_NCHW.


    &#34;&#34;&#34;

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)
    __repr__ = _swig_repr

    def __init__(self):
        _pyarmnn.TransposeConvolution2dDescriptor_swiginit(self, _pyarmnn.new_TransposeConvolution2dDescriptor())
    m_PadLeft = property(_pyarmnn.TransposeConvolution2dDescriptor_m_PadLeft_get, _pyarmnn.TransposeConvolution2dDescriptor_m_PadLeft_set)
    m_PadRight = property(_pyarmnn.TransposeConvolution2dDescriptor_m_PadRight_get, _pyarmnn.TransposeConvolution2dDescriptor_m_PadRight_set)
    m_PadTop = property(_pyarmnn.TransposeConvolution2dDescriptor_m_PadTop_get, _pyarmnn.TransposeConvolution2dDescriptor_m_PadTop_set)
    m_PadBottom = property(_pyarmnn.TransposeConvolution2dDescriptor_m_PadBottom_get, _pyarmnn.TransposeConvolution2dDescriptor_m_PadBottom_set)
    m_StrideX = property(_pyarmnn.TransposeConvolution2dDescriptor_m_StrideX_get, _pyarmnn.TransposeConvolution2dDescriptor_m_StrideX_set)
    m_StrideY = property(_pyarmnn.TransposeConvolution2dDescriptor_m_StrideY_get, _pyarmnn.TransposeConvolution2dDescriptor_m_StrideY_set)
    m_BiasEnabled = property(_pyarmnn.TransposeConvolution2dDescriptor_m_BiasEnabled_get, _pyarmnn.TransposeConvolution2dDescriptor_m_BiasEnabled_set)
    m_DataLayout = property(_pyarmnn.TransposeConvolution2dDescriptor_m_DataLayout_get, _pyarmnn.TransposeConvolution2dDescriptor_m_DataLayout_set)
    __swig_destroy__ = _pyarmnn.delete_TransposeConvolution2dDescriptor</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_BiasEnabled"><code class="name">var <span class="ident">m_BiasEnabled</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_DataLayout"><code class="name">var <span class="ident">m_DataLayout</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadBottom"><code class="name">var <span class="ident">m_PadBottom</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadLeft"><code class="name">var <span class="ident">m_PadLeft</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadRight"><code class="name">var <span class="ident">m_PadRight</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_PadTop"><code class="name">var <span class="ident">m_PadTop</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_StrideX"><code class="name">var <span class="ident">m_StrideX</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.m_StrideY"><code class="name">var <span class="ident">m_StrideY</span></code></dt>
<dd>
<section class="desc"></section>
</dd>
<dt id="pyarmnn.TransposeConvolution2dDescriptor.thisown"><code class="name">var <span class="ident">thisown</span></code></dt>
<dd>
<section class="desc"><p>The membership flag</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc=&#34;The membership flag&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#about-pyarmnn">About PyArmNN</a></li>
<li><a href="#pyarmnn-installation">PyArmNN installation</a><ul>
<li><a href="#installing-from-wheel">Installing from wheel</a></li>
</ul>
</li>
<li><a href="#pyarmnn-api-overview">PyArmNN API overview</a><ul>
<li><a href="#getting-started">Getting started</a></li>
<li><a href="#running-examples">Running examples</a></li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pyarmnn.CreateDescriptorForConcatenation" href="#pyarmnn.CreateDescriptorForConcatenation">CreateDescriptorForConcatenation</a></code></li>
<li><code><a title="pyarmnn.GetMajorVersion" href="#pyarmnn.GetMajorVersion">GetMajorVersion</a></code></li>
<li><code><a title="pyarmnn.GetMinorVersion" href="#pyarmnn.GetMinorVersion">GetMinorVersion</a></code></li>
<li><code><a title="pyarmnn.GetVersion" href="#pyarmnn.GetVersion">GetVersion</a></code></li>
<li><code><a title="pyarmnn.Optimize" href="#pyarmnn.Optimize">Optimize</a></code></li>
<li><code><a title="pyarmnn.dequantize" href="#pyarmnn.dequantize">dequantize</a></code></li>
<li><code><a title="pyarmnn.get_profiling_data" href="#pyarmnn.get_profiling_data">get_profiling_data</a></code></li>
<li><code><a title="pyarmnn.make_input_tensors" href="#pyarmnn.make_input_tensors">make_input_tensors</a></code></li>
<li><code><a title="pyarmnn.make_output_tensors" href="#pyarmnn.make_output_tensors">make_output_tensors</a></code></li>
<li><code><a title="pyarmnn.quantize" href="#pyarmnn.quantize">quantize</a></code></li>
<li><code><a title="pyarmnn.workload_tensors_to_ndarray" href="#pyarmnn.workload_tensors_to_ndarray">workload_tensors_to_ndarray</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pyarmnn.ActivationDescriptor" href="#pyarmnn.ActivationDescriptor">ActivationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ActivationDescriptor.m_A" href="#pyarmnn.ActivationDescriptor.m_A">m_A</a></code></li>
<li><code><a title="pyarmnn.ActivationDescriptor.m_B" href="#pyarmnn.ActivationDescriptor.m_B">m_B</a></code></li>
<li><code><a title="pyarmnn.ActivationDescriptor.m_Function" href="#pyarmnn.ActivationDescriptor.m_Function">m_Function</a></code></li>
<li><code><a title="pyarmnn.ActivationDescriptor.thisown" href="#pyarmnn.ActivationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.BackendId" href="#pyarmnn.BackendId">BackendId</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.BackendId.Get" href="#pyarmnn.BackendId.Get">Get</a></code></li>
<li><code><a title="pyarmnn.BackendId.IsCpuRef" href="#pyarmnn.BackendId.IsCpuRef">IsCpuRef</a></code></li>
<li><code><a title="pyarmnn.BackendId.thisown" href="#pyarmnn.BackendId.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.BatchNormalizationDescriptor" href="#pyarmnn.BatchNormalizationDescriptor">BatchNormalizationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.BatchNormalizationDescriptor.m_DataLayout" href="#pyarmnn.BatchNormalizationDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.BatchNormalizationDescriptor.m_Eps" href="#pyarmnn.BatchNormalizationDescriptor.m_Eps">m_Eps</a></code></li>
<li><code><a title="pyarmnn.BatchNormalizationDescriptor.thisown" href="#pyarmnn.BatchNormalizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.BatchToSpaceNdDescriptor" href="#pyarmnn.BatchToSpaceNdDescriptor">BatchToSpaceNdDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.m_BlockShape" href="#pyarmnn.BatchToSpaceNdDescriptor.m_BlockShape">m_BlockShape</a></code></li>
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.m_Crops" href="#pyarmnn.BatchToSpaceNdDescriptor.m_Crops">m_Crops</a></code></li>
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.m_DataLayout" href="#pyarmnn.BatchToSpaceNdDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.BatchToSpaceNdDescriptor.thisown" href="#pyarmnn.BatchToSpaceNdDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ConcatDescriptor" href="#pyarmnn.ConcatDescriptor">ConcatDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.ConcatDescriptor.GetConcatAxis" href="#pyarmnn.ConcatDescriptor.GetConcatAxis">GetConcatAxis</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.GetNumDimensions" href="#pyarmnn.ConcatDescriptor.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.GetNumViews" href="#pyarmnn.ConcatDescriptor.GetNumViews">GetNumViews</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.GetViewOrigin" href="#pyarmnn.ConcatDescriptor.GetViewOrigin">GetViewOrigin</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.SetConcatAxis" href="#pyarmnn.ConcatDescriptor.SetConcatAxis">SetConcatAxis</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.SetViewOriginCoord" href="#pyarmnn.ConcatDescriptor.SetViewOriginCoord">SetViewOriginCoord</a></code></li>
<li><code><a title="pyarmnn.ConcatDescriptor.thisown" href="#pyarmnn.ConcatDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ConstTensor" href="#pyarmnn.ConstTensor">ConstTensor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ConstTensor.get_memory_area" href="#pyarmnn.ConstTensor.get_memory_area">get_memory_area</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.Convolution2dDescriptor" href="#pyarmnn.Convolution2dDescriptor">Convolution2dDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_BiasEnabled" href="#pyarmnn.Convolution2dDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_DataLayout" href="#pyarmnn.Convolution2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_DilationX" href="#pyarmnn.Convolution2dDescriptor.m_DilationX">m_DilationX</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_DilationY" href="#pyarmnn.Convolution2dDescriptor.m_DilationY">m_DilationY</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadBottom" href="#pyarmnn.Convolution2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadLeft" href="#pyarmnn.Convolution2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadRight" href="#pyarmnn.Convolution2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_PadTop" href="#pyarmnn.Convolution2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_StrideX" href="#pyarmnn.Convolution2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.m_StrideY" href="#pyarmnn.Convolution2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.Convolution2dDescriptor.thisown" href="#pyarmnn.Convolution2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.CreationOptions" href="#pyarmnn.CreationOptions">CreationOptions</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.CreationOptions.m_DynamicBackendsPath" href="#pyarmnn.CreationOptions.m_DynamicBackendsPath">m_DynamicBackendsPath</a></code></li>
<li><code><a title="pyarmnn.CreationOptions.m_EnableGpuProfiling" href="#pyarmnn.CreationOptions.m_EnableGpuProfiling">m_EnableGpuProfiling</a></code></li>
<li><code><a title="pyarmnn.CreationOptions.m_GpuAccTunedParameters" href="#pyarmnn.CreationOptions.m_GpuAccTunedParameters">m_GpuAccTunedParameters</a></code></li>
<li><code><a title="pyarmnn.CreationOptions.thisown" href="#pyarmnn.CreationOptions.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor" href="#pyarmnn.DepthwiseConvolution2dDescriptor">DepthwiseConvolution2dDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_BiasEnabled" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_DataLayout" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationX" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationX">m_DilationX</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationY" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_DilationY">m_DilationY</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadBottom" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadLeft" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadRight" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_PadTop" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideX" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideY" href="#pyarmnn.DepthwiseConvolution2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.DepthwiseConvolution2dDescriptor.thisown" href="#pyarmnn.DepthwiseConvolution2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.DetectionPostProcessDescriptor" href="#pyarmnn.DetectionPostProcessDescriptor">DetectionPostProcessDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_DetectionsPerClass" href="#pyarmnn.DetectionPostProcessDescriptor.m_DetectionsPerClass">m_DetectionsPerClass</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_MaxClassesPerDetection" href="#pyarmnn.DetectionPostProcessDescriptor.m_MaxClassesPerDetection">m_MaxClassesPerDetection</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_MaxDetections" href="#pyarmnn.DetectionPostProcessDescriptor.m_MaxDetections">m_MaxDetections</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_NmsIouThreshold" href="#pyarmnn.DetectionPostProcessDescriptor.m_NmsIouThreshold">m_NmsIouThreshold</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_NmsScoreThreshold" href="#pyarmnn.DetectionPostProcessDescriptor.m_NmsScoreThreshold">m_NmsScoreThreshold</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_NumClasses" href="#pyarmnn.DetectionPostProcessDescriptor.m_NumClasses">m_NumClasses</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleH" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleH">m_ScaleH</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleW" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleW">m_ScaleW</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleX" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleX">m_ScaleX</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_ScaleY" href="#pyarmnn.DetectionPostProcessDescriptor.m_ScaleY">m_ScaleY</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.m_UseRegularNms" href="#pyarmnn.DetectionPostProcessDescriptor.m_UseRegularNms">m_UseRegularNms</a></code></li>
<li><code><a title="pyarmnn.DetectionPostProcessDescriptor.thisown" href="#pyarmnn.DetectionPostProcessDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.FakeQuantizationDescriptor" href="#pyarmnn.FakeQuantizationDescriptor">FakeQuantizationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.FakeQuantizationDescriptor.m_Max" href="#pyarmnn.FakeQuantizationDescriptor.m_Max">m_Max</a></code></li>
<li><code><a title="pyarmnn.FakeQuantizationDescriptor.m_Min" href="#pyarmnn.FakeQuantizationDescriptor.m_Min">m_Min</a></code></li>
<li><code><a title="pyarmnn.FakeQuantizationDescriptor.thisown" href="#pyarmnn.FakeQuantizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.FullyConnectedDescriptor" href="#pyarmnn.FullyConnectedDescriptor">FullyConnectedDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.FullyConnectedDescriptor.m_BiasEnabled" href="#pyarmnn.FullyConnectedDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.FullyConnectedDescriptor.m_TransposeWeightMatrix" href="#pyarmnn.FullyConnectedDescriptor.m_TransposeWeightMatrix">m_TransposeWeightMatrix</a></code></li>
<li><code><a title="pyarmnn.FullyConnectedDescriptor.thisown" href="#pyarmnn.FullyConnectedDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ICaffeParser" href="#pyarmnn.ICaffeParser">ICaffeParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ICaffeParser.CreateNetworkFromBinaryFile" href="#pyarmnn.ICaffeParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.ICaffeParser.GetNetworkInputBindingInfo" href="#pyarmnn.ICaffeParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ICaffeParser.GetNetworkOutputBindingInfo" href="#pyarmnn.ICaffeParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ICaffeParser.thisown" href="#pyarmnn.ICaffeParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IConnectableLayer" href="#pyarmnn.IConnectableLayer">IConnectableLayer</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.IConnectableLayer.GetGuid" href="#pyarmnn.IConnectableLayer.GetGuid">GetGuid</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetInputSlot" href="#pyarmnn.IConnectableLayer.GetInputSlot">GetInputSlot</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetName" href="#pyarmnn.IConnectableLayer.GetName">GetName</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetNumInputSlots" href="#pyarmnn.IConnectableLayer.GetNumInputSlots">GetNumInputSlots</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetNumOutputSlots" href="#pyarmnn.IConnectableLayer.GetNumOutputSlots">GetNumOutputSlots</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.GetOutputSlot" href="#pyarmnn.IConnectableLayer.GetOutputSlot">GetOutputSlot</a></code></li>
<li><code><a title="pyarmnn.IConnectableLayer.thisown" href="#pyarmnn.IConnectableLayer.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IDeviceSpec" href="#pyarmnn.IDeviceSpec">IDeviceSpec</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IDeviceSpec.GetSupportedBackends" href="#pyarmnn.IDeviceSpec.GetSupportedBackends">GetSupportedBackends</a></code></li>
<li><code><a title="pyarmnn.IDeviceSpec.thisown" href="#pyarmnn.IDeviceSpec.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IInputSlot" href="#pyarmnn.IInputSlot">IInputSlot</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IInputSlot.GetConnection" href="#pyarmnn.IInputSlot.GetConnection">GetConnection</a></code></li>
<li><code><a title="pyarmnn.IInputSlot.thisown" href="#pyarmnn.IInputSlot.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.INetwork" href="#pyarmnn.INetwork">INetwork</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.INetwork.AddActivationLayer" href="#pyarmnn.INetwork.AddActivationLayer">AddActivationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddAdditionLayer" href="#pyarmnn.INetwork.AddAdditionLayer">AddAdditionLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddBatchNormalizationLayer" href="#pyarmnn.INetwork.AddBatchNormalizationLayer">AddBatchNormalizationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddBatchToSpaceNdLayer" href="#pyarmnn.INetwork.AddBatchToSpaceNdLayer">AddBatchToSpaceNdLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddConcatLayer" href="#pyarmnn.INetwork.AddConcatLayer">AddConcatLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddConstantLayer" href="#pyarmnn.INetwork.AddConstantLayer">AddConstantLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddConvolution2dLayer" href="#pyarmnn.INetwork.AddConvolution2dLayer">AddConvolution2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDepthwiseConvolution2dLayer" href="#pyarmnn.INetwork.AddDepthwiseConvolution2dLayer">AddDepthwiseConvolution2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDequantizeLayer" href="#pyarmnn.INetwork.AddDequantizeLayer">AddDequantizeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDetectionPostProcessLayer" href="#pyarmnn.INetwork.AddDetectionPostProcessLayer">AddDetectionPostProcessLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddDivisionLayer" href="#pyarmnn.INetwork.AddDivisionLayer">AddDivisionLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddFloorLayer" href="#pyarmnn.INetwork.AddFloorLayer">AddFloorLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddFullyConnectedLayer" href="#pyarmnn.INetwork.AddFullyConnectedLayer">AddFullyConnectedLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddGatherLayer" href="#pyarmnn.INetwork.AddGatherLayer">AddGatherLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddInputLayer" href="#pyarmnn.INetwork.AddInputLayer">AddInputLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddL2NormalizationLayer" href="#pyarmnn.INetwork.AddL2NormalizationLayer">AddL2NormalizationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddLstmLayer" href="#pyarmnn.INetwork.AddLstmLayer">AddLstmLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMaximumLayer" href="#pyarmnn.INetwork.AddMaximumLayer">AddMaximumLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMeanLayer" href="#pyarmnn.INetwork.AddMeanLayer">AddMeanLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMergeLayer" href="#pyarmnn.INetwork.AddMergeLayer">AddMergeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMinimumLayer" href="#pyarmnn.INetwork.AddMinimumLayer">AddMinimumLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddMultiplicationLayer" href="#pyarmnn.INetwork.AddMultiplicationLayer">AddMultiplicationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddNormalizationLayer" href="#pyarmnn.INetwork.AddNormalizationLayer">AddNormalizationLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddOutputLayer" href="#pyarmnn.INetwork.AddOutputLayer">AddOutputLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPadLayer" href="#pyarmnn.INetwork.AddPadLayer">AddPadLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPermuteLayer" href="#pyarmnn.INetwork.AddPermuteLayer">AddPermuteLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPooling2dLayer" href="#pyarmnn.INetwork.AddPooling2dLayer">AddPooling2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddPreluLayer" href="#pyarmnn.INetwork.AddPreluLayer">AddPreluLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddQuantizeLayer" href="#pyarmnn.INetwork.AddQuantizeLayer">AddQuantizeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddQuantizedLstmLayer" href="#pyarmnn.INetwork.AddQuantizedLstmLayer">AddQuantizedLstmLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddReshapeLayer" href="#pyarmnn.INetwork.AddReshapeLayer">AddReshapeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddResizeLayer" href="#pyarmnn.INetwork.AddResizeLayer">AddResizeLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddRsqrtLayer" href="#pyarmnn.INetwork.AddRsqrtLayer">AddRsqrtLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSoftmaxLayer" href="#pyarmnn.INetwork.AddSoftmaxLayer">AddSoftmaxLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSpaceToBatchNdLayer" href="#pyarmnn.INetwork.AddSpaceToBatchNdLayer">AddSpaceToBatchNdLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSpaceToDepthLayer" href="#pyarmnn.INetwork.AddSpaceToDepthLayer">AddSpaceToDepthLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSplitterLayer" href="#pyarmnn.INetwork.AddSplitterLayer">AddSplitterLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddStackLayer" href="#pyarmnn.INetwork.AddStackLayer">AddStackLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddStridedSliceLayer" href="#pyarmnn.INetwork.AddStridedSliceLayer">AddStridedSliceLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSubtractionLayer" href="#pyarmnn.INetwork.AddSubtractionLayer">AddSubtractionLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddSwitchLayer" href="#pyarmnn.INetwork.AddSwitchLayer">AddSwitchLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.AddTransposeConvolution2dLayer" href="#pyarmnn.INetwork.AddTransposeConvolution2dLayer">AddTransposeConvolution2dLayer</a></code></li>
<li><code><a title="pyarmnn.INetwork.thisown" href="#pyarmnn.INetwork.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IOnnxParser" href="#pyarmnn.IOnnxParser">IOnnxParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IOnnxParser.CreateNetworkFromBinaryFile" href="#pyarmnn.IOnnxParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.IOnnxParser.GetNetworkInputBindingInfo" href="#pyarmnn.IOnnxParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.IOnnxParser.GetNetworkOutputBindingInfo" href="#pyarmnn.IOnnxParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.IOnnxParser.thisown" href="#pyarmnn.IOnnxParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IOptimizedNetwork" href="#pyarmnn.IOptimizedNetwork">IOptimizedNetwork</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IOptimizedNetwork.SerializeToDot" href="#pyarmnn.IOptimizedNetwork.SerializeToDot">SerializeToDot</a></code></li>
<li><code><a title="pyarmnn.IOptimizedNetwork.thisown" href="#pyarmnn.IOptimizedNetwork.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IOutputSlot" href="#pyarmnn.IOutputSlot">IOutputSlot</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IOutputSlot.CalculateIndexOnOwner" href="#pyarmnn.IOutputSlot.CalculateIndexOnOwner">CalculateIndexOnOwner</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.Connect" href="#pyarmnn.IOutputSlot.Connect">Connect</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.Disconnect" href="#pyarmnn.IOutputSlot.Disconnect">Disconnect</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetConnection" href="#pyarmnn.IOutputSlot.GetConnection">GetConnection</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetNumConnections" href="#pyarmnn.IOutputSlot.GetNumConnections">GetNumConnections</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetOwningLayerGuid" href="#pyarmnn.IOutputSlot.GetOwningLayerGuid">GetOwningLayerGuid</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.GetTensorInfo" href="#pyarmnn.IOutputSlot.GetTensorInfo">GetTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.IsTensorInfoSet" href="#pyarmnn.IOutputSlot.IsTensorInfoSet">IsTensorInfoSet</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.SetTensorInfo" href="#pyarmnn.IOutputSlot.SetTensorInfo">SetTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IOutputSlot.thisown" href="#pyarmnn.IOutputSlot.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IProfiler" href="#pyarmnn.IProfiler">IProfiler</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.IProfiler.EnableProfiling" href="#pyarmnn.IProfiler.EnableProfiling">EnableProfiling</a></code></li>
<li><code><a title="pyarmnn.IProfiler.IsProfilingEnabled" href="#pyarmnn.IProfiler.IsProfilingEnabled">IsProfilingEnabled</a></code></li>
<li><code><a title="pyarmnn.IProfiler.as_json" href="#pyarmnn.IProfiler.as_json">as_json</a></code></li>
<li><code><a title="pyarmnn.IProfiler.event_log" href="#pyarmnn.IProfiler.event_log">event_log</a></code></li>
<li><code><a title="pyarmnn.IProfiler.thisown" href="#pyarmnn.IProfiler.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.IRuntime" href="#pyarmnn.IRuntime">IRuntime</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.IRuntime.EnqueueWorkload" href="#pyarmnn.IRuntime.EnqueueWorkload">EnqueueWorkload</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetDeviceSpec" href="#pyarmnn.IRuntime.GetDeviceSpec">GetDeviceSpec</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetInputTensorInfo" href="#pyarmnn.IRuntime.GetInputTensorInfo">GetInputTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetOutputTensorInfo" href="#pyarmnn.IRuntime.GetOutputTensorInfo">GetOutputTensorInfo</a></code></li>
<li><code><a title="pyarmnn.IRuntime.GetProfiler" href="#pyarmnn.IRuntime.GetProfiler">GetProfiler</a></code></li>
<li><code><a title="pyarmnn.IRuntime.LoadNetwork" href="#pyarmnn.IRuntime.LoadNetwork">LoadNetwork</a></code></li>
<li><code><a title="pyarmnn.IRuntime.UnloadNetwork" href="#pyarmnn.IRuntime.UnloadNetwork">UnloadNetwork</a></code></li>
<li><code><a title="pyarmnn.IRuntime.thisown" href="#pyarmnn.IRuntime.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ITfLiteParser" href="#pyarmnn.ITfLiteParser">ITfLiteParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ITfLiteParser.CreateNetworkFromBinaryFile" href="#pyarmnn.ITfLiteParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetNetworkInputBindingInfo" href="#pyarmnn.ITfLiteParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetNetworkOutputBindingInfo" href="#pyarmnn.ITfLiteParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetSubgraphCount" href="#pyarmnn.ITfLiteParser.GetSubgraphCount">GetSubgraphCount</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetSubgraphInputTensorNames" href="#pyarmnn.ITfLiteParser.GetSubgraphInputTensorNames">GetSubgraphInputTensorNames</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.GetSubgraphOutputTensorNames" href="#pyarmnn.ITfLiteParser.GetSubgraphOutputTensorNames">GetSubgraphOutputTensorNames</a></code></li>
<li><code><a title="pyarmnn.ITfLiteParser.thisown" href="#pyarmnn.ITfLiteParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ITfParser" href="#pyarmnn.ITfParser">ITfParser</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ITfParser.CreateNetworkFromBinaryFile" href="#pyarmnn.ITfParser.CreateNetworkFromBinaryFile">CreateNetworkFromBinaryFile</a></code></li>
<li><code><a title="pyarmnn.ITfParser.GetNetworkInputBindingInfo" href="#pyarmnn.ITfParser.GetNetworkInputBindingInfo">GetNetworkInputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfParser.GetNetworkOutputBindingInfo" href="#pyarmnn.ITfParser.GetNetworkOutputBindingInfo">GetNetworkOutputBindingInfo</a></code></li>
<li><code><a title="pyarmnn.ITfParser.thisown" href="#pyarmnn.ITfParser.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.L2NormalizationDescriptor" href="#pyarmnn.L2NormalizationDescriptor">L2NormalizationDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.L2NormalizationDescriptor.m_DataLayout" href="#pyarmnn.L2NormalizationDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.L2NormalizationDescriptor.m_Eps" href="#pyarmnn.L2NormalizationDescriptor.m_Eps">m_Eps</a></code></li>
<li><code><a title="pyarmnn.L2NormalizationDescriptor.thisown" href="#pyarmnn.L2NormalizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.LstmDescriptor" href="#pyarmnn.LstmDescriptor">LstmDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.LstmDescriptor.m_ActivationFunc" href="#pyarmnn.LstmDescriptor.m_ActivationFunc">m_ActivationFunc</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_CifgEnabled" href="#pyarmnn.LstmDescriptor.m_CifgEnabled">m_CifgEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_ClippingThresCell" href="#pyarmnn.LstmDescriptor.m_ClippingThresCell">m_ClippingThresCell</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_ClippingThresProj" href="#pyarmnn.LstmDescriptor.m_ClippingThresProj">m_ClippingThresProj</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_LayerNormEnabled" href="#pyarmnn.LstmDescriptor.m_LayerNormEnabled">m_LayerNormEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_PeepholeEnabled" href="#pyarmnn.LstmDescriptor.m_PeepholeEnabled">m_PeepholeEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.m_ProjectionEnabled" href="#pyarmnn.LstmDescriptor.m_ProjectionEnabled">m_ProjectionEnabled</a></code></li>
<li><code><a title="pyarmnn.LstmDescriptor.thisown" href="#pyarmnn.LstmDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.LstmInputParams" href="#pyarmnn.LstmInputParams">LstmInputParams</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.LstmInputParams.m_CellBias" href="#pyarmnn.LstmInputParams.m_CellBias">m_CellBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellLayerNormWeights" href="#pyarmnn.LstmInputParams.m_CellLayerNormWeights">m_CellLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellToForgetWeights" href="#pyarmnn.LstmInputParams.m_CellToForgetWeights">m_CellToForgetWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellToInputWeights" href="#pyarmnn.LstmInputParams.m_CellToInputWeights">m_CellToInputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_CellToOutputWeights" href="#pyarmnn.LstmInputParams.m_CellToOutputWeights">m_CellToOutputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ForgetGateBias" href="#pyarmnn.LstmInputParams.m_ForgetGateBias">m_ForgetGateBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ForgetLayerNormWeights" href="#pyarmnn.LstmInputParams.m_ForgetLayerNormWeights">m_ForgetLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputGateBias" href="#pyarmnn.LstmInputParams.m_InputGateBias">m_InputGateBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputLayerNormWeights" href="#pyarmnn.LstmInputParams.m_InputLayerNormWeights">m_InputLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToCellWeights" href="#pyarmnn.LstmInputParams.m_InputToCellWeights">m_InputToCellWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToForgetWeights" href="#pyarmnn.LstmInputParams.m_InputToForgetWeights">m_InputToForgetWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToInputWeights" href="#pyarmnn.LstmInputParams.m_InputToInputWeights">m_InputToInputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_InputToOutputWeights" href="#pyarmnn.LstmInputParams.m_InputToOutputWeights">m_InputToOutputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_OutputGateBias" href="#pyarmnn.LstmInputParams.m_OutputGateBias">m_OutputGateBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_OutputLayerNormWeights" href="#pyarmnn.LstmInputParams.m_OutputLayerNormWeights">m_OutputLayerNormWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ProjectionBias" href="#pyarmnn.LstmInputParams.m_ProjectionBias">m_ProjectionBias</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_ProjectionWeights" href="#pyarmnn.LstmInputParams.m_ProjectionWeights">m_ProjectionWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToCellWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToCellWeights">m_RecurrentToCellWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToForgetWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToForgetWeights">m_RecurrentToForgetWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToInputWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToInputWeights">m_RecurrentToInputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.m_RecurrentToOutputWeights" href="#pyarmnn.LstmInputParams.m_RecurrentToOutputWeights">m_RecurrentToOutputWeights</a></code></li>
<li><code><a title="pyarmnn.LstmInputParams.thisown" href="#pyarmnn.LstmInputParams.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.MeanDescriptor" href="#pyarmnn.MeanDescriptor">MeanDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.MeanDescriptor.m_Axis" href="#pyarmnn.MeanDescriptor.m_Axis">m_Axis</a></code></li>
<li><code><a title="pyarmnn.MeanDescriptor.m_KeepDims" href="#pyarmnn.MeanDescriptor.m_KeepDims">m_KeepDims</a></code></li>
<li><code><a title="pyarmnn.MeanDescriptor.thisown" href="#pyarmnn.MeanDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.NormalizationDescriptor" href="#pyarmnn.NormalizationDescriptor">NormalizationDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.NormalizationDescriptor.m_Alpha" href="#pyarmnn.NormalizationDescriptor.m_Alpha">m_Alpha</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_Beta" href="#pyarmnn.NormalizationDescriptor.m_Beta">m_Beta</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_DataLayout" href="#pyarmnn.NormalizationDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_K" href="#pyarmnn.NormalizationDescriptor.m_K">m_K</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_NormChannelType" href="#pyarmnn.NormalizationDescriptor.m_NormChannelType">m_NormChannelType</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_NormMethodType" href="#pyarmnn.NormalizationDescriptor.m_NormMethodType">m_NormMethodType</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.m_NormSize" href="#pyarmnn.NormalizationDescriptor.m_NormSize">m_NormSize</a></code></li>
<li><code><a title="pyarmnn.NormalizationDescriptor.thisown" href="#pyarmnn.NormalizationDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.OptimizerOptions" href="#pyarmnn.OptimizerOptions">OptimizerOptions</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.OptimizerOptions.m_Debug" href="#pyarmnn.OptimizerOptions.m_Debug">m_Debug</a></code></li>
<li><code><a title="pyarmnn.OptimizerOptions.m_ReduceFp32ToFp16" href="#pyarmnn.OptimizerOptions.m_ReduceFp32ToFp16">m_ReduceFp32ToFp16</a></code></li>
<li><code><a title="pyarmnn.OptimizerOptions.thisown" href="#pyarmnn.OptimizerOptions.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.PadDescriptor" href="#pyarmnn.PadDescriptor">PadDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.PadDescriptor.m_PadList" href="#pyarmnn.PadDescriptor.m_PadList">m_PadList</a></code></li>
<li><code><a title="pyarmnn.PadDescriptor.m_PadValue" href="#pyarmnn.PadDescriptor.m_PadValue">m_PadValue</a></code></li>
<li><code><a title="pyarmnn.PadDescriptor.thisown" href="#pyarmnn.PadDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.PermutationVector" href="#pyarmnn.PermutationVector">PermutationVector</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.PermutationVector.GetSize" href="#pyarmnn.PermutationVector.GetSize">GetSize</a></code></li>
<li><code><a title="pyarmnn.PermutationVector.IsInverse" href="#pyarmnn.PermutationVector.IsInverse">IsInverse</a></code></li>
<li><code><a title="pyarmnn.PermutationVector.thisown" href="#pyarmnn.PermutationVector.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.PermuteDescriptor" href="#pyarmnn.PermuteDescriptor">PermuteDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.PermuteDescriptor.m_DimMappings" href="#pyarmnn.PermuteDescriptor.m_DimMappings">m_DimMappings</a></code></li>
<li><code><a title="pyarmnn.PermuteDescriptor.thisown" href="#pyarmnn.PermuteDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.Pooling2dDescriptor" href="#pyarmnn.Pooling2dDescriptor">Pooling2dDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_DataLayout" href="#pyarmnn.Pooling2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_OutputShapeRounding" href="#pyarmnn.Pooling2dDescriptor.m_OutputShapeRounding">m_OutputShapeRounding</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadBottom" href="#pyarmnn.Pooling2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadLeft" href="#pyarmnn.Pooling2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadRight" href="#pyarmnn.Pooling2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PadTop" href="#pyarmnn.Pooling2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PaddingMethod" href="#pyarmnn.Pooling2dDescriptor.m_PaddingMethod">m_PaddingMethod</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PoolHeight" href="#pyarmnn.Pooling2dDescriptor.m_PoolHeight">m_PoolHeight</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PoolType" href="#pyarmnn.Pooling2dDescriptor.m_PoolType">m_PoolType</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_PoolWidth" href="#pyarmnn.Pooling2dDescriptor.m_PoolWidth">m_PoolWidth</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_StrideX" href="#pyarmnn.Pooling2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.m_StrideY" href="#pyarmnn.Pooling2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.Pooling2dDescriptor.thisown" href="#pyarmnn.Pooling2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ProfilerData" href="#pyarmnn.ProfilerData">ProfilerData</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ProfilerData.inference_data" href="#pyarmnn.ProfilerData.inference_data">inference_data</a></code></li>
<li><code><a title="pyarmnn.ProfilerData.per_workload_execution_data" href="#pyarmnn.ProfilerData.per_workload_execution_data">per_workload_execution_data</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ReshapeDescriptor" href="#pyarmnn.ReshapeDescriptor">ReshapeDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ReshapeDescriptor.m_TargetShape" href="#pyarmnn.ReshapeDescriptor.m_TargetShape">m_TargetShape</a></code></li>
<li><code><a title="pyarmnn.ReshapeDescriptor.thisown" href="#pyarmnn.ReshapeDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.ResizeDescriptor" href="#pyarmnn.ResizeDescriptor">ResizeDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.ResizeDescriptor.m_DataLayout" href="#pyarmnn.ResizeDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.m_Method" href="#pyarmnn.ResizeDescriptor.m_Method">m_Method</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.m_TargetHeight" href="#pyarmnn.ResizeDescriptor.m_TargetHeight">m_TargetHeight</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.m_TargetWidth" href="#pyarmnn.ResizeDescriptor.m_TargetWidth">m_TargetWidth</a></code></li>
<li><code><a title="pyarmnn.ResizeDescriptor.thisown" href="#pyarmnn.ResizeDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SoftmaxDescriptor" href="#pyarmnn.SoftmaxDescriptor">SoftmaxDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.SoftmaxDescriptor.m_Axis" href="#pyarmnn.SoftmaxDescriptor.m_Axis">m_Axis</a></code></li>
<li><code><a title="pyarmnn.SoftmaxDescriptor.m_Beta" href="#pyarmnn.SoftmaxDescriptor.m_Beta">m_Beta</a></code></li>
<li><code><a title="pyarmnn.SoftmaxDescriptor.thisown" href="#pyarmnn.SoftmaxDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SpaceToBatchNdDescriptor" href="#pyarmnn.SpaceToBatchNdDescriptor">SpaceToBatchNdDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.m_BlockShape" href="#pyarmnn.SpaceToBatchNdDescriptor.m_BlockShape">m_BlockShape</a></code></li>
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.m_DataLayout" href="#pyarmnn.SpaceToBatchNdDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.m_PadList" href="#pyarmnn.SpaceToBatchNdDescriptor.m_PadList">m_PadList</a></code></li>
<li><code><a title="pyarmnn.SpaceToBatchNdDescriptor.thisown" href="#pyarmnn.SpaceToBatchNdDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SpaceToDepthDescriptor" href="#pyarmnn.SpaceToDepthDescriptor">SpaceToDepthDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.SpaceToDepthDescriptor.m_BlockSize" href="#pyarmnn.SpaceToDepthDescriptor.m_BlockSize">m_BlockSize</a></code></li>
<li><code><a title="pyarmnn.SpaceToDepthDescriptor.m_DataLayout" href="#pyarmnn.SpaceToDepthDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.SpaceToDepthDescriptor.thisown" href="#pyarmnn.SpaceToDepthDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.SplitterDescriptor" href="#pyarmnn.SplitterDescriptor">SplitterDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.SplitterDescriptor.GetNumDimensions" href="#pyarmnn.SplitterDescriptor.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetNumViews" href="#pyarmnn.SplitterDescriptor.GetNumViews">GetNumViews</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetOrigins" href="#pyarmnn.SplitterDescriptor.GetOrigins">GetOrigins</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetViewOrigin" href="#pyarmnn.SplitterDescriptor.GetViewOrigin">GetViewOrigin</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.GetViewSizes" href="#pyarmnn.SplitterDescriptor.GetViewSizes">GetViewSizes</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.SetViewOriginCoord" href="#pyarmnn.SplitterDescriptor.SetViewOriginCoord">SetViewOriginCoord</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.SetViewSize" href="#pyarmnn.SplitterDescriptor.SetViewSize">SetViewSize</a></code></li>
<li><code><a title="pyarmnn.SplitterDescriptor.thisown" href="#pyarmnn.SplitterDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.StackDescriptor" href="#pyarmnn.StackDescriptor">StackDescriptor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.StackDescriptor.m_Axis" href="#pyarmnn.StackDescriptor.m_Axis">m_Axis</a></code></li>
<li><code><a title="pyarmnn.StackDescriptor.m_InputShape" href="#pyarmnn.StackDescriptor.m_InputShape">m_InputShape</a></code></li>
<li><code><a title="pyarmnn.StackDescriptor.m_NumInputs" href="#pyarmnn.StackDescriptor.m_NumInputs">m_NumInputs</a></code></li>
<li><code><a title="pyarmnn.StackDescriptor.thisown" href="#pyarmnn.StackDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.StridedSliceDescriptor" href="#pyarmnn.StridedSliceDescriptor">StridedSliceDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.StridedSliceDescriptor.GetStartForAxis" href="#pyarmnn.StridedSliceDescriptor.GetStartForAxis">GetStartForAxis</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.GetStopForAxis" href="#pyarmnn.StridedSliceDescriptor.GetStopForAxis">GetStopForAxis</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_Begin" href="#pyarmnn.StridedSliceDescriptor.m_Begin">m_Begin</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_BeginMask" href="#pyarmnn.StridedSliceDescriptor.m_BeginMask">m_BeginMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_DataLayout" href="#pyarmnn.StridedSliceDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_EllipsisMask" href="#pyarmnn.StridedSliceDescriptor.m_EllipsisMask">m_EllipsisMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_End" href="#pyarmnn.StridedSliceDescriptor.m_End">m_End</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_EndMask" href="#pyarmnn.StridedSliceDescriptor.m_EndMask">m_EndMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_NewAxisMask" href="#pyarmnn.StridedSliceDescriptor.m_NewAxisMask">m_NewAxisMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_ShrinkAxisMask" href="#pyarmnn.StridedSliceDescriptor.m_ShrinkAxisMask">m_ShrinkAxisMask</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.m_Stride" href="#pyarmnn.StridedSliceDescriptor.m_Stride">m_Stride</a></code></li>
<li><code><a title="pyarmnn.StridedSliceDescriptor.thisown" href="#pyarmnn.StridedSliceDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.Tensor" href="#pyarmnn.Tensor">Tensor</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.Tensor.get_memory_area" href="#pyarmnn.Tensor.get_memory_area">get_memory_area</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.TensorInfo" href="#pyarmnn.TensorInfo">TensorInfo</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.TensorInfo.GetDataType" href="#pyarmnn.TensorInfo.GetDataType">GetDataType</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetNumBytes" href="#pyarmnn.TensorInfo.GetNumBytes">GetNumBytes</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetNumDimensions" href="#pyarmnn.TensorInfo.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetNumElements" href="#pyarmnn.TensorInfo.GetNumElements">GetNumElements</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetQuantizationOffset" href="#pyarmnn.TensorInfo.GetQuantizationOffset">GetQuantizationOffset</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetQuantizationScale" href="#pyarmnn.TensorInfo.GetQuantizationScale">GetQuantizationScale</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.GetShape" href="#pyarmnn.TensorInfo.GetShape">GetShape</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.IsQuantized" href="#pyarmnn.TensorInfo.IsQuantized">IsQuantized</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.IsTypeSpaceMatch" href="#pyarmnn.TensorInfo.IsTypeSpaceMatch">IsTypeSpaceMatch</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetDataType" href="#pyarmnn.TensorInfo.SetDataType">SetDataType</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetQuantizationOffset" href="#pyarmnn.TensorInfo.SetQuantizationOffset">SetQuantizationOffset</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetQuantizationScale" href="#pyarmnn.TensorInfo.SetQuantizationScale">SetQuantizationScale</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.SetShape" href="#pyarmnn.TensorInfo.SetShape">SetShape</a></code></li>
<li><code><a title="pyarmnn.TensorInfo.thisown" href="#pyarmnn.TensorInfo.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.TensorShape" href="#pyarmnn.TensorShape">TensorShape</a></code></h4>
<ul class="">
<li><code><a title="pyarmnn.TensorShape.GetNumDimensions" href="#pyarmnn.TensorShape.GetNumDimensions">GetNumDimensions</a></code></li>
<li><code><a title="pyarmnn.TensorShape.GetNumElements" href="#pyarmnn.TensorShape.GetNumElements">GetNumElements</a></code></li>
<li><code><a title="pyarmnn.TensorShape.thisown" href="#pyarmnn.TensorShape.thisown">thisown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pyarmnn.TransposeConvolution2dDescriptor" href="#pyarmnn.TransposeConvolution2dDescriptor">TransposeConvolution2dDescriptor</a></code></h4>
<ul class="two-column">
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_BiasEnabled" href="#pyarmnn.TransposeConvolution2dDescriptor.m_BiasEnabled">m_BiasEnabled</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_DataLayout" href="#pyarmnn.TransposeConvolution2dDescriptor.m_DataLayout">m_DataLayout</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadBottom" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadBottom">m_PadBottom</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadLeft" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadLeft">m_PadLeft</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadRight" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadRight">m_PadRight</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_PadTop" href="#pyarmnn.TransposeConvolution2dDescriptor.m_PadTop">m_PadTop</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_StrideX" href="#pyarmnn.TransposeConvolution2dDescriptor.m_StrideX">m_StrideX</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.m_StrideY" href="#pyarmnn.TransposeConvolution2dDescriptor.m_StrideY">m_StrideY</a></code></li>
<li><code><a title="pyarmnn.TransposeConvolution2dDescriptor.thisown" href="#pyarmnn.TransposeConvolution2dDescriptor.thisown">thisown</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>